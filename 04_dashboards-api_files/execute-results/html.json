{
  "hash": "530675f7df09b7ceedeb216b05a7a1c7",
  "result": {
    "markdown": "# Dashboards and APIs\n\n## Learning Objectives\n\nBy the end of today's session you should be able to:\n\n1.  Understand the basic principles of APIs\n2.  Download and visualise data from NOMIS using the NOMIS API\n3.  Understand the basic principles of R Shiny\n4.  Build a basic dashboard using R Shiny\n\n\n\n\n\n## Introduction to APIs\n\nWeb services make their data easily accessible to computer programs like R through use of an Application Programming Interface (API). Today's practical will teach you how to access data from APIs, and load them into your R environment for analysis.\n\nTo download data from an API you need to send a HTTP request to a server, which tells the server to return the specific parcel of data that matches the criteria in the HTTP request.\n\nFor example, on NOMIS there is a page called ['Census 2021 Bulk Data Download'](https://www.nomisweb.co.uk/sources/census_2021_bulk), which contains .zip files for different tables of data available from the latest census.\n\nNow you should go to the ['Census 2021 Bulk Data Download'](https://www.nomisweb.co.uk/sources/census_2021_bulk) page, and see what it contains.\n\n\\[IMAGE\\]\n\nThere are lots of files on the web page - e.g. census2021-ts001.zip, census2021-ts007a.zip.\n\nYou can click on these files individually, download them to your PC, unzip them and read them into R. Alternatively, we can programmatically download the data directly from the webpage.\n\nIf you 'right click' on one of the .zip files and press 'copy link', you will have a URL which can access that specific .zip file, as below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl <- \"https://www.nomisweb.co.uk/output/census/2021/census2021-ts061.zip\"\nurl\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"https://www.nomisweb.co.uk/output/census/2021/census2021-ts061.zip\"\n```\n:::\n:::\n\n\nThe specific URL above relates to table [TS061 - \"Method of Travel to Work\"](https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/employmentandemployeetypes/bulletins/traveltoworkenglandandwales/census2021), which is the same dataset we were using in yesterday's Data Visualisation workshop.\n\nNow I'm going to show you how to download the .zip file, and read in the file of data we used yesterday. This is a really basic example of using an API, which shows how you can download data from NOMIS into your environment, without having to physically go and download it, save it to a folder, unzip it and read it into memory.\n\nFirst, let's download the .zip file - this line of code downloads the .zip file to your local machine, which you will be able to find in your working directory - go and take a look!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Download the .zip file, using the url set above\ndownload.file(url, \"temp.zip\")\n```\n:::\n\n\nNext we need to unzip the folder, to get to the datasets stored within:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## First set where you want the unzipped files to be stored\noutDir <- \"data/unzip\"\n## Unzip the folder to the data/unzip folder\nunzip(\"temp.zip\", exdir = outDir)\n```\n:::\n\n\nOk so now that you've downloaded the files to your local machine, we can look and see what files are available to us:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Use list.files() to see what we unzipped\nlist.files(\"data/unzip\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"census2021-ts061-ctry.csv\" \"census2021-ts061-lsoa.csv\"\n[3] \"census2021-ts061-ltla.csv\" \"census2021-ts061-msoa.csv\"\n[5] \"census2021-ts061-oa.csv\"   \"census2021-ts061-rgn.csv\" \n[7] \"census2021-ts061-utla.csv\" \"metadata\"                 \n```\n:::\n:::\n\n\nThankfully, NOMIS use a really standard naming protocol for their files, which makes it really easy to tell what each of the files contains. If you cast your mind back to yesterday, we used a file called \"census2021-ts061-lsoa.csv\", which we provided to you as part of the course materials. However, as you can see from the code above, you have now programmatically downloaded the same file, which we can read in:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Read in the LSOA census data\ndb <- read.csv(\"data/unzip/census2021-ts061-lsoa.csv\")\n```\n:::\n\n\n### Independent exercise - Over to you!\n\n1.  As a recap, see if you can reproduce one of the visualisations we produced yesterday using the data we have just scraped from the API.\n2.  Test downloading two more datasets from NOMIS, by swapping in different table names into the URL.\n3.  (*optional*) Produce an interesting visualisation from that new dataset.\n\n## Using the NOMIS API\n\nOne of the things that you see more commonly in practice is the construction of specific R packages used to access APIs, with supporting documentation and specific functions that make it easier to use the API.\n\nOne such example is [nomisr](https://docs.evanodell.com/nomisr/articles/introduction.html), which is an R package that was built to enable users to query data from NOMIS. It is free to access and contains up-to-date official statistics including data from the latest Census, Labour Force Survey and DWP benefit statistics.\n\nIn the section that follows, I'm going to be showing you how to use the nomisr package to download datasets.\n\nVast amounts of data are available through NOMIS, so you need to use some of the different functions within nomisr to identify the specific datasets you want to use.\n\nAn example is presented below which searches for datasets within NOMIS that are specifically about 'Travel':\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Search for data on Labour Force\nsearch <- nomis_search(\"*Travel*\")\n```\n:::\n\n\nThis returns a dataframe (which you should see in your environment) that describes all of the different NOMIS held datasets where 'Travel' is mentioned. The column perhaps of most interest is the short name for the different datasets, which you can inspect below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Have a look at the first six datasets \nhead(search$name.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2001 census - UK travel flows (local authority)\"            \n[2] \"2001 census - Scottish travel flows (local authority)\"      \n[3] \"2001 census - UK travel flows (ward)\"                       \n[4] \"QS702EW - Distance travelled to work\"                       \n[5] \"WD702EW - Distance travelled to work (Workday population)\"  \n[6] \"WP702EW - Distance travelled to work (Workplace population)\"\n```\n:::\n:::\n\n\nIf you open up the dataframe in your environment and scroll down you should see one row has the value - TS061 - Method used to travel to work - which is the one we've been using a lot in this practical.\n\nWe can filter to this row very easily using the filter() command that we introduced yesterday:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Filter to row of interest\nsearch_sub <- search %>%\n  filter(name.value == \"TS061 - Method used to travel to work\")\n\n## Have a look at the result\nsearch_sub\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 12\n  agencyid id      uri   version annot…¹ compo…² compo…³ compo…⁴ compo…⁵ compo…⁶\n  <chr>    <chr>   <chr>   <dbl> <list>  <list>  <list>  <chr>   <chr>   <chr>  \n1 NOMIS    NM_207… Nm-2…       1 <df>    <df>    <df>    OBS_VA… CL_207… TIME   \n# … with 2 more variables: name.value <chr>, name.lang <chr>, and abbreviated\n#   variable names ¹​annotations.annotation, ²​components.attribute,\n#   ³​components.dimension, ⁴​components.primarymeasure.conceptref,\n#   ⁵​components.timedimension.codelist, ⁶​components.timedimension.conceptref\n```\n:::\n:::\n\n\nWe can get some metadata for this dataset very easily using the nomis_get_metadata() command. First, let's see what measures are available:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Supply the ID of the row we're interested in, and the second parameters specifies we'd like to know more about the measures\nnomis_get_metadata(search_sub$id, \"measures\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  id    label.en description.en\n  <chr> <chr>    <chr>         \n1 20100 value    value         \n2 20301 percent  percent       \n```\n:::\n:::\n\n\nSo for TS061, we can get both raw counts ('value') and percent. Let's now see what geographies are available:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Supply the ID of the row we're interested in, and the second parameter specifies that we want to know more about geographies\nnomis_get_metadata(search_sub$id, \"geography\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 4\n  id         parentCode label.en          description.en   \n  <chr>      <chr>      <chr>             <chr>            \n1 2092957703 <NA>       England and Wales England and Wales\n2 2092957699 <NA>       England           England          \n3 2092957700 2092957700 Wales             Wales            \n```\n:::\n:::\n\n\nOk, so this is telling us the different geographic levels we can download the data for. However, if we add an additional parameter to this, we can also see the specific geographic units that this data is available at:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Add in an additional parameter\nnomis_get_metadata(search_sub$id, \"geography\", \"TYPE\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 × 3\n   id      label.en                                                 descriptio…¹\n   <chr>   <chr>                                                    <chr>       \n 1 TYPE150 2021 output areas                                        2021 output…\n 2 TYPE151 2021 super output areas - lower layer                    2021 super …\n 3 TYPE152 2021 super output areas - middle layer                   2021 super …\n 4 TYPE153 2022 wards                                               2022 wards  \n 5 TYPE154 2022 local authorities: districts                        2022 local …\n 6 TYPE155 2022 local authorities: counties                         2022 local …\n 7 TYPE168 2021 national parks                                      2021 nation…\n 8 TYPE423 local authorities: county / unitary (as of April 2023)   local autho…\n 9 TYPE424 local authorities: district / unitary (as of April 2023) local autho…\n10 TYPE459 local enterprise partnerships (as of April 2021)         local enter…\n11 TYPE480 regions                                                  regions     \n12 TYPE499 countries                                                countries   \n# … with abbreviated variable name ¹​description.en\n```\n:::\n:::\n\n\nThose steps basically give us everything we need to download the dataset directly from the NOMIS API using the package, instead of downloading the .zip files directly.\n\nLet's download the file - it could take a while! If you don't understand any of the specific inputs to this line of code, feel free to shout Patrick to talk it through.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Download the file\ndb_v2 <- nomis_get_data(id = \"NM_2078_1\", time = \"latest\", geography = c(\"TYPE151\"), measures = \"20301\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving additional pages 1 of 17\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving additional pages 2 of 17\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving additional pages 3 of 17\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving additional pages 4 of 17\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving additional pages 5 of 17\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving additional pages 6 of 17\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving additional pages 7 of 17\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving additional pages 8 of 17\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving additional pages 9 of 17\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving additional pages 10 of 17\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving additional pages 11 of 17\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving additional pages 12 of 17\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving additional pages 13 of 17\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving additional pages 14 of 17\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving additional pages 15 of 17\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving additional pages 16 of 17\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving additional pages 17 of 17\n```\n:::\n:::\n\n\nThe format the data is presented in is not the most intuitive, so those reshaping skills we acquired yesterday are going to come in handy here again!\n\nFirstly, let's get the columns we need for our analysis - LSOA codes, the different modes of transport and the actual reported values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Select columns of interest\ndb_clean <- db_v2 %>%\n  select(GEOGRAPHY_CODE, C2021_TTWMETH_12_NAME, OBS_VALUE) \n\n## Inspect\nhead(db_clean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n  GEOGRAPHY_CODE C2021_TTWMETH_12_NAME                                   OBS_V…¹\n  <chr>          <chr>                                                     <dbl>\n1 E01011954      Total: All usual residents aged 16 years and over in e…   100  \n2 E01011954      Work mainly at or from home                                11.9\n3 E01011954      Underground, metro, light rail, tram                        0  \n4 E01011954      Train                                                       0.3\n5 E01011954      Bus, minibus or coach                                       4.1\n6 E01011954      Taxi                                                        2  \n# … with abbreviated variable name ¹​OBS_VALUE\n```\n:::\n:::\n\n\nSo as you can see from the table, it's actually in a long format, whereas we might want it to be in a wide format, where each column is the % of people using each transport mode. Let's use the pivot_wider() command to change this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Go from long to wide\ndb_clean <- db_clean %>%\n  pivot_wider(names_from = C2021_TTWMETH_12_NAME, values_from = OBS_VALUE)\n\n## Inspect\nhead(db_clean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 13\n  GEOGRAPH…¹ Total…² Work …³ Under…⁴ Train Bus, …⁵  Taxi Motor…⁶ Drivi…⁷ Passe…⁸\n  <chr>        <dbl>   <dbl>   <dbl> <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>\n1 E01011954      100    11.9     0     0.3     4.1   2       0.3    63.6     7.5\n2 E01011969      100    14.7     0     0.9     2.9   0.7     0.2    67.6     6.7\n3 E01011970      100    19.5     0     1.5     2.7   0.6     0.8    65.5     5.4\n4 E01011971      100    19       0     0.7     1.6   0.5     0      68.1     5.6\n5 E01033465      100    22.2     0.2   1       1.5   1.1     0.1    65.5     3.6\n6 E01033467      100    20.6     0.3   0.5     2.3   1.2     0      67.1     4  \n# … with 3 more variables: Bicycle <dbl>, `On foot` <dbl>,\n#   `Other method of travel to work` <dbl>, and abbreviated variable names\n#   ¹​GEOGRAPHY_CODE,\n#   ²​`Total: All usual residents aged 16 years and over in employment the week before the census`,\n#   ³​`Work mainly at or from home`, ⁴​`Underground, metro, light rail, tram`,\n#   ⁵​`Bus, minibus or coach`, ⁶​`Motorcycle, scooter or moped`,\n#   ⁷​`Driving a car or van`, ⁸​`Passenger in a car or van`\n```\n:::\n:::\n\n\nGreat, that's worked! You'll also notice the number of rows of db_clean matches that of db (which was the file we unzipped at the start of the practical).\n\nSome final data cleaning steps:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Tidy up the dataset\ndb_final <- db_clean %>%\n  setNames(c(\"LSOA21CD\", \"total\", \"work_from_home\", \"underground_metro\", \"train\", \"bus_minibus_coach\", \n             \"taxi\", \"motorcycle\", \"car_driving\", \"car_passenger\", \"bicycle\", \"foot\", \"other\")) ## set new names\n```\n:::\n\n\nAnd then we can easily produce one of the visualisations from yesterday:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Reproduce the scatter plot from yesterday's class\nggplot(data = db_final, aes(x = work_from_home, y = car_driving)) +\n  geom_point(alpha = 0.3, size = 0.35) +\n  geom_smooth(method = \"lm\") +\n  xlim(0, 100) +\n  ylim(0, 100) +\n  labs(x = \"Population who work from home (%)\", y = \"Population who drive to work (%)\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](04_dashboards-api_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n### Independent exercise - Over to you!\n\n1.  Experiment with downloading a different dataset using the nomisr package, and clean it.\n2.  Produce an interesting visualisation using your chosen dataset.\n3.  (*optional*) See if you can attach the LAD names to your dataset, and produce a visualisation that examines LAD differences in your chosen dataset - recommend you choose a dataset at either LSOA or MSOA geography to use yesterday's lookup table.\n\n## Building Dashboards in R\n\nDashboards are often a great way to share results and analyses with others. There are a number of ways you can build dashboards in R, including:\n\n1.  Using markdown (flexdashboard R package)\n2.  Using R shiny.\n\nThe former offers you to create a dashboard with panels and pages very easily, and has significant advantages over R Shiny:\n\n1.  Minimal coding required.\n2.  Dashboard can be distributed as the .html file, with no server required.\n3.  Other packages can hook into the dashboard to add interactivity.\n\n### Getting started\n\nTo build a dashboard using R markdown, we will need to use an alternate type of computational workbook - thus far we have been working with Quarto files (.qmd), but now we need to switch to the format that supports \"Flex Dashboards\".\n\nGo to File \\> New File \\> R Markdown \\> From Template \\> Flex Dashboard.\n\n\\[IMAGE\\]\n\n**IMPORTANT** For instruction purposes, I am going to document the steps in this file, but you need to be working on the new .Rmd file that we have just created, not inside this Quarto document. Patrick will demo this for you.\n\nOk, so go to your .Rmd file, and save it as something you can remember - e.g., dashboard.Rmd. Inside the file you will notice a couple of different things:\n\n1.  Code blocks - you will see code blocks like those you have been running in this document, which can be used to run lines of code easily.\n2.  YAML header - at the top of the new file is a YAML header, which is where you can set up the basic metadata for the dashboard.\n\nHave a go at changing your YAML header to the following:\n\n\n---\ntitle: \"Transport Dashboard - Liverpool\"\nauthor: \"Dr. Patrick Ballantyne\"\ndate: \"`r Sys.Date()\"\noutput: \n  flexdashboard::flex_dashboard:\n    orientation: rows\n    vertical_layout: scroll\n---\n\n\n\n\n## Other Useful Reporting Techniques\n\nWe have shown you the power of using R and Quarto for generating computational workbooks where you can view both the figures/outputs and code used to generate them, all at once.\n\n### Constructing Reports\n\nThe .html files that render alongside these .qmd files can be seen as 'reports' in a way. However, there is a whole host of design-related modifications you can make to the .qmd file which will enhance the appearance of the output report.\n\nThere is lots of useful information online about creating nice reports using R markdown - including this one from [The Epidemiologist R Handbook](https://epirhandbook.com/en/reports-with-r-markdown.html).\n\n### Routine Reporting\n\nThe Epidemiologist Handbook also has a really nice section on how to use R to run reports routinely, using the reportfactory R package. Have a a look ath the [Organising routing reports](https://epirhandbook.com/en/organizing-routine-reports.html) guide if you are interested in learning more about this!\n\n## Additional Resources\n",
    "supporting": [
      "04_dashboards-api_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}