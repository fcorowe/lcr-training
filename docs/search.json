[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R training: Liverpool City Region",
    "section": "",
    "text": "Welcome\nThis website hosts the materials for the R training course for the Liverpool City Region. This training workshop was designed and is delivered by Prof. Francisco Rowe and Dr. Patrick Pallantyne.\nThe website is free to use and is licensed under the Attribution-NonCommercial-NoDerivatives 4.0 International.\n\n\nContact\n\nProf. Francisco Rowe, Professor in Population Data Science\nf.rowe-gonzalez [at] liverpool.ac.uk\nDepartment of Geography and Planning, University of Liverpool, Liverpool, United Kingdom\n\n\nDr. Patrick Ballantyne, Postdoctoral Researcher in Geographic Data Science\np.ballantyne [at] liverpool.ac.uk\nDepartment of Geography and Planning, University of Liverpool, Liverpool, United Kingdom",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "00_overview.html",
    "href": "00_overview.html",
    "title": "Overview",
    "section": "",
    "text": "Description\nThis workshop aims to provide R training to analysts in Liverpool City Region Combined Authority. Over four days we will cover a number of topics, which align with the current needs of the analyst team, demonstrating how R can be used for a diverse range of day-to-day analyst tasks.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "00_overview.html#delivery-structure",
    "href": "00_overview.html#delivery-structure",
    "title": "Overview",
    "section": "Delivery & Structure",
    "text": "Delivery & Structure\nThe course will be taught across four days. Each day will run from 10AM to 3PM. Days 1 & 2 will be hosted at the University of Liverpool, and Days 3 & 4 will be hosted at LCRCA.\n\n\n\nDay\nActivity\nInstructor\n\n\n\n\n1\nR Fundamentals\nFrancisco Rowe\n\n\n2\nData visualisation\nPatrick Ballantyne\n\n\n3\nAPIs & Dashboards\nPatrick Ballantyne\n\n\n4\nData modeling\nFrancisco Rowe",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "00_overview.html#before-the-workshop",
    "href": "00_overview.html#before-the-workshop",
    "title": "Overview",
    "section": "Before the workshop",
    "text": "Before the workshop\n\n\n\n\n\n\nImportant\n\n\n\nPlease make sure you download and install the most recent version of R, RStudio and Quarto on the computer that you will be using during the workshop, and install the indicated R packages – see detailed instructions below.\n\n\n\n\n\n\n\n\nNote\n\n\n\nAll three software packages are open and free to use.\n\n\nR\nYou can download R here. Make sure you select the appropriate version for your Operating System: Windows, MacOS (Apple silicon M1/M2 or older intel Macs). For example, if you use a macOS laptop with an M1 processor, click on ‘Download R for macOS’ and then, click the link to download the installer file (.pkg extension for macOS) under the header ‘For Apple silicon (M1/M2) Macs’. You can then open the installer and follow the instructions that you will be prompted with. For Windows users, click on ‘install R for the first time’ and follow the prompts.\nRStudio\nYou will also need to download RStudio Desktop (or simply RStudio), which is an integrated development environment to help you write code in R more easily. To download RStudio, follow this link and scroll down to the section titled ‘All Installers and Tarballs’. Download the appropriate installer file according to your Operating System. Then, open the installer and follow the installation instructions that you will be prompted with.\nQuarto\nDownload Quarto from this website. Quarto is a publishing system that will allow you to open and work on the computational notebooks for the workshop. On ‘Step 1’ on the website, download the version of Quarto that matches your Operating System. Open the installer file, run it and follow the prompts.\nR packages\nOnce you have installed R, you will need to install some R extensions, known as packages, that will be useful for the applications explored in this workshop. The packages you need to install are:\n\ntidyverse\nggthemes\nzoo\nmice\npatchwork\nviridis\ntmap\nsf\nsp\nstringr\nRColorBrewer\nshowtext\nscales\nleaflet\ntmap\nmapdeck\nplotly\nhtmlwidgets\nnomisr\nflexdashboard\nggfortify\nforecast\ntseries\n\nTo install the packages, open RStudio. On the console window (normally at the bottom left), write the following command: install.packages(\"name of package\"). Make sure you replace “name of package” by the actual name of the package that you want to install e.g. install.packages(\"tidyverse\"). Then, press enter and repeat this process until you have installed all the packages in the list.\nYou can install all the packages by copying and running the code below:\n\nlist.of.packages.cran &lt;- c(\n   \"tidyverse\",\n   \"ggthemes\",\n   \"zoo\",\n   \"mice\",\n   \"patchwork\",\n   \"viridis\",\n   \"tmap\",\n   \"sf\",\n   \"sp\",\n   \"stringr\",\n   \"RColorBrewer\",\n   \"showtext\",\n   \"scales\",\n   \"leaflet\",\n   \"tmap\",\n   \"mapdeck\",\n   \"plotly\",\n   \"htmlwidgets\",\n   \"nomisr\",\n   \"flexdashboard\",\n   \"ggfortify\",\n   \"forecast\",\n   \"tseries\"\n)\n\nnew.packages.cran &lt;- list.of.packages.cran[!(list.of.packages.cran %in% installed.packages()[,\"Package\"])]\nif(length(new.packages.cran)) install.packages(new.packages.cran)\n\nfor(i in 1:length(list.of.packages.cran)) {\n  library(list.of.packages.cran[i], character.only = T)\n}\n\nYou can load all the packages by copying and running the code below:\n\ndeps &lt;- list(\n   \"tidyverse\",\n   \"ggthemes\",\n   \"zoo\",\n   \"mice\",\n   \"patchwork\",\n   \"viridis\",\n   \"tmap\",\n   \"sf\",\n   \"sp\",\n   \"stringr\",\n   \"RColorBrewer\",\n   \"showtext\",\n   \"scales\",\n   \"leaflet\",\n   \"tmap\",\n   \"mapdeck\",\n   \"plotly\",\n   \"htmlwidgets\",\n   \"nomisr\",\n   \"flexdashboard\",\n    \"ggfortify\",\n   \"forecast\",\n   \"tseries\"\n)\n\nfor(lib in deps){library(lib, character.only = TRUE)}\n\n\n\n\n\n\n\nNote\n\n\n\nWe might ask you to install more packages on the day that this workshop is taking place.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nInstructions by email will be sent before the workshop to download the Github repository and data which will be used during the workshop. Please ensure you have downloaded the repository and data before the workshop.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "00_overview.html#during-the-workshop",
    "href": "00_overview.html#during-the-workshop",
    "title": "Overview",
    "section": "During the workshop",
    "text": "During the workshop\nAll the workshop material will be made available on this website which is currently under construction. Further instructions on how to download the material will be given during the workshop.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "01_fundamentals.html",
    "href": "01_fundamentals.html",
    "title": "1  R Fundamentals",
    "section": "",
    "text": "1.1 Learning Objectives\nBy the end of today’s session you should be able to:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "01_fundamentals.html#learning-objectives",
    "href": "01_fundamentals.html#learning-objectives",
    "title": "1  R Fundamentals",
    "section": "",
    "text": "Be familiar with R, RStudio, Quarto and R programming.\nHandle different data types, including numeric, string and factors.\nUnderstand how to create and handle non-geographic and geographic data frames.\nBe familiar with common R packages, including the tidyverse and r-spatial ecosystems.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "01_fundamentals.html#plan-for-the-day",
    "href": "01_fundamentals.html#plan-for-the-day",
    "title": "1  R Fundamentals",
    "section": "1.2 Plan for the day",
    "text": "1.2 Plan for the day\n\n\n\nTime\nContent\n\n\n\n\n10.00 - 10.15\nIntroduction\n\n\n10.15 - 10.45\nSetting up & interacting with materials\n\n\n10.45 - 11.30\nR Basics\n\n\n11.30 - 11.50\nBreak\n\n\n11.50 - 12.50\nUsing Quarto documents & Data types\n\n\n12.50 - 13.30\nLunch\n\n\n13.30 - 14.15\nNon-geographic data frames\n\n\n14.15 - 14.45\nGeographic data frames\n\n\n14.45 - 15.00\nQuestions & closing",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "01_fundamentals.html#dependencies",
    "href": "01_fundamentals.html#dependencies",
    "title": "1  R Fundamentals",
    "section": "1.3 Dependencies",
    "text": "1.3 Dependencies\n\n# data manipulation\nlibrary(tidyverse)\n# spatial data manipulation\nlibrary(sf)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "01_fundamentals.html#introducing-r",
    "href": "01_fundamentals.html#introducing-r",
    "title": "1  R Fundamentals",
    "section": "1.4 Introducing R",
    "text": "1.4 Introducing R\nR is a freely available language and environment for statistical computing and graphics which provides a wide variety of statistical and graphical techniques. It has gained widespread use in academia and industry. R offers a wider array of functionality than a traditional statistics package, is composed of core (base) functionality, and is expandable through libraries hosted on The Comprehensive R Archive Network (CRAN). CRAN is a network of ftp and web servers around the world that store identical, up-to-date, versions of code and documentation for R.\nCommands are sent to R using either the terminal / command line or the R Console which is installed with R on either Windows or OS X. On Linux, there is no equivalent of the console, however, third party solutions exist. On your own machine, R can be installed from here.\nNormally RStudio is used to implement R coding. RStudio is an integrated development environment (IDE) for R and provides a more user-friendly front-end to R than the front-end provided with R.\nTo run R or RStudio, just double click on the R or RStudio icon. Throughout this course, we will be using RStudio:\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you would like to know more about the various features of RStudio, read this post.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "01_fundamentals.html#working-directory",
    "href": "01_fundamentals.html#working-directory",
    "title": "1  R Fundamentals",
    "section": "1.5 Working directory",
    "text": "1.5 Working directory\nBefore we start any analysis, ensure to set the path to the directory where we are working. We have two options to do this.\nOption 1\nOnce you have opened R, you can use the command setwd( ) to set the working directory. For example, replace in the following line the path to the folder where you have placed this file and where the data folder lives.\n\nsetwd(\"\")\n\nYou can check your current working directory by typing:\n\ngetwd()\n\nOption 2\nBefore opening any files in the folder, open the file with the extension *.Rproj. This is a R project and automatically indexes all the files in the folder and subfolders so there is no need to explicitly set the working directory. You can call any files in the R project folder by replacing the working directory with “.”. For instance, let us open a dataset from our subfolder data:\n\nread_csv(\"./data/census2021-ts061-lsoa.csv\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "01_fundamentals.html#r-scripts",
    "href": "01_fundamentals.html#r-scripts",
    "title": "1  R Fundamentals",
    "section": "1.6 R scripts",
    "text": "1.6 R scripts\nAn R script is a series of commands that you can execute at one time and help you save time. R scripts are useful to ensure reproducibility; that is if you want to repeat the same series of steps with the same or different datasets. An R script is a plain text file with R commands.\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo get familiar with good practices in writing your code in R, we recommend the Chapter Workflow: basics and Workflow: scripts and projects from the R in Data Science book by Wickham, Çetinkaya-Rundel, and Grolemund (2023)\n\n\nTo create an R script in RStudio, you need to:\n\nOpen a new script file: File &gt; New File &gt; R Script\nWrite some code on your new script window by typing eg. mtcars\nRun the script. Click anywhere on the line of code, then hit Ctrl + Enter (Windows) or Cmd + Enter (Mac) to run the command or select the code chunk and click run on the right-top corner of your script window. If do that, you should get:\n\n\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\n\nSave the script: File &gt; Save As, select your required destination folder, and enter any filename that you like, provided that it ends with the file extension .R\n\n\n\n\n\n\n\nTask\nOpen and create a basic R Script",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "01_fundamentals.html#quarto-document",
    "href": "01_fundamentals.html#quarto-document",
    "title": "1  R Fundamentals",
    "section": "1.7 Quarto Document",
    "text": "1.7 Quarto Document\nA Quarto Document is based on Markdown technology. It allows to integrate descriptive text and code chunks. Code chunks can be executed independently and interactively, with output visible immediately beneath a code chunk - see Xie, Allaire, and Grolemund (2018). A Quarto Document is an improved version of the original R Notebook. Quarto Document requires a package called Quarto. Quarto does not have a dependency or requirement for R. Quarto is multilingual, beginning with R, Python, Javascript, and Julia. The concept is that Quarto will work even for languages that do not yet exist.\nTo create a Quarto Document, you need to:\n\nOpen a new script file: File &gt; New File &gt; Quarto Document.\nQuarto Documents work in the same way as R Notebooks with small variations. You can find a comprehensive guide on how to use Quarto Documents on the Quarto website.\n\n\n\n\n\n\n\nTask\nOpen, create, preview and render a Quarto Document\n\n\n\nNow that you are familiar with Quarto, we will explore some basic elements:\n\nYAML options\nCode chunks\nPreview\nRendering\n\nTo master Quarto, please read the Quarto Guide page.\n\n1.7.1 Using quarto documents\nQuarto documents are very flexible. They can be rendered into different formats, including pdf, html and doc files. They can be used to product reports, articles, briefs, websites, books and more. We can explore how this can be done using some of the templates we have produced and are hosted on our personal Github repository.\nLet us explore the use of Quarto documents by downloading the repository above and examine the various templates available.\n\n\n\n\n\n\nTask\nInclude your name and affiliation on one of the Quarto Document templates. Also try changing the font family.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "01_fundamentals.html#help",
    "href": "01_fundamentals.html#help",
    "title": "1  R Fundamentals",
    "section": "1.8 Help",
    "text": "1.8 Help\nYou can use help or ? to ask for details for a specific function:\nhelp(sqrt) #or ?sqrt\n?ggplot\nAnd using example provides examples for said function:\n\nexample(geom_map)\n\n\ngem_mp&gt; # First, a made-up example containing a few polygons, to explain\ngem_mp&gt; # how `geom_map()` works. It requires two data frames:\ngem_mp&gt; # One contains the coordinates of each polygon (`positions`), and is\ngem_mp&gt; # provided via the `map` argument. The other contains the\ngem_mp&gt; # other the values associated with each polygon (`values`).  An id\ngem_mp&gt; # variable links the two together.\ngem_mp&gt; \ngem_mp&gt; ids &lt;- factor(c(\"1.1\", \"2.1\", \"1.2\", \"2.2\", \"1.3\", \"2.3\"))\n\ngem_mp&gt; values &lt;- data.frame(\ngem_mp+   id = ids,\ngem_mp+   value = c(3, 3.1, 3.1, 3.2, 3.15, 3.5)\ngem_mp+ )\n\ngem_mp&gt; positions &lt;- data.frame(\ngem_mp+   id = rep(ids, each = 4),\ngem_mp+   x = c(2, 1, 1.1, 2.2, 1, 0, 0.3, 1.1, 2.2, 1.1, 1.2, 2.5, 1.1, 0.3,\ngem_mp+   0.5, 1.2, 2.5, 1.2, 1.3, 2.7, 1.2, 0.5, 0.6, 1.3),\ngem_mp+   y = c(-0.5, 0, 1, 0.5, 0, 0.5, 1.5, 1, 0.5, 1, 2.1, 1.7, 1, 1.5,\ngem_mp+   2.2, 2.1, 1.7, 2.1, 3.2, 2.8, 2.1, 2.2, 3.3, 3.2)\ngem_mp+ )\n\ngem_mp&gt; ggplot(values) +\ngem_mp+   geom_map(aes(map_id = id), map = positions) +\ngem_mp+   expand_limits(positions)\n\n\n\n\n\n\n\n\n\n\ngem_mp&gt; ggplot(values, aes(fill = value)) +\ngem_mp+   geom_map(aes(map_id = id), map = positions) +\ngem_mp+   expand_limits(positions)\n\n\n\n\n\n\n\n\n\n\ngem_mp&gt; ggplot(values, aes(fill = value)) +\ngem_mp+   geom_map(aes(map_id = id), map = positions) +\ngem_mp+   expand_limits(positions) + ylim(0, 3)\n\n\n\n\n\n\n\n\n\n\ngem_mp&gt; # Now some examples with real maps\ngem_mp&gt; if (require(maps)) {\ngem_mp+ \ngem_mp+   crimes &lt;- data.frame(state = tolower(rownames(USArrests)), USArrests)\ngem_mp+ \ngem_mp+   # Equivalent to crimes %&gt;% tidyr::pivot_longer(Murder:Rape)\ngem_mp+   vars &lt;- lapply(names(crimes)[-1], function(j) {\ngem_mp+     data.frame(state = crimes$state, variable = j, value = crimes[[j]])\ngem_mp+   })\ngem_mp+   crimes_long &lt;- do.call(\"rbind\", vars)\ngem_mp+ \ngem_mp+   states_map &lt;- map_data(\"state\")\ngem_mp+ \ngem_mp+   # without geospatial coordinate system, the resulting plot\ngem_mp+   # looks weird\ngem_mp+   ggplot(crimes, aes(map_id = state)) +\ngem_mp+     geom_map(aes(fill = Murder), map = states_map) +\ngem_mp+     expand_limits(x = states_map$long, y = states_map$lat)\ngem_mp+ \ngem_mp+   # in combination with `coord_sf()` we get an appropriate result\ngem_mp+   ggplot(crimes, aes(map_id = state)) +\ngem_mp+     geom_map(aes(fill = Murder), map = states_map) +\ngem_mp+     # crs = 5070 is a Conus Albers projection for North America,\ngem_mp+     #   see: https://epsg.io/5070\ngem_mp+     # default_crs = 4326 tells coord_sf() that the input map data\ngem_mp+     #   are in longitude-latitude format\ngem_mp+     coord_sf(\ngem_mp+       crs = 5070, default_crs = 4326,\ngem_mp+       xlim = c(-125, -70), ylim = c(25, 52)\ngem_mp+     )\ngem_mp+ \ngem_mp+  ggplot(crimes_long, aes(map_id = state)) +\ngem_mp+    geom_map(aes(fill = value), map = states_map) +\ngem_mp+    coord_sf(\ngem_mp+      crs = 5070, default_crs = 4326,\ngem_mp+      xlim = c(-125, -70), ylim = c(25, 52)\ngem_mp+    ) +\ngem_mp+    facet_wrap(~variable)\ngem_mp+ }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTask\nAsk for help for a different function.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "01_fundamentals.html#r-data-types",
    "href": "01_fundamentals.html#r-data-types",
    "title": "1  R Fundamentals",
    "section": "1.9 R data types",
    "text": "1.9 R data types\nThere are a number of data types. Four are the most common. In R, numeric is the default type for numbers. It stores all numbers as floating-point numbers (numbers with decimals). This is because most statistical calculations deal with numbers with up to two decimals.\nBefore starting with the various data types which R can handle, we should understand that any element appearing in our R environment is called a R object and they can take different shapes. It could be a single character, a vector, a matrix, a list or have a more complex structure.\nNumeric\n\nnum &lt;- 4.5 # Decimal values\nclass(num)\n\n[1] \"numeric\"\n\n\nInteger\n\nint &lt;- as.integer(4) # Natural numbers. Note integers are also numerics.\nclass(int)\n\n[1] \"integer\"\n\n\nCharacter\n\ncha &lt;- \"are you enjoying this?\" # text or string. You can also type `as.character(\"are you enjoying this?\")`\nclass(cha)\n\n[1] \"character\"\n\n\nLogical\n\nlog &lt;- 2 &lt; 1 # assigns TRUE or FALSE. In this case, FALSE as 2 is greater than 1\nlog\n\n[1] FALSE\n\nclass(log)\n\n[1] \"logical\"\n\n\nYou can create vectors by concatenating elements:\n\ndata_vector &lt;- c(2, 3, 4, 5, 6)\ndata_vector\n\n[1] 2 3 4 5 6\n\n\n\n\n\n\n\n\nTask\nCreate a variable called income, with the following five respondent values: high, low, low, middle, high.\n\n\n\n\n1.9.1 Factors\nA factor variable assigns a numeric code to each possible category (level) in a variable. Behind the scenes, R stores the variable using these numeric codes to save space and speed up computing. For example, compare the size of a list of 10,000 males and females to a list of 10,000 1s and 0s. At the same time R also saves the category names associated with each numeric code (level). These are used for display purposes.\nFor example, the variable gender, converted to a factor, would be stored as a series of 1s and 2s, where 1 = female and 2 = male; but would be displayed in all outputs using their category labels of female and male.\nDefining a factor\nA factor can be defined by first creating a numeric or character vector; for example:\n\ngender &lt;- c(\"female\", \"male\", \"male\", \"female\", \"female\") # create a gender variable\ngender &lt;- factor(gender) # replace character vector with a factor version\ngender\n\n[1] female male   male   female female\nLevels: female male\n\n\nWe can ask the class of gender:\n\nclass(gender)\n\n[1] \"factor\"\n\n\nAnd also its structure:\n\nstr(gender)\n\n Factor w/ 2 levels \"female\",\"male\": 1 2 2 1 1\n\n\ngender is a factor and is stored as a series of 1s and 2s, with 1s representing females and 2s representing males. The function levels( ) lists the levels (categories) associated with a given factor variable:\n\nlevels(gender)\n\n[1] \"female\" \"male\"  \n\n\nThe categories are reported in the order that they have been numbered (starting from 1). Hence from the output we can infer that females are coded as 1, and males as 2. Factor variables are useful to encode categorical or qualitative data; that is, data on nominal or ordinal scales.\nDefining an ordered factor\nBy default the levels of the factor (variable categories) are allocated in alphabetical order. Hence in the example above female = 1 and male = 2.\nSometimes an alternative ordering is required, for example male = 1 and female = 2.\nFor nominal variables, the solution is to specify the required order of the levels when calling the factor( ) function via the levels( ) sub-command:\n\ngender2 &lt;- factor(gender, levels= c(\"male\", \"female\"))\ngender2\n\n[1] female male   male   female female\nLevels: male female\n\n\nUsing a factor to define nominal and ordinal variables\nFor ordinal variables, such as income (income bracket), we create an ordered factor by calling the ordered( ) rather than factor( ) function, including a call to the sub-command levels( ) which specifies the required category order:\n\nincome &lt;- c(\"high\", \"low\", \"low\", \"middle\", \"high\")\nincome &lt;- ordered(income, levels = c(\"low\", \"middle\", \"high\"))\nincome\n\n[1] high   low    low    middle high  \nLevels: low &lt; middle &lt; high\n\n\nLet us explore its class, structure and levels:\n\nclass(income)\n\n[1] \"ordered\" \"factor\" \n\nstr(income)\n\n Ord.factor w/ 3 levels \"low\"&lt;\"middle\"&lt;..: 3 1 1 2 3\n\nlevels(income)\n\n[1] \"low\"    \"middle\" \"high\"  \n\n\nNote that if we do not use the levels( ) sub-command, then the default behaviour of ordered( ) is to order the categories alphabetically, like factor( ).\n\n\n\n\n\n\nTask\nRun the following line of code, then convert the resulting variable into a factor with the categories ordered car, train, bus, bicycle:\ntravel_mode &lt;- c(\"train\", \"bicycle\", \"bus\", \"car\", \"car\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "01_fundamentals.html#data-frames",
    "href": "01_fundamentals.html#data-frames",
    "title": "1  R Fundamentals",
    "section": "1.10 Data frames",
    "text": "1.10 Data frames\nR stores different types of data using different types of data structure. Data are normally stored as a data.frame. Data frames are a special R object. A data frame contains one row per observation and one column per attribute. In this course, we distinguish between non-geographic and geographic data frames.\n\n1.10.1 Non-geographic data frames\nNon-geographic data frames are data structures which have no indexed spatial elements as we will see below.\nReading data frames\nWe will start by illustrating how data frames can be read from our local hard drive. R has many commands to read and load data objects. The command to use will depend upon the format they have been saved. Normally they are saved in csv format from Excel or other software packages. So we use either of these lines of code:\n\ndf &lt;- read.csv(\"path/file_name.csv\", header = FALSE)\n\ndf &lt;- read.table(\"path/file_name.csv\", header = FALSE, sep =\",\")\n\ndf &lt;- read(\"path/file_name.csv\", header = FALSE)\n\ndf &lt;- read.csv2(\"path/file_name.csv\", header = FALSE)\n\nLet us use the first option to read some 2021 Census data.\n\ndf_census &lt;- read.csv(\"./data/census2021-ts061-lsoa.csv\")\nstr(df_census)\n\n'data.frame':   35672 obs. of  15 variables:\n $ date                                                                                                                     : int  2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 ...\n $ geography                                                                                                                : chr  \"City of London 001A\" \"City of London 001B\" \"City of London 001C\" \"City of London 001E\" ...\n $ geography.code                                                                                                           : chr  \"E01000001\" \"E01000002\" \"E01000003\" \"E01000005\" ...\n $ Method.of.travel.to.workplace..Total..All.usual.residents.aged.16.years.and.over.in.employment.the.week.before.the.census: int  866 881 1000 496 888 1385 651 784 740 904 ...\n $ Method.of.travel.to.workplace..Work.mainly.at.or.from.home                                                               : int  639 676 618 203 192 370 80 163 136 188 ...\n $ Method.of.travel.to.workplace..Underground..metro..light.rail..tram                                                      : int  35 31 74 69 205 358 126 201 155 203 ...\n $ Method.of.travel.to.workplace..Train                                                                                     : int  17 10 21 25 104 177 74 96 88 112 ...\n $ Method.of.travel.to.workplace..Bus..minibus.or.coach                                                                     : int  13 15 26 44 60 117 125 70 86 98 ...\n $ Method.of.travel.to.workplace..Taxi                                                                                      : int  4 2 4 2 1 8 4 1 1 10 ...\n $ Method.of.travel.to.workplace..Motorcycle..scooter.or.moped                                                              : int  3 1 4 3 5 3 3 4 3 5 ...\n $ Method.of.travel.to.workplace..Driving.a.car.or.van                                                                      : int  18 19 24 33 227 220 176 166 174 203 ...\n $ Method.of.travel.to.workplace..Passenger.in.a.car.or.van                                                                 : int  0 3 7 1 10 21 11 19 28 12 ...\n $ Method.of.travel.to.workplace..Bicycle                                                                                   : int  24 25 62 18 6 21 6 5 12 14 ...\n $ Method.of.travel.to.workplace..On.foot                                                                                   : int  109 92 143 90 61 71 40 44 42 38 ...\n $ Method.of.travel.to.workplace..Other.method.of.travel.to.work                                                            : int  4 7 17 8 17 19 6 15 15 21 ...\n\n\n\n\n\n\n\n\nTask\nLet us inspect the data: What class is the data frame? What data type are the variables in the data frame? What are the name of all columns in the data frame?\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo read files in other formats, refer to this useful DataCamp tutorial.\n\n\nCreating data frames\nWe can also create a data frame from scratch within R. We first need to create each column independently. We create three variables: lt_la (lower tier local authorities), deprivation_category and deprivation based on the 2021 census data on deprivation from the ONS website.\n\nlt_la &lt;- c(\"Knowsley\", \"Knowsley\", \"Knowsley\", \"Knowsley\", \"Knowsley\", \"Knowsley\", \"Liverpool\", \"Liverpool\", \"Liverpool\", \"Liverpool\", \"Liverpool\", \"Liverpool\", \"St. Helens\", \"St. Helens\", \"St. Helens\", \"St. Helens\", \"St. Helens\", \"St. Helens\", \"Sefton\", \"Sefton\", \"Sefton\", \"Sefton\", \"Sefton\", \"Sefton\", \"Wirral\", \"Wirral\", \"Wirral\", \"Wirral\", \"Wirral\", \"Wirral\")\n\ndeprivation_category &lt;- c(\"Does not apply\", \"Household is not deprived in any dimension\", \"Household is deprived in one dimension\", \"Household is deprived in two dimensions\", \"Household is deprived in three dimensions\", \"Household is deprived in four dimensions\", \"Does not apply\", \"Household is not deprived in any dimension\", \"Household is deprived in one dimension\", \"Household is deprived in two dimensions\", \"Household is deprived in three dimensions\", \"Household is deprived in four dimensions\", \"Does not apply\", \"Household is not deprived in any dimension\", \"Household is deprived in one dimension\", \"Household is deprived in two dimensions\", \"Household is deprived in three dimensions\", \"Household is deprived in four dimensions\", \"Does not apply\", \"Household is not deprived in any dimension\", \"Household is deprived in one dimension\", \"Household is deprived in two dimensions\", \"Household is deprived in three dimensions\", \"Household is deprived in four dimensions\", \"Does not apply\", \"Household is not deprived in any dimension\", \"Household is deprived in one dimension\", \"Household is deprived in two dimensions\", \"Household is deprived in three dimensions\", \"Household is deprived in four dimensions\")\n\ndeprivation &lt;- c(0, 26952, 21374, 12688, 4856, 203, 0, 86264, 67761, 38407, 14386, 673, 0, 35793, 27070, 13852, 4161, 137, 0, 55668, 41850, 19817, 5463, 275, 0, 65530, 47854, 22925, 6645, 298)\n\nWe now need to put these columns together as a data frame as follows:\n\ndf &lt;- data.frame(lt_la, deprivation_category, deprivation)\n\nWe can explore its structure:\n\nstr(df)\n\n'data.frame':   30 obs. of  3 variables:\n $ lt_la               : chr  \"Knowsley\" \"Knowsley\" \"Knowsley\" \"Knowsley\" ...\n $ deprivation_category: chr  \"Does not apply\" \"Household is not deprived in any dimension\" \"Household is deprived in one dimension\" \"Household is deprived in two dimensions\" ...\n $ deprivation         : num  0 26952 21374 12688 4856 ...\n\n\nReferencing data frames\nTo refer to particular parts of a data frame - say, a particular column, or a subset of respondents. Hence it is worth spending some time understanding how to reference data frames.\nThe relevant R function, [ ], has the format [row,col] or, more generally, [set of rows, set of cols].\nRun the following commands to get a feel of how to extract different slices of the data:\n\ndf # whole data.frame\n\ndf[1, 1] # contents of first row and column\n\ndf[2, 2:3] # contents of the second row, second and third columns\n\ndf[1, ] # first row, ALL columns [the default if no columns specified]\n\ndf[ ,1:2] # ALL rows; first and second columns\n\ndf[c(1,3,5), ] # rows 1,3,5; ALL columns\n\ndf[ , 2] # ALL rows; second column (by default results containing only \n             #one column are converted back into a vector)\n\ndf[ , 2, drop=FALSE] # ALL rows; second column (returned as a data.frame)\n\nIn the above, note that we have used two other R functions:\n1:3 The colon operator tells R to produce a list of numbers including the named start and end points.\nc(1,3,5) tells R to combine the contents within the brackets into one list of objects.\nRun both of these functions on their own to get a better understanding of what they do.\nThree other methods for referencing the contents of a data.frame make direct use of the variable names within the data.frame, which tends to make for easier to read/understand code:\ndf[, \"deprivation\"] # variable name in quotes inside the square brackets\n\ndf$deprivation # variable name prefixed with $ and appended to the data.frame name\n# or you can use attach\n\nattach(df)\ndeprivation # but be careful if you already have an age variable in your local workspace\nWant to check the variables available, use the names( ):\n\nnames(df)\n\n[1] \"lt_la\"                \"deprivation_category\" \"deprivation\"         \n\n\nManipulating data frames\nAdding new columns\nUsually you want to add or create new variables to your data frame using existing variables e.g. computing percentages by dividing two variables. There are many ways in which you can do this i.e. referencing a data frame as we have done above, or using $ (e.g. df_census$pop). For this course, we will use tidyverse.\n\ndf_census &lt;- df_census %&gt;% \n  mutate( active_travel = Method.of.travel.to.workplace..Bicycle + Method.of.travel.to.workplace..On.foot )\nstr(df_census)\n\n'data.frame':   35672 obs. of  16 variables:\n $ date                                                                                                                     : int  2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 ...\n $ geography                                                                                                                : chr  \"City of London 001A\" \"City of London 001B\" \"City of London 001C\" \"City of London 001E\" ...\n $ geography.code                                                                                                           : chr  \"E01000001\" \"E01000002\" \"E01000003\" \"E01000005\" ...\n $ Method.of.travel.to.workplace..Total..All.usual.residents.aged.16.years.and.over.in.employment.the.week.before.the.census: int  866 881 1000 496 888 1385 651 784 740 904 ...\n $ Method.of.travel.to.workplace..Work.mainly.at.or.from.home                                                               : int  639 676 618 203 192 370 80 163 136 188 ...\n $ Method.of.travel.to.workplace..Underground..metro..light.rail..tram                                                      : int  35 31 74 69 205 358 126 201 155 203 ...\n $ Method.of.travel.to.workplace..Train                                                                                     : int  17 10 21 25 104 177 74 96 88 112 ...\n $ Method.of.travel.to.workplace..Bus..minibus.or.coach                                                                     : int  13 15 26 44 60 117 125 70 86 98 ...\n $ Method.of.travel.to.workplace..Taxi                                                                                      : int  4 2 4 2 1 8 4 1 1 10 ...\n $ Method.of.travel.to.workplace..Motorcycle..scooter.or.moped                                                              : int  3 1 4 3 5 3 3 4 3 5 ...\n $ Method.of.travel.to.workplace..Driving.a.car.or.van                                                                      : int  18 19 24 33 227 220 176 166 174 203 ...\n $ Method.of.travel.to.workplace..Passenger.in.a.car.or.van                                                                 : int  0 3 7 1 10 21 11 19 28 12 ...\n $ Method.of.travel.to.workplace..Bicycle                                                                                   : int  24 25 62 18 6 21 6 5 12 14 ...\n $ Method.of.travel.to.workplace..On.foot                                                                                   : int  109 92 143 90 61 71 40 44 42 38 ...\n $ Method.of.travel.to.workplace..Other.method.of.travel.to.work                                                            : int  4 7 17 8 17 19 6 15 15 21 ...\n $ active_travel                                                                                                            : int  133 117 205 108 67 92 46 49 54 52 ...\n\n\nNote we used a pipe operator %&gt;%. This operator helps make the code more efficient and readable, see Wickham, Çetinkaya-Rundel, and Grolemund (2023) for more details. When using the pipe operator, recall to first indicate the data frame before %&gt;%.\nNote also the use a variable name before the = sign in brackets to indicate the name of the new variable after mutate.\nSelecting columns\nUsually you want to select a subset of variables for your analysis as storing to large data sets in your R memory can reduce the processing speed of your machine. A selection of data can be achieved by using the select function:\n\nndf &lt;- df_census %&gt;% \n  select( geography, active_travel)\n\nAgain first indicate the data frame and then the variable you want to select to build a new data frame. Note the code chunk above has created a new data frame called ndf. Explore it.\nFiltering data\nYou may also want to filter values based on defined conditions. You may want to filter observations greater than a certain threshold or only areas within a certain region. For example, you may want to select areas with an active travel count over 100:\n\nndf2 &lt;- ndf %&gt;% \n  filter( active_travel &gt; 100 )\n\nYou can use more than one variable to set conditions. Use “,” to add a condition.\nJoining data frames\nWe often need to join data from separate data frames. To this end, you need a common unique id variable. Let us imagine we have two separate data frames i.e. our original census data frame (df_census) and our data frame containing our active travel counts (i.e. ndf), and we want to join them. We re-read our df_census and then join the data frames.\n\n# read data\ndf_census &lt;- read.csv(\"./data/census2021-ts061-lsoa.csv\")\n# visualise data structure\nstr(df_census)\n\n'data.frame':   35672 obs. of  15 variables:\n $ date                                                                                                                     : int  2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 ...\n $ geography                                                                                                                : chr  \"City of London 001A\" \"City of London 001B\" \"City of London 001C\" \"City of London 001E\" ...\n $ geography.code                                                                                                           : chr  \"E01000001\" \"E01000002\" \"E01000003\" \"E01000005\" ...\n $ Method.of.travel.to.workplace..Total..All.usual.residents.aged.16.years.and.over.in.employment.the.week.before.the.census: int  866 881 1000 496 888 1385 651 784 740 904 ...\n $ Method.of.travel.to.workplace..Work.mainly.at.or.from.home                                                               : int  639 676 618 203 192 370 80 163 136 188 ...\n $ Method.of.travel.to.workplace..Underground..metro..light.rail..tram                                                      : int  35 31 74 69 205 358 126 201 155 203 ...\n $ Method.of.travel.to.workplace..Train                                                                                     : int  17 10 21 25 104 177 74 96 88 112 ...\n $ Method.of.travel.to.workplace..Bus..minibus.or.coach                                                                     : int  13 15 26 44 60 117 125 70 86 98 ...\n $ Method.of.travel.to.workplace..Taxi                                                                                      : int  4 2 4 2 1 8 4 1 1 10 ...\n $ Method.of.travel.to.workplace..Motorcycle..scooter.or.moped                                                              : int  3 1 4 3 5 3 3 4 3 5 ...\n $ Method.of.travel.to.workplace..Driving.a.car.or.van                                                                      : int  18 19 24 33 227 220 176 166 174 203 ...\n $ Method.of.travel.to.workplace..Passenger.in.a.car.or.van                                                                 : int  0 3 7 1 10 21 11 19 28 12 ...\n $ Method.of.travel.to.workplace..Bicycle                                                                                   : int  24 25 62 18 6 21 6 5 12 14 ...\n $ Method.of.travel.to.workplace..On.foot                                                                                   : int  109 92 143 90 61 71 40 44 42 38 ...\n $ Method.of.travel.to.workplace..Other.method.of.travel.to.work                                                            : int  4 7 17 8 17 19 6 15 15 21 ...\n\n\nThe variable geography in this data frame corresponds to the unique identifier we will use. As they are unique, they can be automatically matched by using the merge() function. The merge() function uses two arguments: x and y. The former refers to data frame 1 and the latter to data frame 2. Both of these two data frames must have a id variable containing the same information. Note they can have different names. Another key argument to include is all.x=TRUE which tells the function to keep all the records in x, but only those in y that match in case there are discrepancies in the id variable.\n\n# join data frames\njoin_dfs &lt;- merge( df_census, # df1\n                   ndf, # df2\n                   by.x=\"geography\", by.y=\"geography\", # common ids\n                   all.x = TRUE)\n# check data\nhead(join_dfs)\n\n  geography date geography.code\n1 Adur 001A 2021      E01031349\n2 Adur 001B 2021      E01031350\n3 Adur 001C 2021      E01031351\n4 Adur 001D 2021      E01031352\n5 Adur 001E 2021      E01031370\n6 Adur 001F 2021      E01031374\n  Method.of.travel.to.workplace..Total..All.usual.residents.aged.16.years.and.over.in.employment.the.week.before.the.census\n1                                                                                                                       665\n2                                                                                                                       655\n3                                                                                                                       771\n4                                                                                                                       685\n5                                                                                                                       694\n6                                                                                                                       832\n  Method.of.travel.to.workplace..Work.mainly.at.or.from.home\n1                                                        203\n2                                                        170\n3                                                        216\n4                                                        192\n5                                                        191\n6                                                        301\n  Method.of.travel.to.workplace..Underground..metro..light.rail..tram\n1                                                                   0\n2                                                                   2\n3                                                                   0\n4                                                                   0\n5                                                                   1\n6                                                                   0\n  Method.of.travel.to.workplace..Train\n1                                   15\n2                                   12\n3                                   13\n4                                    9\n5                                    8\n6                                   21\n  Method.of.travel.to.workplace..Bus..minibus.or.coach\n1                                                   20\n2                                                   36\n3                                                   24\n4                                                   31\n5                                                   20\n6                                                   23\n  Method.of.travel.to.workplace..Taxi\n1                                   0\n2                                   4\n3                                   3\n4                                   4\n5                                   4\n6                                   1\n  Method.of.travel.to.workplace..Motorcycle..scooter.or.moped\n1                                                           7\n2                                                           3\n3                                                           4\n4                                                           6\n5                                                           6\n6                                                           4\n  Method.of.travel.to.workplace..Driving.a.car.or.van\n1                                                 326\n2                                                 318\n3                                                 412\n4                                                 351\n5                                                 341\n6                                                 364\n  Method.of.travel.to.workplace..Passenger.in.a.car.or.van\n1                                                       23\n2                                                       33\n3                                                       22\n4                                                       25\n5                                                       22\n6                                                       28\n  Method.of.travel.to.workplace..Bicycle Method.of.travel.to.workplace..On.foot\n1                                     17                                     48\n2                                     18                                     48\n3                                     24                                     44\n4                                     19                                     41\n5                                     25                                     66\n6                                     32                                     52\n  Method.of.travel.to.workplace..Other.method.of.travel.to.work active_travel\n1                                                             6            65\n2                                                            11            66\n3                                                             9            68\n4                                                             7            60\n5                                                            10            91\n6                                                             6            84\n\n\nSaving data\nYou may need to save your R projects. Projects contain all the objects that you have created in your workspace. You can save them by using the save.image( ) function:\n\nsave.image(\"lcr-course_day-1.RData\")\n\nThis creates a file labelled “lcr-course_day-1.RData” in your working directory. You can load this at a later stage using the load( ) function.\n\nload(\"lcr-course_day-1.RData\")\n\nAlternatively you can save or export your data into a csv file. The first argument in the function is the object name, and the second: the name of the csv we want to create.\n\nwrite.csv(join_dfs, \"join_censusdfs.csv\")\n\n\n\n1.10.2 Geographic data frames\nAn important component of geographic data science is to manipulate geographic data frames. R has various purposely designed packages for manipulation of spatial data and spatial analysis techniques. Various packages exist in CRAN, including sf (E. Pebesma 2018, 2022a), stars (E. Pebesma 2022b), terra, s2 (Dunnington, Pebesma, and Rubak 2023), lwgeom (E. Pebesma 2023), gstat (E. J. Pebesma 2004; E. Pebesma and Graeler 2022), spdep (Bivand 2022), spatialreg (Bivand and Piras 2022), spatstat (Baddeley, Rubak, and Turner 2015; Baddeley, Turner, and Rubak 2022), tmap (Tennekes 2018, 2022), mapview (Appelhans et al. 2022) and more. A key package is this ecosystem is sf (E. Pebesma and Bivand 2023). R package sf provides a table format for simple features, where feature geometries are stored in a list-column. It appeared in 2016 and was developed to move spatial data analysis in R closer to standards-based approaches seen in the industry and open source projects, to build upon more modern versions of open source geospatial software stack and allow for integration of R spatial software with the tidyverse (Wickham et al. 2019), particularly ggplot2, dplyr, and tidyr. Hence, this book relies heavely on sf for the manipulation and analysis of the data.\n\n\n\n\n\n\n\n\nNote\n\n\n\nLovelace, Nowosad, and Muenchow (2024) provide a helpful overview and evolution of R spatial package ecosystem.\n\n\nReading geographic data frames\nTo read our spatial data, we use the st_read function. We read a shapefile containing data at the Lower Super Output Areas (LSOAs) level.\n\nsdf &lt;- st_read(\"./data/LCR-LSOA.gpkg\") \n\nReading layer `LCR-LSOA' from data source \n  `/Users/franciscorowe/Dropbox/Francisco/Research/grants/2024/lcr_training/lcr-training/data/LCR-LSOA.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1043 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 318351.7 ymin: 377513.8 xmax: 361791.1 ymax: 422866.5\nProjected CRS: OSGB36 / British National Grid\n\nhead(sdf)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 356526.1 ymin: 397294.1 xmax: 359746.3 ymax: 399734.2\nProjected CRS: OSGB36 / British National Grid\n   LSOA21CD   LSOA21NM                               GlobalID Rank. Decile\n1 E01006220 Wigan 035A {6A968831-6B5B-42A7-AFDE-9A2FD2E01FE2}     5      5\n2 E01006225 Wigan 036B {0727B328-8FBD-4074-A887-A40CB89502E2}     9      9\n3 E01006226 Wigan 035E {8A587355-7518-47EF-A60A-6CB117F54F05}     8      8\n4 E01006227 Wigan 038A {CC387BCB-5B3B-4E57-ABA3-4ADB3175D624}     8      8\n5 E01006264 Wigan 036D {89C9660D-5EC9-4498-BEBF-BED018377F41}    10     10\n6 E01006346 Wigan 038E {37DD7E6B-F345-400F-BD76-D8700BFCE534}     7      7\n       Top  Bottom.                           geom\n1 17.47911 42.96657 MULTIPOLYGON (((359223.5 39...\n2 39.40579 27.52150 MULTIPOLYGON (((356696.7 39...\n3 29.37013 36.02265 MULTIPOLYGON (((358079.4 39...\n4 27.95950 37.14953 MULTIPOLYGON (((359464.4 39...\n5 38.51224 26.55367 MULTIPOLYGON (((356526.2 39...\n6 28.96305 36.88915 MULTIPOLYGON (((359465.7 39...\n\n\nExamine the input data. A spatial data frame stores a range of attributes derived from a shapefile including the geometry of features (e.g. polygon shape and location), attributes for each feature (stored in the .dbf), projection and coordinates of the shapefile’s bounding box - for details, execute:\n\n?st_read\n\nYou can employ the usual functions to visualise the content of the created data frame:\n\n# visualise variable names\nnames(sdf)\n\n[1] \"LSOA21CD\" \"LSOA21NM\" \"GlobalID\" \"Rank.\"    \"Decile\"   \"Top\"      \"Bottom.\" \n[8] \"geom\"    \n\n\n\n# data structure\nstr(sdf)\n\nClasses 'sf' and 'data.frame':  1043 obs. of  8 variables:\n $ LSOA21CD: chr  \"E01006220\" \"E01006225\" \"E01006226\" \"E01006227\" ...\n $ LSOA21NM: chr  \"Wigan 035A\" \"Wigan 036B\" \"Wigan 035E\" \"Wigan 038A\" ...\n $ GlobalID: chr  \"{6A968831-6B5B-42A7-AFDE-9A2FD2E01FE2}\" \"{0727B328-8FBD-4074-A887-A40CB89502E2}\" \"{8A587355-7518-47EF-A60A-6CB117F54F05}\" \"{CC387BCB-5B3B-4E57-ABA3-4ADB3175D624}\" ...\n $ Rank.   : num  5 9 8 8 10 7 10 7 9 1 ...\n $ Decile  : int  5 9 8 8 10 7 10 7 9 1 ...\n $ Top     : num  17.5 39.4 29.4 28 38.5 ...\n $ Bottom. : num  43 27.5 36 37.1 26.6 ...\n $ geom    :sfc_MULTIPOLYGON of length 1043; first list element: List of 3\n  ..$ :List of 1\n  .. ..$ : num [1:17, 1:2] 359223 359312 359308 359300 359297 ...\n  ..$ :List of 1\n  .. ..$ : num [1:4, 1:2] 359352 359347 359346 359352 398448 ...\n  ..$ :List of 1\n  .. ..$ : num [1:12, 1:2] 359474 359467 359461 359462 359464 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geom\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA\n  ..- attr(*, \"names\")= chr [1:7] \"LSOA21CD\" \"LSOA21NM\" \"GlobalID\" \"Rank.\" ...\n\n\n\n# see first few observations\nhead(sdf)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 356526.1 ymin: 397294.1 xmax: 359746.3 ymax: 399734.2\nProjected CRS: OSGB36 / British National Grid\n   LSOA21CD   LSOA21NM                               GlobalID Rank. Decile\n1 E01006220 Wigan 035A {6A968831-6B5B-42A7-AFDE-9A2FD2E01FE2}     5      5\n2 E01006225 Wigan 036B {0727B328-8FBD-4074-A887-A40CB89502E2}     9      9\n3 E01006226 Wigan 035E {8A587355-7518-47EF-A60A-6CB117F54F05}     8      8\n4 E01006227 Wigan 038A {CC387BCB-5B3B-4E57-ABA3-4ADB3175D624}     8      8\n5 E01006264 Wigan 036D {89C9660D-5EC9-4498-BEBF-BED018377F41}    10     10\n6 E01006346 Wigan 038E {37DD7E6B-F345-400F-BD76-D8700BFCE534}     7      7\n       Top  Bottom.                           geom\n1 17.47911 42.96657 MULTIPOLYGON (((359223.5 39...\n2 39.40579 27.52150 MULTIPOLYGON (((356696.7 39...\n3 29.37013 36.02265 MULTIPOLYGON (((358079.4 39...\n4 27.95950 37.14953 MULTIPOLYGON (((359464.4 39...\n5 38.51224 26.55367 MULTIPOLYGON (((356526.2 39...\n6 28.96305 36.88915 MULTIPOLYGON (((359465.7 39...\n\n\nManipulating geographic data frames\nAs indicated above, the advantage of using sf to handle spatial data frames is that you can deploy all the tidyverse ecosystem. For example, try the tasks below.\n\n\n\n\n\n\nTask\nTry selecting columns “LSOA21NM” and “Decile” and using the new data frame to filter the data by “Decile = 5”.\n\n\n\nSimplifying boundaries\nNormally, the resolution of boundaries is very detailed and precise, but such level of detail and precision is not necessary for visualisation purposes, making their rendering small and computationally intensive. To address this, we simplify the boundaries which means we make them less detailed and precise. We can achive this as follows”\n\n# simplify boundaries\nsimple_sdf &lt;- sdf %&gt;% \n  st_simplify(preserveTopology =T, \n              dTolerance = 100) %&gt;%  # 100m\n  sf::st_make_valid() # check the geometry is valid\n\nsimple_sdf\n\nSimple feature collection with 1043 features and 7 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 318370.4 ymin: 377513.8 xmax: 361791.1 ymax: 422852\nProjected CRS: OSGB36 / British National Grid\nFirst 10 features:\n    LSOA21CD      LSOA21NM                               GlobalID Rank. Decile\n1  E01006220    Wigan 035A {6A968831-6B5B-42A7-AFDE-9A2FD2E01FE2}     5      5\n2  E01006225    Wigan 036B {0727B328-8FBD-4074-A887-A40CB89502E2}     9      9\n3  E01006226    Wigan 035E {8A587355-7518-47EF-A60A-6CB117F54F05}     8      8\n4  E01006227    Wigan 038A {CC387BCB-5B3B-4E57-ABA3-4ADB3175D624}     8      8\n5  E01006264    Wigan 036D {89C9660D-5EC9-4498-BEBF-BED018377F41}    10     10\n6  E01006346    Wigan 038E {37DD7E6B-F345-400F-BD76-D8700BFCE534}     7      7\n7  E01006348    Wigan 039E {A24ED8C9-78AC-4C8C-8E32-45135C82072B}    10     10\n8  E01006366    Wigan 018E {3CF75243-6530-41F4-81F5-12B8F9C9FD73}     7      7\n9  E01006368    Wigan 018G {02EA8DCD-7F22-4B80-A9D2-C16E346F6AB4}     9      9\n10 E01006412 Knowsley 006A {F20DE2BD-17F4-4CAC-B81D-DDCD2335AD32}     1      1\n        Top  Bottom.                           geom\n1  17.47911 42.96657 MULTIPOLYGON (((359466.9 39...\n2  39.40579 27.52150 MULTIPOLYGON (((357307.6 39...\n3  29.37013 36.02265 MULTIPOLYGON (((358079.4 39...\n4  27.95950 37.14953 MULTIPOLYGON (((359464.7 39...\n5  38.51224 26.55367 MULTIPOLYGON (((356600.3 39...\n6  28.96305 36.88915 MULTIPOLYGON (((359555.1 39...\n7  45.76905 19.96260 MULTIPOLYGON (((359656.1 39...\n8  35.56405 29.57298 MULTIPOLYGON (((352147.5 40...\n9  35.92737 26.32944 MULTIPOLYGON (((353739.3 40...\n10 11.05569 42.80964 POLYGON ((342810.5 394193.3...\n\n\nReprojecting boundaries\nWe often work with multiple shapefiles in one project and these shapefiles can have boundaries in different projections. As such, they need to be harmonised before they can be integrated in analysis. We show how this process can be conducted.\nThe first step is to decide the Coordinate Reference Systems (CRS) for the data to be projected. In this example, we use the World Geodetic System 1984 (i.e. EPSG:4326).\n\n# set crs\ncrs_default = \"EPSG:4326\"\n\n\n# change crs\nrepro_simple_sdf &lt;- simple_sdf %&gt;% \n  st_transform(crs_default) \n\nrepro_simple_sdf\n\nSimple feature collection with 1043 features and 7 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -3.22874 ymin: 53.28929 xmax: -2.576743 ymax: 53.69821\nGeodetic CRS:  WGS 84\nFirst 10 features:\n    LSOA21CD      LSOA21NM                               GlobalID Rank. Decile\n1  E01006220    Wigan 035A {6A968831-6B5B-42A7-AFDE-9A2FD2E01FE2}     5      5\n2  E01006225    Wigan 036B {0727B328-8FBD-4074-A887-A40CB89502E2}     9      9\n3  E01006226    Wigan 035E {8A587355-7518-47EF-A60A-6CB117F54F05}     8      8\n4  E01006227    Wigan 038A {CC387BCB-5B3B-4E57-ABA3-4ADB3175D624}     8      8\n5  E01006264    Wigan 036D {89C9660D-5EC9-4498-BEBF-BED018377F41}    10     10\n6  E01006346    Wigan 038E {37DD7E6B-F345-400F-BD76-D8700BFCE534}     7      7\n7  E01006348    Wigan 039E {A24ED8C9-78AC-4C8C-8E32-45135C82072B}    10     10\n8  E01006366    Wigan 018E {3CF75243-6530-41F4-81F5-12B8F9C9FD73}     7      7\n9  E01006368    Wigan 018G {02EA8DCD-7F22-4B80-A9D2-C16E346F6AB4}     9      9\n10 E01006412 Knowsley 006A {F20DE2BD-17F4-4CAC-B81D-DDCD2335AD32}     1      1\n        Top  Bottom.                           geom\n1  17.47911 42.96657 MULTIPOLYGON (((-2.612213 5...\n2  39.40579 27.52150 MULTIPOLYGON (((-2.644766 5...\n3  29.37013 36.02265 MULTIPOLYGON (((-2.633147 5...\n4  27.95950 37.14953 MULTIPOLYGON (((-2.612225 5...\n5  38.51224 26.55367 MULTIPOLYGON (((-2.655565 5...\n6  28.96305 36.88915 MULTIPOLYGON (((-2.610809 5...\n7  45.76905 19.96260 MULTIPOLYGON (((-2.609102 5...\n8  35.56405 29.57298 MULTIPOLYGON (((-2.723027 5...\n9  35.92737 26.32944 MULTIPOLYGON (((-2.698892 5...\n10 11.05569 42.80964 POLYGON ((-2.862428 53.4413...\n\n\nMapping\nWe can also quickly map spatial boundaries by using the R base function plot.\n\nplot(simple_sdf$geom)\n\n\n\n\n\n\n\n\nDuring the next session, we will explore more sophisticated ways of mapping spatial data using different packages and functions.\n\n\n\n\nAppelhans, Tim, Florian Detsch, Christoph Reudenbach, and Stefan Woellauer. 2022. Mapview: Interactive Viewing of Spatial Data in r. https://github.com/r-spatial/mapview.\n\n\nBaddeley, Adrian, Ege Rubak, and Rolf Turner. 2015. Spatial Point Patterns: Methodology and Applications with r. CRC press.\n\n\nBaddeley, Adrian, Rolf Turner, and Ege Rubak. 2022. Spatstat: Spatial Point Pattern Analysis, Model-Fitting, Simulation, Tests. http://spatstat.org/.\n\n\nBivand, Roger. 2022. Spdep: Spatial Dependence: Weighting Schemes, Statistics.\n\n\nBivand, Roger, and Gianfranco Piras. 2022. Spatialreg: Spatial Regression Analysis. https://CRAN.R-project.org/package=spatialreg.\n\n\nDunnington, Dewey, Edzer Pebesma, and Ege Rubak. 2023. S2: Spherical Geometry Operators Using the S2 Geometry Library. https://CRAN.R-project.org/package=s2.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2024. Geocomputation with r. Online. https://doi.org/10.1201/9780203730058.\n\n\nPebesma, Edzer. 2018. “Simple Features for R: Standardized Support for Spatial Vector Data.” The R Journal 10 (1): 439–46. https://doi.org/10.32614/RJ-2018-009.\n\n\n———. 2022a. Sf: Simple Features for r. https://CRAN.R-project.org/package=sf.\n\n\n———. 2022b. Stars: Spatiotemporal Arrays, Raster and Vector Data Cubes. https://CRAN.R-project.org/package=stars.\n\n\n———. 2023. Lwgeom: Bindings to Selected Liblwgeom Functions for Simple Features. https://github.com/r-spatial/lwgeom/.\n\n\nPebesma, Edzer J. 2004. “Multivariable Geostatistics in S: The Gstat Package.” Computers & Geosciences 30 (7): 683–91. https://doi.org/10.1016/j.cageo.2004.03.012.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With Applications in r. CRC Press.\n\n\nPebesma, Edzer, and Benedikt Graeler. 2022. Gstat: Spatial and Spatio-Temporal Geostatistical Modelling, Prediction and Simulation. https://github.com/r-spatial/gstat/.\n\n\nTennekes, Martijn. 2018. “tmap: Thematic Maps in R.” Journal of Statistical Software 84 (6): 1–39. https://doi.org/10.18637/jss.v084.i06.\n\n\n———. 2022. Tmap: Thematic Maps. https://github.com/r-tmap/tmap.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science. \" O’Reilly Media, Inc.\".\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2018. R Markdown. Chapman; Hall/CRC. https://doi.org/10.1201/9781138359444.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "02_data-visualisation.html",
    "href": "02_data-visualisation.html",
    "title": "2  Data Visualisation",
    "section": "",
    "text": "2.1 Learning objectives\nBy the end of today’s session you should be able to:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Visualisation</span>"
    ]
  },
  {
    "objectID": "02_data-visualisation.html#learning-objectives",
    "href": "02_data-visualisation.html#learning-objectives",
    "title": "2  Data Visualisation",
    "section": "",
    "text": "Produce static visualisations and maps using ggplot\nProduce more advanced static visualisations and maps, using advanced data wrangling techniques\nProduce interactive visualisations\nExplore reporting strategies for visualisation outputs",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Visualisation</span>"
    ]
  },
  {
    "objectID": "02_data-visualisation.html#data",
    "href": "02_data-visualisation.html#data",
    "title": "2  Data Visualisation",
    "section": "2.2 Data",
    "text": "2.2 Data\nFor today’s practical, we will be using a couple of different datasets.\nFirstly, we will be using data from the latest UK census - available from NOMIS. In particular, we will be looking at one specific census table; ‘Method of Travel to Work’, which describes the main method of transport people use to travel to work - e.g. by car, by bus, on foot etc.\nFor today’s, we will be using the table of data that is available for Lower Super Output Areas (LSOAs). Let’s go ahead and read the table of data in:\n\n## Read in the ts061 (LSOAs)\nts061 &lt;- read.csv(\"data/census2021-ts061-lsoa.csv\")\n\nLet’s have a look at some of the attributes in the data:\n\n## Examine attributes\nhead(ts061)\n\n  date                 geography geography.code\n1 2021       City of London 001A      E01000001\n2 2021       City of London 001B      E01000002\n3 2021       City of London 001C      E01000003\n4 2021       City of London 001E      E01000005\n5 2021 Barking and Dagenham 016A      E01000006\n6 2021 Barking and Dagenham 015A      E01000007\n  Method.of.travel.to.workplace..Total..All.usual.residents.aged.16.years.and.over.in.employment.the.week.before.the.census\n1                                                                                                                       866\n2                                                                                                                       881\n3                                                                                                                      1000\n4                                                                                                                       496\n5                                                                                                                       888\n6                                                                                                                      1385\n  Method.of.travel.to.workplace..Work.mainly.at.or.from.home\n1                                                        639\n2                                                        676\n3                                                        618\n4                                                        203\n5                                                        192\n6                                                        370\n  Method.of.travel.to.workplace..Underground..metro..light.rail..tram\n1                                                                  35\n2                                                                  31\n3                                                                  74\n4                                                                  69\n5                                                                 205\n6                                                                 358\n  Method.of.travel.to.workplace..Train\n1                                   17\n2                                   10\n3                                   21\n4                                   25\n5                                  104\n6                                  177\n  Method.of.travel.to.workplace..Bus..minibus.or.coach\n1                                                   13\n2                                                   15\n3                                                   26\n4                                                   44\n5                                                   60\n6                                                  117\n  Method.of.travel.to.workplace..Taxi\n1                                   4\n2                                   2\n3                                   4\n4                                   2\n5                                   1\n6                                   8\n  Method.of.travel.to.workplace..Motorcycle..scooter.or.moped\n1                                                           3\n2                                                           1\n3                                                           4\n4                                                           3\n5                                                           5\n6                                                           3\n  Method.of.travel.to.workplace..Driving.a.car.or.van\n1                                                  18\n2                                                  19\n3                                                  24\n4                                                  33\n5                                                 227\n6                                                 220\n  Method.of.travel.to.workplace..Passenger.in.a.car.or.van\n1                                                        0\n2                                                        3\n3                                                        7\n4                                                        1\n5                                                       10\n6                                                       21\n  Method.of.travel.to.workplace..Bicycle Method.of.travel.to.workplace..On.foot\n1                                     24                                    109\n2                                     25                                     92\n3                                     62                                    143\n4                                     18                                     90\n5                                      6                                     61\n6                                     21                                     71\n  Method.of.travel.to.workplace..Other.method.of.travel.to.work\n1                                                             4\n2                                                             7\n3                                                            17\n4                                                             8\n5                                                            17\n6                                                            19\n\n\nBefore we start working with this data, we are going to tidy it up slightly. As you can probably see, the column names are long and messy, and the values in each column are raw counts, instead of percentages.\nMy preferred approach to tidying up data or ‘data wrangling’ is to use the ‘tidyverse’ suite of packages. One of the real benefits of tidyverse are tools called ‘pipes’ (%&gt;%), which are used to emphasise a sequence of actions, linking a series of different data cleaning steps into one nice block of code.\nIn the example below I show how you can use pipes to select some desired columns (by name), rename them, and then convert one a percentage.\n\n## An example of data wrangling with pipes\nexample &lt;- ts061 %&gt;%\n  select(geography.code,\n         Method.of.travel.to.workplace..Total..All.usual.residents.aged.16.years.and.over.in.employment.the.week.before.the.census,\n         Method.of.travel.to.workplace..Work.mainly.at.or.from.home) %&gt;% ## SELECT is used to select specific columns\n  rename(LSOA21CD = geography.code,\n         total = Method.of.travel.to.workplace..Total..All.usual.residents.aged.16.years.and.over.in.employment.the.week.before.the.census,\n         work_from_home = Method.of.travel.to.workplace..Work.mainly.at.or.from.home) %&gt;% ## RENAME is used to rename columns individually\n  mutate(pctWFH = (work_from_home / total) * 100) ## MUTATE is used to create new columns, or modify existing ones \n\n## Inspect\nhead(example)\n\n   LSOA21CD total work_from_home   pctWFH\n1 E01000001   866            639 73.78753\n2 E01000002   881            676 76.73099\n3 E01000003  1000            618 61.80000\n4 E01000005   496            203 40.92742\n5 E01000006   888            192 21.62162\n6 E01000007  1385            370 26.71480\n\n\nOk, so that’s just one example of some steps you might take to tidy up a raw dataset from NOMIS into something a little bit more user friendly. There are lots of additional ‘data wrangling’ steps you might take as an analyst, some of which we will come onto later on, but for now we just need to apply these techniques to ts061 to get it ready for today’s practical, as below.\nIn the code block below, I am going to select columns by index rather than name, which works much better when you have a lot more columns. I am also going to apply the setNames() function to set all column names at once:\n\n## Tidy up ts061\nts061_clean &lt;- ts061 %&gt;%\n  select(3:15) %&gt;% ## selects all columns between index 3 and 15\n  setNames(c(\"LSOA21CD\", \"total\", \"work_from_home\", \"underground_metro\", \"train\", \"bus_minibus_coach\", \n             \"taxi\", \"motorcycle\", \"car_driving\", \"car_passenger\", \"bicycle\", \"foot\", \"other\")) %&gt;% ## applies new column names to those columns\n  mutate(work_from_home = (work_from_home / total) * 100, underground_metro = (underground_metro / total) * 100,\n         train = (train / total) * 100, bus_minibus_coach = (bus_minibus_coach / total) * 100,\n         taxi = (taxi / total) * 100, motorcycle = (motorcycle / total) * 100, \n         car_driving = (car_driving / total) * 100, car_passenger = (car_passenger / total) * 100,\n         bicycle = (bicycle / total) * 100, foot = (foot / total) * 100, other = (other / total) * 100)\n\n## Inspect\nhead(ts061_clean)\n\n   LSOA21CD total work_from_home underground_metro     train bus_minibus_coach\n1 E01000001   866       73.78753          4.041570  1.963048          1.501155\n2 E01000002   881       76.73099          3.518729  1.135074          1.702611\n3 E01000003  1000       61.80000          7.400000  2.100000          2.600000\n4 E01000005   496       40.92742         13.911290  5.040323          8.870968\n5 E01000006   888       21.62162         23.085586 11.711712          6.756757\n6 E01000007  1385       26.71480         25.848375 12.779783          8.447653\n       taxi motorcycle car_driving car_passenger   bicycle      foot     other\n1 0.4618938  0.3464203    2.078522     0.0000000 2.7713626 12.586605 0.4618938\n2 0.2270148  0.1135074    2.156640     0.3405221 2.8376844 10.442679 0.7945516\n3 0.4000000  0.4000000    2.400000     0.7000000 6.2000000 14.300000 1.7000000\n4 0.4032258  0.6048387    6.653226     0.2016129 3.6290323 18.145161 1.6129032\n5 0.1126126  0.5630631   25.563063     1.1261261 0.6756757  6.869369 1.9144144\n6 0.5776173  0.2166065   15.884477     1.5162455 1.5162455  5.126354 1.3718412\n\n\nSo now we have a nice tidy table, where each variable is now a percentage. The final step is to add some additional geographies to the table - in this case we will append on the corresponding Local Authority District for each LSOA.\nThe Open Geography Portal is a great place to find lookup tables for any administrative datasets in the UK. The specific table we have given you provides a lookup between Output Areas (OAs), Lower Super Output Areas (LSOAs), Middle Super Output Areas (MSOAs), Local Enterprise Partnerships (LEPs) and Local Authority Districts (LADs). Let’s read in the lookup table:\n\n## Read in the lookup table\nlookup &lt;- read.csv(\"data/OAs_to_LSOAs_to_MSOAs_to_LEP_to_LAD_(May_2022)_Lookup_in_England.csv\")\n\n## Have a look at the data\nhead(lookup)\n\n     OA21CD  LSOA21CD        LSOA21NM  MSOA21CD       MSOA21NM  LEP21CD1\n1 E00060358 E01011968 Hartlepool 014D E02006909 Hartlepool 014 E37000034\n2 E00060359 E01011968 Hartlepool 014D E02006909 Hartlepool 014 E37000034\n3 E00060360 E01011968 Hartlepool 014D E02006909 Hartlepool 014 E37000034\n4 E00060361 E01011968 Hartlepool 014D E02006909 Hartlepool 014 E37000034\n5 E00060362 E01011970 Hartlepool 001C E02002483 Hartlepool 001 E37000034\n6 E00060363 E01011970 Hartlepool 001C E02002483 Hartlepool 001 E37000034\n     LEP21NM1 LEP21CD2 LEP21NM2   LAD22CD    LAD22NM ObjectId\n1 Tees Valley                   E06000001 Hartlepool        1\n2 Tees Valley                   E06000001 Hartlepool        2\n3 Tees Valley                   E06000001 Hartlepool        3\n4 Tees Valley                   E06000001 Hartlepool        4\n5 Tees Valley                   E06000001 Hartlepool        5\n6 Tees Valley                   E06000001 Hartlepool        6\n\n\nLookup tables often contain more information than you actually need. For example, the one above is structured so that every row is an Output Area (e.g., E00060361), and then the various columns link to other geographies - LSOA, LEP, LAD etc. What we are interested in doing is joining the LSOA-level census data from earlier, with the LAD-specific columns in the lookup table. So, we need to do a couple of things to the lookup table:\n\n## Tidy up the lookup\nlookup_clean &lt;- lookup %&gt;%\n  select(LSOA21CD, LAD22CD, LAD22NM) %&gt;% ## select the LSOA and LAD columns\n  distinct() ## keeps only unique values, i.e., dropping all the additional rows for Output Areas\n\n## Look at the dataset\nhead(lookup_clean)\n\n   LSOA21CD   LAD22CD    LAD22NM\n1 E01011968 E06000001 Hartlepool\n2 E01011970 E06000001 Hartlepool\n3 E01011969 E06000001 Hartlepool\n4 E01011971 E06000001 Hartlepool\n5 E01033465 E06000001 Hartlepool\n6 E01033467 E06000001 Hartlepool\n\n\nThe final step is to attach the Local Authority variables (LAD22CD, LAD22NM) to our main dataset. This can be done in a number of ways, but I have a personal preference for integrating these kind of joins within pipes (as we have done so far).\n\n## Attach the LAD variables to the main dataset\ndb &lt;- ts061_clean %&gt;%\n  inner_join(lookup_clean, by = \"LSOA21CD\")\n\n## Look at the new attributes\ncolnames(db)\n\n [1] \"LSOA21CD\"          \"total\"             \"work_from_home\"   \n [4] \"underground_metro\" \"train\"             \"bus_minibus_coach\"\n [7] \"taxi\"              \"motorcycle\"        \"car_driving\"      \n[10] \"car_passenger\"     \"bicycle\"           \"foot\"             \n[13] \"other\"             \"LAD22CD\"           \"LAD22NM\"          \n\n\nOk, so we have a nice data set that is cleaned and ready for use in today’s practical.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Visualisation</span>"
    ]
  },
  {
    "objectID": "02_data-visualisation.html#static-data-visualisation-basic",
    "href": "02_data-visualisation.html#static-data-visualisation-basic",
    "title": "2  Data Visualisation",
    "section": "2.3 Static data visualisation (basic)",
    "text": "2.3 Static data visualisation (basic)\nFor most of today’s practical, we are going to be using the ggplot2 package to learn how to create nice visualisations in R. It is a really awesome package, has really excellent documentation and the quality of graphics it can produce is (arguably) second-to-none.\nHOWEVER…. Lot’s of people say that ggplot is a tricky syntax to get used to, as it requires a more ‘programmatic’ style of coding (e.g. piping), instead of line-by-line.\n\n2.3.1 The ‘grammar of graphics’\nBefore getting stuck into ggplot, there are a couple of key fundamentals that you need to learn, which comprise something called the ‘grammar of graphics’ The first relates to specifying the specific dataset that you are using to create a plot - it is very easy to do this:\n\n## Specify db as our source of data\nggplot(data = db)\n\n\n\n\n\n\n\n\nAs you can see, ggplot has opened a blank canvas which is going to rely on data from the ‘db’ object to create some form of visualisation.\nThe next fundamental relates to how the information from that source of data is going to be represented, which relies on use of ggplot’s mapping argument - aes(). With this argument, you are able to identify how different variables from your dataset can be visually represented.\nSo for example, let’s say we are interested in looking at the association between two variables in our dataset, plotting one on each axis:\n\n## Set some ggplot aesthetics\nggplot(data = db, aes(x = work_from_home, y = car_driving)) \n\n\n\n\n\n\n\n\nGgplot has now established that those are the two variables you wish to create your visualisation around, and has added axis’ that reflect the underlying distribution of these variables. The final fundamental stage is to introduce ‘geoms’ to our existing plot. Geoms are different types of objects that are used to represent data, including points, bars, lines etc. etc. We will explore lots of these today, but for now, let’s just consider plotting a scatter between the two variables in the plot above.\n\n## Add your first geom\nggplot(data = db, aes(x = work_from_home, y = car_driving)) +\n  geom_point()\n\n\n\n\n\n\n\n\nExcellent! Your first ggplot visualisation is now ready. It doesn’t look the best (right now), but hopefully you have a good understanding of those three fundamental concepts when using ggplot for plotting. So to recap, for every ggplot visualisation you need to be clear on:\n\nWhich dataset is being used to generate the visualisation\nHow you are going to map your variables to generate plot aesthetics (aes)\nThe specific type of geom that you want to use\n\nBefore we move on to exploring other types of data visualisation, let’s think about how we can make this plot better, by changing some of the default options.\n\n## Change some point parameters - size and transparency \nggplot(data = db, aes(x = work_from_home, y = car_driving)) +\n  geom_point(alpha = 0.3, size = 0.35) ## alpha is used to change the transparency of points\n\n\n\n\n\n\n\n\n\n## Add a trend line\nggplot(data = db, aes(x = work_from_home, y = car_driving)) +\n  geom_point(alpha = 0.3, size = 0.35) +\n  geom_smooth(method = \"lm\") ## geom_smooth is used to add an overall trend line to a plot\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n## Change axis titles\nggplot(data = db, aes(x = work_from_home, y = car_driving)) +\n  geom_point(alpha = 0.3, size = 0.35) +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Population who work from home (%)\", y = \"Population who drive to work (%)\") ## change the x and y axis labels\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFor official reporting and academic publications, it is also important cite the data source used to generate the output, which can be done nicely with a caption in the labs() command:\n\n## Cite the data source\nggplot(data = db, aes(x = work_from_home, y = car_driving)) +\n  geom_point(alpha = 0.3, size = 0.35) +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Population who work from home (%)\", y = \"Population who drive to work (%)\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") ## set a caption for the plot\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe final tweak you might make to a plot like this is to change the plot theme. Ggplot has a number of themes that can be selected to change the general appearance of a plot. Here is one example:\n\n## Change the plot theme\nggplot(data = db, aes(x = work_from_home, y = car_driving)) +\n  geom_point(alpha = 0.3, size = 0.35) +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Population who work from home (%)\", y = \"Population who drive to work (%)\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_bw() ## sets a theme to the plot\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n2.3.2 Independent exercise - Over to you!\nHave a go at making some other modifications to the plot above:\n\nChange the variables that are being plotted on the x and y axis, to look at associations between different modes of travel.\nExplore different themes, and see which one you like most.\n(optional) See if you can figure out how to scale the x and y axis to be between 0 and 100, using the xlim() and ylim() commands.\n\n\n## Patrick's attempt\nggplot(data = db, aes(x = work_from_home, y = car_driving)) +\n  geom_point(alpha = 0.3, size = 0.35) +\n  geom_smooth(method = \"lm\") +\n  xlim(0, 100) +\n  ylim(0, 100) +\n  labs(x = \"Population who work from home (%)\", y = \"Population who drive to work (%)\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n2.3.3 Other static visualisations\nNow that you have a good understanding of how to construct a basic scatter plot using ggplot, and how to change some of the parameters to make your plot more visually appealing, we are going to do a quick overview of some simple visualisation techniques and how to build these in ggplot.\nFirstly, let’s have a look at building a histogram. NOTE: histograms are uni-dimensional, so you only need to set one variable in the aes() command:\n\n## Compute a histogram for one variable.\nggplot(data = db, aes(x = work_from_home)) +\n  geom_histogram(fill = \"orange\") +\n  labs(x = \"Population who work from home (%)\", y = \"Number of LSOAs\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nAlternatively, if you don’t like bar-style histograms, you can swap geom_histogram() for geom_density() to achieve a similar output:\n\n## Different style of histogram\nggplot(data = db, aes(x = work_from_home)) +\n  geom_density(fill = \"orange\") +\n  labs(x = \"Population who work from home (%)\", y = \"Number of LSOAs\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can also very easily plot a bar chart using ggplot. Let’s look at the distribution of LSOAs across LADs.\nBut first, let’s filter our dataset to only look at LSOAs within Liverpool City Region Combined Authority (LCRCA):\n\n## Filter to the six LADs that make up Liverpool City Region Combined Authority\ndb_lcr &lt;- db %&gt;%\n  filter(LAD22NM == \"Liverpool\" | LAD22NM == \"Wirral\" | LAD22NM == \"St. Helens\" | LAD22NM == \"Sefton\" | LAD22NM == \"Knowsley\" | LAD22NM == \"Halton\") ## filter allows you to filter specific values\n\n\n## Plot a bar chart\nggplot(data = db_lcr, aes(x = LAD22NM)) +\n  geom_bar(fill = \"orange\") +\n  labs(x = \"Local Authority District\", y = \"Number of LSOAs\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nBy default, when you have one variable on the x axis and call geom_bar(), ggplot will return a count of the number of rows in each x axis value.\nSometimes, it’s more useful to flip the axis on a plot, especially when you have a lot of categories:\n\n## Flip the axis\nggplot(data = db_lcr, aes(x = LAD22NM)) +\n  geom_bar(fill = \"orange\") +\n  labs(x = \"Local Authority District\", y = \"Number of LSOAs\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() +\n  coord_flip() ## this command swaps the x and y axis\n\n\n\n\n\n\n\n\nFinally, you might be interested in changing how the bars are ordered, going from lowest to highest values.\n\n## Reorder bar plot\nggplot(data = db_lcr, aes(x = fct_infreq(LAD22NM))) + ## Use the fct_infreq to reorder the x axis values\n  geom_bar(fill = \"orange\") +\n  labs(x = \"Local Authority District\", y = \"Number of LSOAs\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() +\n  coord_flip()\n\n\n\n\n\n\n\n\nOr from highest to lowest:\n\n## Reorder bar plot\nggplot(data = db_lcr, aes(x = fct_rev(fct_infreq(LAD22NM)))) + ## Use the fct_rev() and fct_infreq() commands to reorder the x axis values\n  geom_bar(fill = \"orange\") +\n  labs(x = \"Local Authority District\", y = \"Number of LSOAs\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() +\n  coord_flip()\n\n\n\n\n\n\n\n\nWhat if we wanted to look at the underlying distribution of different commuting methods across the LADs? I really like dotplots as a visualisation technique, and published a paper using one recently.\nLet’s use a dotplot to look at the distribution of walking commuters across the six LADs:\n\n## Examine differences in people who walk to work\nggplot(data = db_lcr, aes(x = LAD22NM, y = foot)) +\n  geom_dotplot(binaxis = \"y\", stackdir = \"center\", stackratio = 0.5, dotsize = .3) +\n  labs(x = \"Local Authority District\", y = \"Population who walk to work(%)\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal()\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\n\n\n\nHowever, as you’re probably thinking, something more advanced might be needed to look at these differences. For example, if you calculated the average percentage of people who walk to work across the six LADs, what interesting story might that tell?\nWe will explore some of these ideas in the next part of the course, where I will show you how to reshape dataframes, and the importance of doing so for producing really powerful visualisations.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Visualisation</span>"
    ]
  },
  {
    "objectID": "02_data-visualisation.html#static-data-visualisation-advanced",
    "href": "02_data-visualisation.html#static-data-visualisation-advanced",
    "title": "2  Data Visualisation",
    "section": "2.4 Static data visualisation (advanced)",
    "text": "2.4 Static data visualisation (advanced)\nOk, so by now you should understand the basics of producing static visualisations with ggplot. Now, we are going to work towards building some better visualisations, which are not possible to achieve without learning more about reshaping data. If you are familar with pivot tables, its a similar concept!\nSo take our dataset for Liverpool City Region:\n\nhead(db_lcr)\n\n   LSOA21CD total work_from_home underground_metro     train bus_minibus_coach\n1 E01006412   570       11.22807         0.0000000 0.7017544         16.666667\n2 E01006413   524       12.59542         0.0000000 0.9541985         19.656489\n3 E01006414   481        9.97921         0.0000000 0.8316008         20.166320\n4 E01006415   956       18.93305         0.2092050 1.8828452          5.125523\n5 E01006416   588       15.47619         0.1700680 1.1904762          9.353741\n6 E01006417   529       16.82420         0.1890359 2.4574669          5.293006\n      taxi motorcycle car_driving car_passenger  bicycle      foot     other\n1 3.333333  0.3508772    47.71930     10.526316 2.982456  5.964912 0.5263158\n2 3.816794  0.5725191    45.61069      8.206107 1.145038  6.297710 1.1450382\n3 3.534304  0.4158004    47.19335      7.484407 1.663202  8.316008 0.4158004\n4 2.301255  0.3138075    53.97490      6.694561 1.987448  7.322176 1.2552301\n5 2.891156  0.0000000    43.87755      8.843537 4.081633 13.605442 0.5102041\n6 4.914934  0.0000000    47.63705      7.183365 3.024575 11.342155 1.1342155\n    LAD22CD  LAD22NM\n1 E08000011 Knowsley\n2 E08000011 Knowsley\n3 E08000011 Knowsley\n4 E08000011 Knowsley\n5 E08000011 Knowsley\n6 E08000011 Knowsley\n\n\nWe are interested in looking at average commuter behaviours between the six Local Authority Districts that make-up Liverpool City Region Combined Authority. To do so, I’m going to introduce two new commands - group_by() and summarise(). As an example, I’ll show you how to calculate the average percentage of people who walk to work in each LAD:\n\n## Calculate average walking to work in LADs\nwalk &lt;- db_lcr %&gt;%\n  select(LAD22NM, foot) %&gt;%\n  group_by(LAD22NM) %&gt;% ## tells R to calculate a different value for each LAD\n  summarise(foot = mean(foot)) ## tells R to calculate the average % of people who walk to work, per LAD\n\n## Look at the output\nwalk\n\n# A tibble: 6 × 2\n  LAD22NM     foot\n  &lt;chr&gt;      &lt;dbl&gt;\n1 Halton      7.74\n2 Knowsley    7.55\n3 Liverpool   9.82\n4 Sefton      7.21\n5 St. Helens  6.06\n6 Wirral      6.71\n\n\nThen we can produce an interesting visualisation that conveys this story:\n\n## Plot a bar chart\nggplot(data = walk, aes(x = fct_reorder(LAD22NM, -foot), y = foot)) + ## notice how I've set up the new column we calculated as the y axis value\n  geom_bar(stat = \"identity\", fill = \"orange\") + ## this is a slight bug - you need to tell R that each x axis value has it's own y axis value\n  labs(x = \"Local Authority District\", y = \"Population who walk to work (%)\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() \n\n\n\n\n\n\n\n\nNow let’s think about how we can look at differences in commuting patterns between all modes of transport. To do so, we need to calculate the average percentage of people using each mode of transport, in each LAD. Below I show how this can be done using the summarise_all() function, which can be applied when all columns are of the same data type:\n\n## Calculate average use of modes of transport between LADs\nlcr_avg &lt;- db_lcr %&gt;%\n  select(-c(LSOA21CD, total, LAD22CD)) %&gt;% ## first you'll need to drop columns that you don't need anymore\n  group_by(LAD22NM) %&gt;% ## calculates a value for every LAD\n  summarise_all(mean) ## calculates the mean value of every column, for every LAD\n\n## Look at the result\nhead(lcr_avg)\n\n# A tibble: 6 × 12\n  LAD22NM    work_from_home underground_metro train bus_minibus_coach  taxi\n  &lt;chr&gt;               &lt;dbl&gt;             &lt;dbl&gt; &lt;dbl&gt;             &lt;dbl&gt; &lt;dbl&gt;\n1 Halton               23.5            0.0407 0.778              3.68 0.891\n2 Knowsley             20.5            0.0734 2.52               7.29 2.08 \n3 Liverpool            25.4            0.256  2.40              11.4  1.82 \n4 Sefton               27.7            0.149  3.09               4.16 1.40 \n5 St. Helens           22.5            0.0369 1.12               3.75 1.16 \n6 Wirral               26.6            0.239  2.65               4.52 0.958\n# ℹ 6 more variables: motorcycle &lt;dbl&gt;, car_driving &lt;dbl&gt;, car_passenger &lt;dbl&gt;,\n#   bicycle &lt;dbl&gt;, foot &lt;dbl&gt;, other &lt;dbl&gt;\n\n\nNow we need to think about reshaping this dataset. Why?\nWell if you look at the code used to produce the bar plot seen above, you’ll notice you can only put one command for x and y in the aes() parameter. Thus, we need to reshape our data from wide to long, so that all the %s are within one neat column that can be specified as the y axis variable.\nDon’t worry if this doesn’t make too much sense. The more you practice ggplot, the more you will begin to understand why reshaping is an important part of the grammar of graphics:\n\n## Reshape the dataset from wide to long\nlcr_avg &lt;- lcr_avg %&gt;%\n  pivot_longer(!LAD22NM, names_to = \"variable\", values_to = \"avg_pct\") \n\n## Have a look at the output\nhead(lcr_avg)\n\n# A tibble: 6 × 3\n  LAD22NM variable          avg_pct\n  &lt;chr&gt;   &lt;chr&gt;               &lt;dbl&gt;\n1 Halton  work_from_home    23.5   \n2 Halton  underground_metro  0.0407\n3 Halton  train              0.778 \n4 Halton  bus_minibus_coach  3.68  \n5 Halton  taxi               0.891 \n6 Halton  motorcycle         0.410 \n\n\nOk, so now we have all the modes of transport in one column, and a corresponding column which details the % of people who use that mode of transport. Let’s explore some visualisation options here - firstly, a stacked bar chart. Notice the additional parameter set in the aes() command, which tells R to colour the bars by the different modes of transport.\n\n## Stacked bar chart\nggplot(data = lcr_avg, aes(x = LAD22NM, y = avg_pct, fill = variable)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Local Authority District\", y = \"(Average) Population (%)\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() \n\n\n\n\n\n\n\n\nThere are a few things you can do to change the legend title used to represent the different colours, firstly you can set a new legend title using the labs() command:\n\n## Change label\nggplot(data = lcr_avg, aes(x = LAD22NM, y = avg_pct, fill = variable)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Local Authority District\", y = \"(Average) Population (%)\", fill = \"Mode of Transport\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() \n\n\n\n\n\n\n\n\nSecond, you can remove it completely:\n\n## Remove label\nggplot(data = lcr_avg, aes(x = LAD22NM, y = avg_pct, fill = variable)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Local Authority District\", y = \"(Average) Population (%)\", fill = NULL,\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() \n\n\n\n\n\n\n\n\nOr reposition the labels to be at the bottom of the plot:\n\n## Change label\nggplot(data = lcr_avg, aes(x = LAD22NM, y = avg_pct, fill = variable)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Local Authority District\", y = \"(Average) Population (%)\", fill = NULL,\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nHowever, I think for something like average populations, it’s better to use an unstacked bar chart, which tells a much clearer story. Furthermore, I would probably swap what is being plotted on the axis, to make the plot even clearer, and flip the axis so you can see the different x axis labels.\n\n## Unstacked bar chart\nggplot(data = lcr_avg, aes(x = variable, y = avg_pct, fill = LAD22NM)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(x = \"Mode of Transport\", y = \"(Average) Population (%)\", fill = NULL,\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  coord_flip() +\n  theme_minimal() \n\n\n\n\n\n\n\n\n\n2.4.1 Independent exercise - Over to you!\nHave a go at the following:\n\nSee what changes if you ask the summarise_all() command above to calculate median instead of mean.\nHave a go at changing the colour palette used on the plot above, using the scale_fill_brewer() command. Have a look at the documentation for some help with this.\n\nSee if you can figure out how to generate a facet plot, where six individual plots are created, one per LAD, instead of applying different colours for each LAD. Have a look at this tutorial for some support with this.\n\nSOLUTION - EXERCISE 2\n\n## My solution\nggplot(data = lcr_avg, aes(x = variable, y = avg_pct, fill = LAD22NM)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  labs(x = \"Mode of Transport\", y = \"(Average) Population (%)\", fill = NULL,\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  coord_flip() +\n  theme_minimal() \n\n\n\n\n\n\n\n\nSOLUTION - EXERCISE 3\n\n## My solution\nggplot(data = lcr_avg, aes(x = variable, y = avg_pct)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  labs(x = \"Mode of Transport\", y = \"(Average) Population (%)\", fill = NULL,\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  coord_flip() +\n  facet_wrap(~ LAD22NM) +\n  theme_minimal() \n\n\n\n\n\n\n\n\n\n\n2.4.2 For the spatial peeps!\nFinally, before we move on to talk about interactive visualisations, I want to do a quick overview of how you can use R to make maps. There is a whole host of GIS functionality within the R ecosystem (see links below), but one of the nice things about R is that it also works really well as as a cartographic tool.\nLet’s return to our original dataset - LSOA level breakdown of different commuting patterns:\n\n## Inspect\nhead(db)\n\n   LSOA21CD total work_from_home underground_metro     train bus_minibus_coach\n1 E01000001   866       73.78753          4.041570  1.963048          1.501155\n2 E01000002   881       76.73099          3.518729  1.135074          1.702611\n3 E01000003  1000       61.80000          7.400000  2.100000          2.600000\n4 E01000005   496       40.92742         13.911290  5.040323          8.870968\n5 E01000006   888       21.62162         23.085586 11.711712          6.756757\n6 E01000007  1385       26.71480         25.848375 12.779783          8.447653\n       taxi motorcycle car_driving car_passenger   bicycle      foot     other\n1 0.4618938  0.3464203    2.078522     0.0000000 2.7713626 12.586605 0.4618938\n2 0.2270148  0.1135074    2.156640     0.3405221 2.8376844 10.442679 0.7945516\n3 0.4000000  0.4000000    2.400000     0.7000000 6.2000000 14.300000 1.7000000\n4 0.4032258  0.6048387    6.653226     0.2016129 3.6290323 18.145161 1.6129032\n5 0.1126126  0.5630631   25.563063     1.1261261 0.6756757  6.869369 1.9144144\n6 0.5776173  0.2166065   15.884477     1.5162455 1.5162455  5.126354 1.3718412\n    LAD22CD              LAD22NM\n1 E09000001       City of London\n2 E09000001       City of London\n3 E09000001       City of London\n4 E09000001       City of London\n5 E09000002 Barking and Dagenham\n6 E09000002 Barking and Dagenham\n\n\nWe are going to be producing an LSOA-level map for Liverpool City Region Combined Authority, so let’s filter the dataset to the six LADs in LCRCA:\n\n## Filter to LCRCA\nlsoa_lcr &lt;- db %&gt;%\n  filter(LAD22NM == \"Liverpool\" | LAD22NM == \"Wirral\" | LAD22NM == \"St. Helens\" | LAD22NM == \"Sefton\" | LAD22NM == \"Knowsley\" | LAD22NM == \"Halton\")\n\nNow we need a set of LSOA polygons to plot the map with. You covered spatial data formats briefly yesterday with Francisco, so this should be relatively familiar. We have provided a set of LSOAs for Liverpool, which you can read in as below:\n\n## Read in the LSOAs\nlsoa &lt;- st_read(\"data/LCR-LSOA.gpkg\")\n\nReading layer `LCR-LSOA' from data source \n  `/Users/franciscorowe/Dropbox/Francisco/Research/grants/2024/lcr_training/lcr-training/data/LCR-LSOA.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1043 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 318351.7 ymin: 377513.8 xmax: 361791.1 ymax: 422866.5\nProjected CRS: OSGB36 / British National Grid\n\n## Inspect\nhead(lsoa)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 356526.1 ymin: 397294.1 xmax: 359746.3 ymax: 399734.2\nProjected CRS: OSGB36 / British National Grid\n   LSOA21CD   LSOA21NM                               GlobalID Rank. Decile\n1 E01006220 Wigan 035A {6A968831-6B5B-42A7-AFDE-9A2FD2E01FE2}     5      5\n2 E01006225 Wigan 036B {0727B328-8FBD-4074-A887-A40CB89502E2}     9      9\n3 E01006226 Wigan 035E {8A587355-7518-47EF-A60A-6CB117F54F05}     8      8\n4 E01006227 Wigan 038A {CC387BCB-5B3B-4E57-ABA3-4ADB3175D624}     8      8\n5 E01006264 Wigan 036D {89C9660D-5EC9-4498-BEBF-BED018377F41}    10     10\n6 E01006346 Wigan 038E {37DD7E6B-F345-400F-BD76-D8700BFCE534}     7      7\n       Top  Bottom.                           geom\n1 17.47911 42.96657 MULTIPOLYGON (((359223.5 39...\n2 39.40579 27.52150 MULTIPOLYGON (((356696.7 39...\n3 29.37013 36.02265 MULTIPOLYGON (((358079.4 39...\n4 27.95950 37.14953 MULTIPOLYGON (((359464.4 39...\n5 38.51224 26.55367 MULTIPOLYGON (((356526.2 39...\n6 28.96305 36.88915 MULTIPOLYGON (((359465.7 39...\n\n\nThe ‘geom’ column is the most important here - this is what stores the spatial information needed to produce maps. Let’s just extract the LSOA code and the ‘geom’ column.\n\n## Tidy up\nlsoa &lt;- lsoa %&gt;%\n  select(LSOA21CD, geom)\n\nOk, final ‘boring’ step before getting to mapmaking is the joining of our census data with the polygons. As you can probably see from your environment, there is a mismatch between the number of rows in the ‘lsoa’ object and our ‘lsoa_lcr’ object which contains the census data. Thus, when we merge these two datasets together, we want it to return only those rows which match:\n\n## Merge census data with polygons\nlsoa &lt;- merge(lsoa, lsoa_lcr, by = \"LSOA21CD\", all.y = TRUE)\n\nNow we’re ready to make a map! Let’s return to some ggplot fundamentals - remember that you need to set the data, but this time ignore the aesthetics:\n\n## Set the data\nggplot(data = lsoa)\n\n\n\n\n\n\n\n\nNow, to plot a map using ggplot, you need to use a specific geom type that was built for mapping with - geom_sf(). Remember that the data type of our spatial data is called a ‘simple feature’ or ‘sf’:\n\nstr(lsoa)\n\nClasses 'sf' and 'data.frame':  1003 obs. of  16 variables:\n $ LSOA21CD         : chr  \"E01006412\" \"E01006413\" \"E01006414\" \"E01006415\" ...\n $ total            : int  570 524 481 956 588 529 547 755 1337 623 ...\n $ work_from_home   : num  11.23 12.6 9.98 18.93 15.48 ...\n $ underground_metro: num  0 0 0 0.209 0.17 ...\n $ train            : num  0.702 0.954 0.832 1.883 1.19 ...\n $ bus_minibus_coach: num  16.67 19.66 20.17 5.13 9.35 ...\n $ taxi             : num  3.33 3.82 3.53 2.3 2.89 ...\n $ motorcycle       : num  0.351 0.573 0.416 0.314 0 ...\n $ car_driving      : num  47.7 45.6 47.2 54 43.9 ...\n $ car_passenger    : num  10.53 8.21 7.48 6.69 8.84 ...\n $ bicycle          : num  2.98 1.15 1.66 1.99 4.08 ...\n $ foot             : num  5.96 6.3 8.32 7.32 13.61 ...\n $ other            : num  0.526 1.145 0.416 1.255 0.51 ...\n $ LAD22CD          : chr  \"E08000011\" \"E08000011\" \"E08000011\" \"E08000011\" ...\n $ LAD22NM          : chr  \"Knowsley\" \"Knowsley\" \"Knowsley\" \"Knowsley\" ...\n $ geometry         :sfc_MULTIPOLYGON of length 1003; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:407, 1:2] 342810 342810 342809 342808 342779 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:15] \"LSOA21CD\" \"total\" \"work_from_home\" \"underground_metro\" ...\n\n\nGeom_sf works really well with these types of data, so let’s add it to the code above and see what happens:\n\n## Add a polygon geom\nggplot(data = lsoa) +\n  geom_sf()\n\n\n\n\n\n\n\n\nNice! Almost there… now just to tweak the geom_sf command to enable colouring of the polygons based on values. In this example let’s focus on train usage. Notice how aes() is used directly in the geom_sf() command this time instead of in the ggplot() command.\n\n## Plot a choropleth map\nggplot(data = lsoa) +\n  geom_sf(aes(fill = train)) \n\n\n\n\n\n\n\n\nAwesome! Now let’s tweak some of the plotting parameters to make this much more effective:\n\n## Improve the map\nggplot(data = lsoa) +\n  geom_sf(aes(fill = train), color = NA) + ## color = NA removes the borders\n  scale_fill_viridis_c() + ## sets a different colour palette\n  labs(fill = \"Rail Commuters (%)\", caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") + ## some labels\n  theme_minimal()\n\n\n\n\n\n\n\n\nAwesome! You’ve made a really nice map using R with literally only a couple of lines of code. Take a look at Geocomputation with R if you are interested in learning more about how to use R to make maps, or as a GIS. The syntax for different spatial operations (spatial join, intersection etc.) is really intuitive!",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Visualisation</span>"
    ]
  },
  {
    "objectID": "02_data-visualisation.html#interactive-data-visualisation",
    "href": "02_data-visualisation.html#interactive-data-visualisation",
    "title": "2  Data Visualisation",
    "section": "2.5 Interactive data visualisation",
    "text": "2.5 Interactive data visualisation\nOk, so for the final part of today’s practical we are going to explore some options for producing interactive visualisations using R. By interactive we mean producing a visual representation of data that can be explored and analysed directly within the visualisation itself.\nWe will be focusing on two types of interactive visualisation:\n\nInteractive non-spatial - e.g. graphs, charts\nInteractive spatial - e.g. maps\n\n\n2.5.1 Interactive non-spatial visualisations\nThroughout today’s practical, we’ve constructed a large volume of static plots, like bar charts, histograms etc. If you want to turn any of these into something interactive, this is really easy! All you need to do is use ggplotly() function from the ‘plotly’ package, which converts an existing ggplot visualisation into something interactive.\nLet’s test it on one of our earlier plots - the unstacked bar chart.\n\n## Produce the static plot - note it needs to be saved as an object\np &lt;- ggplot(data = lcr_avg, aes(x = variable, y = avg_pct, fill = LAD22NM)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  labs(x = \"Mode of Transport\", y = \"(Average) Population (%)\", fill = NULL,\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  coord_flip() +\n  theme_minimal() \n\n## Produce the interactive version\nggplotly(p)\n\n\n\n\n\nHow easy was that!\nI think this works really well when you have quite a lot of information, and it’s difficult to unpack exactly the individual trends. A good example of this was the stacked bar chart we produced earlier:\n\n## Produce the stacked bar chart again\np2 &lt;- ggplot(data = lcr_avg, aes(x = LAD22NM, y = avg_pct, fill = variable)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Local Authority District\", y = \"(Average) Population (%)\", fill = NULL,\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() \n\n## Produce the interactive version\nggplotly(p2)\n\n\n\n\n\nThere are lots of ways you can use an interactive plot like this. One is to utilise the Quarto formats we have introduced in this course to produce reports, where you embed the interactive visualisation within the report.\nAlternatively, you can export the interactive chart to both .html and .png formats. To save as a .html file, you need the htmlwidgets package to be installed.\nLet’s export the stacked bar chart as a .html file:\n\n## First assign the interactive plot to a new object\ni &lt;- ggplotly(p2)\n\n## Save the file\nsaveWidget(i, file = \"figs/Stack.html\")\n\n\n\n2.5.2 Independent exercise - Over to you!\n\nSee if you can produce interactive versions of some of the other visualisations we have made today.\nCheck you know how to save these to .html files\n(optional) Start tweaking what appears in the pop-ups on the interactive visualisations - you need to think about what data is being displayed from the original data frame, and how you might modify the original data frame to make the pop ups better.\n\n\n\n2.5.3 Interactive spatial visualisations\nIf you want to turn the ggplot map we made earlier into something interactive, the easiest option is to actually use a different package - tmap. Tmap has a really nice hookup to leaflet, which makes it really easy to plot maps interactively.\nTo reproduce the map above in tmap, here’s the code:\n\n## Choropleth map in tmap\ntm_shape(lsoa) +\n  tm_fill(col = \"train\", title = \"Rail Commuters (%)\", palette = \"viridis\") +\n  tm_layout(frame = FALSE)\n\n\n\n\n\n\n\n\nTo make this interactive, you need to change the default plotting mode in tmap:\nReplot the map and see what happens:\n\n## Choropleth map in tmap (interactive)\ntm_shape(lsoa) +\n  tm_fill(col = \"train\", title = \"Rail Commuters (%)\", palette = \"viridis\", alpha = 0.7) + ## Lower the transparency, so you can see the basemap\n  tm_layout(frame = FALSE)\n\n\n\n\n\nTo save this interactive map to a .html file, you just need to save the interactive map as an object, and then run the tmap_save() command to export to a .html.\n\n## Save the map to an object\np3 &lt;- tm_shape(lsoa) +\n  tm_fill(col = \"train\", title = \"Rail Commuters (%)\", palette = \"viridis\", alpha = 0.7) + ## Lower the transparency, so you can see the basemap\n  tm_layout(frame = FALSE)\n\n## Save as a .html\ntmap_save(p3, \"figs/Map.html\")\n\nInteractive map saved to figs/Map.html\n\n\n\n\n2.5.4 Independent exercise - Over to you!\n\nHave a go at mapping different variables, by playing with the col() command in tmap.\nThink about what additional spatial information you might add to a map like this to tell a good story - chat to Patrick. Clue: how might data on transport infrastructure help to explain differences in public transport usage.\n(optional) Download another spatial dataset, and have a go at trying to produce a map with it.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Visualisation</span>"
    ]
  },
  {
    "objectID": "02_data-visualisation.html#additional-resources",
    "href": "02_data-visualisation.html#additional-resources",
    "title": "2  Data Visualisation",
    "section": "2.6 Additional resources",
    "text": "2.6 Additional resources\nAs I said at the beginning of the practical, ggplot really benefits from a great community which contributes lots of documentation and examples about how to use ggplot for different applications.\nA really cool resource is this - Top 50 ggplot2 visualisations. It has lots of examples of different visualisation techniques that ggplot can be used for.\nThis book is really awesome too - R for Data Science. It was written by Hadley Wickham, who introduced ggplot and the tidyverse to the R world.\nIf interested in using R as a GIS, this free online book is excellent - Geocomputation with R.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data Visualisation</span>"
    ]
  },
  {
    "objectID": "03_dashboards-api.html",
    "href": "03_dashboards-api.html",
    "title": "3  Dashboards and APIs",
    "section": "",
    "text": "3.1 Learning Objectives\nBy the end of today’s session you should be able to:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dashboards and APIs</span>"
    ]
  },
  {
    "objectID": "03_dashboards-api.html#learning-objectives",
    "href": "03_dashboards-api.html#learning-objectives",
    "title": "3  Dashboards and APIs",
    "section": "",
    "text": "Understand the basic principles of APIs\nDownload and visualise data from NOMIS using the NOMIS API\nUnderstand the basic principles of flexdashboard\nBuild a basic dashboard using flexdashboard",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dashboards and APIs</span>"
    ]
  },
  {
    "objectID": "03_dashboards-api.html#introduction-to-apis",
    "href": "03_dashboards-api.html#introduction-to-apis",
    "title": "3  Dashboards and APIs",
    "section": "3.2 Introduction to APIs",
    "text": "3.2 Introduction to APIs\nWeb services make their data easily accessible to computer programs like R through use of an Application Programming Interface (API). Today’s practical will teach you how to access data from APIs, and load them into your R environment for analysis.\nTo download data from an API you need to send a HTTP request to a server, which tells the server to return the specific parcel of data that matches the criteria in the HTTP request.\nFor example, on NOMIS there is a page called ‘Census 2021 Bulk Data Download’, which contains .zip files for different tables of data available from the latest census.\nNow you should go to the ‘Census 2021 Bulk Data Download’ page, and see what it contains.\n\n\n\nNOMIS\n\n\nThere are lots of files on the web page - e.g. census2021-ts001.zip, census2021-ts007a.zip.\nYou can click on these files individually, download them to your PC, unzip them and read them into R. Alternatively, we can programmatically download the data directly from the webpage. If you ‘right click’ on one of the .zip files and press ‘copy link’, you will have a URL which can access that specific .zip file, as below:\n\nurl &lt;- \"https://www.nomisweb.co.uk/output/census/2021/census2021-ts061.zip\"\nurl\n\n[1] \"https://www.nomisweb.co.uk/output/census/2021/census2021-ts061.zip\"\n\n\nThe specific URL above relates to table TS061 - “Method of Travel to Work”, which is the same dataset we have been using throughout this course.\nNow I’m going to show you how to download the .zip file, and read in the file of data we used yesterday. This is a really basic example of using an API, which shows how you can download data from NOMIS into your environment, without having to physically go and download it, save it to a folder, unzip it and read it into memory.\nFirst, let’s download the .zip file - this line of code downloads the .zip file to your local machine. It creates a new file in your working directory called ‘temp.zip’ - go and take a look!\n\n## Download the .zip file, using the url set above\ndownload.file(url, \"temp.zip\")\n\nNext we need to unzip the folder, to get to the datasets stored within:\n\n## First set where you want the unzipped files to be stored\noutDir &lt;- \"data/unzip\"\n## Unzip the folder to the data/unzip folder\nunzip(\"temp.zip\", exdir = outDir)\n\nOk so now that you’ve downloaded the files to your local machine, we can look and see what files are available to us:\n\n## Use list.files() to see what we unzipped\nlist.files(\"data/unzip\")\n\n[1] \"census2021-ts061-ctry.csv\" \"census2021-ts061-lsoa.csv\"\n[3] \"census2021-ts061-ltla.csv\" \"census2021-ts061-msoa.csv\"\n[5] \"census2021-ts061-oa.csv\"   \"census2021-ts061-rgn.csv\" \n[7] \"census2021-ts061-utla.csv\" \"metadata\"                 \n\n\nThankfully, NOMIS use a really standard naming protocol for their files, which makes it really easy to tell what each of the files contains. If you cast your mind back to yesterday, we used a file called “census2021-ts061-lsoa.csv”, which we provided to you as part of the course materials. However, as you can see from the code above, you have now programmatically downloaded the same file, which we can read in:\n\n## Read in the LSOA census data\ndb &lt;- read.csv(\"data/unzip/census2021-ts061-lsoa.csv\")\n\n\n3.2.1 Independent exercise - Over to you! (15 - 20 mins)\n\nAs a recap, see if you can reproduce one of the visualisations we produced yesterday using the data we have just scraped from the API.\nTest downloading two more datasets from NOMIS, by swapping in new URLs, and reading in one of the files from the folder you download.\n(optional) Produce an interesting visualisation from that new dataset.\n\nSolution 2\n\n## Set the new URL\nurl2 &lt;- \"https://www.nomisweb.co.uk/output/census/2021/census2021-ts066.zip\"\n\n## Download the files\ndownload.file(url2, \"temp2.zip\")\n\n## Unzip the files\noutDir2 &lt;- \"data/unzip2\"\n## Unzip the folder to the data/unzip folder\nunzip(\"temp2.zip\", exdir = outDir2)\n\n## Read in the LSOA census data\ndb2 &lt;- read.csv(\"data/unzip2/census2021-ts066-lsoa.csv\")\n\n## Select some columns to work with, and calculate % student\ndb2_clean &lt;- db2 %&gt;%\n  select(geography.code, Economic.activity.status..Total..All.usual.residents.aged.16.years.and.over, Economic.activity.status..Economically.inactive..Student) %&gt;%\n  setNames(c(\"LSOA21CD\", \"total\", \"student\")) %&gt;%\n  mutate(student = (student / total) * 100)\n\nSolution 3\n\n## Produce a histogram\nggplot(data = db2_clean, aes(x = student)) +\n  geom_density(fill = \"orange\") +\n  labs(x = \"Population who are students (%)\", y = \"Number of LSOAs\",\n       caption = \"Data: UK Census (2021) - 'Economic Activity Status' (ts066)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nSo what have we achieved?\n\nYou can now programmatically download datasets from the NOMIS bulk census page, without needing to download the files.\nYou can produce visualisations using these different datasets.\nYou are in a position to automate download and visualisation of census data from NOMIS.\n\n\n\n3.2.2 Advanced Bulk Downloading\nBut what if you want to automate this download in a much quicker manner. The NOMIS API is a good way of doing this (and we’ll be discussing this shortly), but the other way you can do this is through the use of functions.\nFunctions are “self contained modules of code that accomplish a specific task”. They normally take data in soem form, perform a number of modifications to it, and then return some form of result.\nThe basic syntax of a function is as follows:\n\n## Specify a new function\nfunction1 &lt;- function(x) {\n  \n}\n\nThere are three important things to notice here:\n\nFunction name (e.g., function1) - enables you to call the function at a later point.\nObject (e.g., function(x)) - is the input data or parameter that you are going to be using.\nSteps (e.g., {}) - anything within the curly brackets will be a series of steps that are applied.\n\nSo a basic example is we can ask the function to return the first five rows of x:\n\n## Specify a new function - first five\nfirstfive &lt;- function(x) {\n  head(x)\n}\n\nNow you need to run the function on an object - let’s do it on our census dataset:\n\n## Apply the function\nfirstfive(db)\n\n  date                 geography geography.code\n1 2021       City of London 001A      E01000001\n2 2021       City of London 001B      E01000002\n3 2021       City of London 001C      E01000003\n4 2021       City of London 001E      E01000005\n5 2021 Barking and Dagenham 016A      E01000006\n6 2021 Barking and Dagenham 015A      E01000007\n  Method.of.travel.to.workplace..Total..All.usual.residents.aged.16.years.and.over.in.employment.the.week.before.the.census\n1                                                                                                                       866\n2                                                                                                                       881\n3                                                                                                                      1000\n4                                                                                                                       496\n5                                                                                                                       888\n6                                                                                                                      1385\n  Method.of.travel.to.workplace..Work.mainly.at.or.from.home\n1                                                        639\n2                                                        676\n3                                                        618\n4                                                        203\n5                                                        192\n6                                                        370\n  Method.of.travel.to.workplace..Underground..metro..light.rail..tram\n1                                                                  35\n2                                                                  31\n3                                                                  74\n4                                                                  69\n5                                                                 205\n6                                                                 358\n  Method.of.travel.to.workplace..Train\n1                                   17\n2                                   10\n3                                   21\n4                                   25\n5                                  104\n6                                  177\n  Method.of.travel.to.workplace..Bus..minibus.or.coach\n1                                                   13\n2                                                   15\n3                                                   26\n4                                                   44\n5                                                   60\n6                                                  117\n  Method.of.travel.to.workplace..Taxi\n1                                   4\n2                                   2\n3                                   4\n4                                   2\n5                                   1\n6                                   8\n  Method.of.travel.to.workplace..Motorcycle..scooter.or.moped\n1                                                           3\n2                                                           1\n3                                                           4\n4                                                           3\n5                                                           5\n6                                                           3\n  Method.of.travel.to.workplace..Driving.a.car.or.van\n1                                                  18\n2                                                  19\n3                                                  24\n4                                                  33\n5                                                 227\n6                                                 220\n  Method.of.travel.to.workplace..Passenger.in.a.car.or.van\n1                                                        0\n2                                                        3\n3                                                        7\n4                                                        1\n5                                                       10\n6                                                       21\n  Method.of.travel.to.workplace..Bicycle Method.of.travel.to.workplace..On.foot\n1                                     24                                    109\n2                                     25                                     92\n3                                     62                                    143\n4                                     18                                     90\n5                                      6                                     61\n6                                     21                                     71\n  Method.of.travel.to.workplace..Other.method.of.travel.to.work\n1                                                             4\n2                                                             7\n3                                                            17\n4                                                             8\n5                                                            17\n6                                                            19\n\n\nSo, that’s a really basic example of how to use a function.\nLet me show you how functions can be used to clean datasets programmatically:\n\n## Function cleans the raw census dataset\ncleandb &lt;- function(x) {\n  \n  ## Select columns\n  out &lt;- x %&gt;%\n    select(geography.code, \n           Method.of.travel.to.workplace..Total..All.usual.residents.aged.16.years.and.over.in.employment.the.week.before.the.census,\n           Method.of.travel.to.workplace..Train) %&gt;%\n    setNames(c(\"LSOA21CD\", \"total\", \"train\")) %&gt;%\n    mutate(pctTrain = (train / total) * 100)\n  \n  ## Return the new dataframe\n  return(out)\n  \n}\n\nNow that the function has been specified, you can pass your dataset through it:\n\n## Pass census data through the new function\ncleaned &lt;- cleandb(db)\n\n## Look at it\nhead(cleaned)\n\n   LSOA21CD total train  pctTrain\n1 E01000001   866    17  1.963048\n2 E01000002   881    10  1.135074\n3 E01000003  1000    21  2.100000\n4 E01000005   496    25  5.040323\n5 E01000006   888   104 11.711712\n6 E01000007  1385   177 12.779783\n\n\nThere are lots of reasons why this approach is useful:\n\nCan provide a standard set of code chunks to clean data from NOMIS, and other sources\nCan be looped across multiple different datasets\nCan be customised to perform different steps of cleaning that you need for your use case.\n\nHowever, perhaps the most useful thing functions can do, is be used to apply an API query and return a cleaned dataset for your use.\nLet’s have a look at an example: tidylodes.\n\n\n\ntidylodes\n\n\nWe can implement some of these techniques and ideas to automate scraping of data from NOMIS.\nFor example, take the URL we set above:\n\nurl\n\n[1] \"https://www.nomisweb.co.uk/output/census/2021/census2021-ts061.zip\"\n\n\nIf we wrote a function that could enable specification of a different table number, we could build a pipeline where you only have to change a couple of characters to return a cleaned dataset for your reports.\nFor example, the other URL I provided in my solution above:\n\nurl2\n\n[1] \"https://www.nomisweb.co.uk/output/census/2021/census2021-ts066.zip\"\n\n\nYou’ll notice the only difference with this URL is the ts066 string at the end of the URL. Let’s start building a function that can swap these different characters in and out:\n\ndownloadNOMIS &lt;- function(x = \"ts061\") {\n  \n  ## Create the URL, based on the character supplied in x\n  url &lt;- paste0(\"https://www.nomisweb.co.uk/output/census/2021/census2021-\", x, \".zip\")\n  return(url)\n}\n\nLet’s test this:\n\ndownloadNOMIS(\"ts061\")\n\n[1] \"https://www.nomisweb.co.uk/output/census/2021/census2021-ts061.zip\"\n\n\nAnd then with a different table number\n\ndownloadNOMIS(\"ts066\")\n\n[1] \"https://www.nomisweb.co.uk/output/census/2021/census2021-ts066.zip\"\n\n\nOk, so now we need to add to the function, to get R to download from the URL:\n\ndownloadNOMIS &lt;- function(x = \"ts061\") {\n  \n  ## Create the URL, based on the character supplied in x\n  url &lt;- paste0(\"https://www.nomisweb.co.uk/output/census/2021/census2021-\", x, \".zip\")\n  \n  ## Download\n  download.file(url, \"table.zip\")\n  \n}\n\nTest it:\n\ndownloadNOMIS(\"ts066\")\n\nNow if you go into your working directory, you should have a .zip folder called table.\nFinal steps: unzipping and checking all the files are there:\n\ndownloadNOMIS &lt;- function(x = \"ts061\") {\n  \n  ## Create the URL, based on the character supplied in x\n  url &lt;- paste0(\"https://www.nomisweb.co.uk/output/census/2021/census2021-\", x, \".zip\")\n  \n  ## Download\n  download.file(url, \"table.zip\")\n  \n  ## Unzip the files\n  outDir2 &lt;- \"data/tableUZ\"\n  ## Unzip the folder to the data/unzip folder\n  unzip(\"table.zip\", exdir = outDir2)\n\n}\n\nNow run the command for a table of your choosing:\n\ndownloadNOMIS(\"ts004\")\n\nYou can check this has worked by looking at the files available in the tableUZ folder, set up in the function above:\n\nlist.files(\"data/tableUZ\")\n\n [1] \"census2021-ts001-ctry.csv\"  \"census2021-ts001-lsoa.csv\" \n [3] \"census2021-ts001-ltla.csv\"  \"census2021-ts001-msoa.csv\" \n [5] \"census2021-ts001-oa.csv\"    \"census2021-ts001-rgn.csv\"  \n [7] \"census2021-ts001-utla.csv\"  \"census2021-ts002-ctry.csv\" \n [9] \"census2021-ts002-lsoa..csv\" \"census2021-ts002-ltla.csv\" \n[11] \"census2021-ts002-msoa..csv\" \"census2021-ts002-oa.csv\"   \n[13] \"census2021-ts002-rgn.csv\"   \"census2021-ts002-utla.csv\" \n[15] \"census2021-ts003-ctry.csv\"  \"census2021-ts003-lsoa.csv\" \n[17] \"census2021-ts003-ltla.csv\"  \"census2021-ts003-msoa.csv\" \n[19] \"census2021-ts003-oa.csv\"    \"census2021-ts003-rgn.csv\"  \n[21] \"census2021-ts003-utla.csv\"  \"census2021-ts004-ctry.csv\" \n[23] \"census2021-ts004-llta.csv\"  \"census2021-ts004-lsoa.csv\" \n[25] \"census2021-ts004-msoa.csv\"  \"census2021-ts004-oa.csv\"   \n[27] \"census2021-ts004-rgn.csv\"   \"census2021-ts004-ulta.csv\" \n[29] \"metadata\"                  \n\n\nAwesome! You have created a function that enables you to have access to tables of data from NOMIS very easily. Finally, you might be interested in asking the function to read in a specific file - you can do this easily from NOMIS as the file naming protocols are very organised.\n\ndownloadNOMIS &lt;- function(x = \"ts061\") {\n  \n  ## Create the URL, based on the character supplied in x\n  url &lt;- paste0(\"https://www.nomisweb.co.uk/output/census/2021/census2021-\", x, \".zip\")\n  \n  ## Download\n  download.file(url, \"table.zip\")\n  \n  ## Unzip the files\n  outDir2 &lt;- \"data/tableUZ\"\n  ## Unzip the folder to the data/unzip folder\n  unzip(\"table.zip\", exdir = outDir2)\n  \n  ## Read in the regional level data\n  db &lt;- read.csv(paste0(\"data/tableUZ/census2021-\", x, \"-rgn.csv\"))\n  return(db)\n}\n\nTest it\n\n## Download and read in\nt &lt;- downloadNOMIS(\"ts003\")\n\n## Inspect\nhead(t)\n\n  date                geography geography.code\n1 2021               North East      E12000001\n2 2021               North West      E12000002\n3 2021 Yorkshire and The Humber      E12000003\n4 2021            East Midlands      E12000004\n5 2021            West Midlands      E12000005\n6 2021                     East      E12000006\n  Household.composition..Total..measures..Value\n1                                       1175683\n2                                       3153406\n3                                       2330657\n4                                       2037334\n5                                       2429493\n6                                       2628778\n  Household.composition..One.person.household..measures..Value\n1                                                       395924\n2                                                      1014913\n3                                                       733558\n4                                                       597177\n5                                                       725807\n6                                                       759808\n  Household.composition..One.person.household..Aged.66.years.and.over..measures..Value\n1                                                                               167832\n2                                                                               420823\n3                                                                               309721\n4                                                                               264630\n5                                                                               318108\n6                                                                               347326\n  Household.composition..One.person.household..Other..measures..Value\n1                                                              228092\n2                                                              594090\n3                                                              423837\n4                                                              332547\n5                                                              407699\n6                                                              412482\n  Household.composition..Single.family.household..measures..Value\n1                                                          731124\n2                                                         1961888\n3                                                         1471340\n4                                                         1317959\n5                                                         1549864\n6                                                         1714480\n  Household.composition..Single.family.household..All.aged.66.years.and.over..measures..Value\n1                                                                                      112397\n2                                                                                      278671\n3                                                                                      221778\n4                                                                                      209388\n5                                                                                      231216\n6                                                                                      272511\n  Household.composition..Single.family.household..Married.or.civil.partnership.couple..measures..Value\n1                                                                                               331330\n2                                                                                               904487\n3                                                                                               687238\n4                                                                                               632498\n5                                                                                               741413\n6                                                                                               848252\n  Household.composition..Single.family.household..Married.or.civil.partnership.couple..No.children..measures..Value\n1                                                                                                            129507\n2                                                                                                            312295\n3                                                                                                            259341\n4                                                                                                            236710\n5                                                                                                            248508\n6                                                                                                            287375\n  Household.composition..Single.family.household..Married.or.civil.partnership.couple..Dependent.children..measures..Value\n1                                                                                                                   135625\n2                                                                                                                   412594\n3                                                                                                                   305595\n4                                                                                                                   280529\n5                                                                                                                   345254\n6                                                                                                                   406526\n  Household.composition..Single.family.household..Married.or.civil.partnership.couple..All.children.non.dependent..measures..Value\n1                                                                                                                            66198\n2                                                                                                                           179598\n3                                                                                                                           122302\n4                                                                                                                           115259\n5                                                                                                                           147651\n6                                                                                                                           154351\n  Household.composition..Single.family.household..Cohabiting.couple.family..measures..Value\n1                                                                                    137302\n2                                                                                    373006\n3                                                                                    291532\n4                                                                                    253787\n5                                                                                    272420\n6                                                                                    309554\n  Household.composition..Single.family.household..Cohabiting.couple.family..No.children..measures..Value\n1                                                                                                  70052\n2                                                                                                 192405\n3                                                                                                 153710\n4                                                                                                 134608\n5                                                                                                 137757\n6                                                                                                 164306\n  Household.composition..Single.family.household..Cohabiting.couple.family..With.dependent.children..measures..Value\n1                                                                                                              57542\n2                                                                                                             155174\n3                                                                                                             119334\n4                                                                                                             103354\n5                                                                                                             115766\n6                                                                                                             125253\n  Household.composition..Single.family.household..Cohabiting.couple.family..All.children.non.dependent..measures..Value\n1                                                                                                                  9708\n2                                                                                                                 25427\n3                                                                                                                 18488\n4                                                                                                                 15825\n5                                                                                                                 18897\n6                                                                                                                 19995\n  Household.composition..Single.family.household..Lone.parent.family..measures..Value\n1                                                                              143417\n2                                                                              382496\n3                                                                              256459\n4                                                                              209278\n5                                                                              287205\n6                                                                              268439\n  Household.composition..Single.family.household..Lone.parent.family..With.dependent.children..measures..Value\n1                                                                                                        94314\n2                                                                                                       241480\n3                                                                                                       168688\n4                                                                                                       132437\n5                                                                                                       180039\n6                                                                                                       166653\n  Household.composition..Single.family.household..Lone.parent.family..All.children.non.dependent..measures..Value\n1                                                                                                           49103\n2                                                                                                          141016\n3                                                                                                           87771\n4                                                                                                           76841\n5                                                                                                          107166\n6                                                                                                          101786\n  Household.composition..Single.family.household..Other.single.family.household..measures..Value\n1                                                                                           6678\n2                                                                                          23228\n3                                                                                          14333\n4                                                                                          13008\n5                                                                                          17610\n6                                                                                          15724\n  Household.composition..Single.family.household..Other.single.family.household..Other.family.composition..measures..Value\n1                                                                                                                     6678\n2                                                                                                                    23228\n3                                                                                                                    14333\n4                                                                                                                    13008\n5                                                                                                                    17610\n6                                                                                                                    15724\n  Household.composition..Other.household.types..measures..Value\n1                                                         48635\n2                                                        176605\n3                                                        125759\n4                                                        122198\n5                                                        153822\n6                                                        154490\n  Household.composition..Other.household.types..With.dependent.children..measures..Value\n1                                                                                  18689\n2                                                                                  73084\n3                                                                                  51557\n4                                                                                  49543\n5                                                                                  72712\n6                                                                                  63676\n  Household.composition..Other.household.types..Other..including.all.full.time.students.and.all.aged.66.years.and.over..measures..Value\n1                                                                                                                                 29946\n2                                                                                                                                103521\n3                                                                                                                                 74202\n4                                                                                                                                 72655\n5                                                                                                                                 81110\n6                                                                                                                                 90814\n\n\nThe final thing I want to show you before we move off of functions is how to apply functions sequentially. Functions can be applied to lists really easily using the lapply() command. This means you could supply multiple names of tables that you want, and get R to download, read and clean them for you using the techniques I have just shown you.\nFor example, take a list like this:\n\nls &lt;- c(\"ts001\", \"ts002\", \"ts003\")\nls\n\n[1] \"ts001\" \"ts002\" \"ts003\"\n\n\nWe can apply the downloadNOMIS function to these three tables, to read in the regional-level tables. The way to do this is to use the lapply command, which takes as arguments 1) a list and 2) a function to apply over the list.\nIn our case this would be:\n\n## Download three tables from NOMIS\ntables &lt;- lapply(ls, downloadNOMIS)\n\nOnce this has finished running, you are left with a list of tables, see:\n\nstr(tables)\n\nList of 3\n $ :'data.frame':   10 obs. of  6 variables:\n  ..$ date                                                              : int [1:10] 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021\n  ..$ geography                                                         : chr [1:10] \"North East\" \"North West\" \"Yorkshire and The Humber\" \"East Midlands\" ...\n  ..$ geography.code                                                    : chr [1:10] \"E12000001\" \"E12000002\" \"E12000003\" \"E12000004\" ...\n  ..$ Residence.type..Total..measures..Value                            : int [1:10] 2647013 7417397 5480774 4880054 5950757 6335074 8799728 9278065 5701186 3107494\n  ..$ Residence.type..Lives.in.a.household..measures..Value             : int [1:10] 2594828 7290560 5376740 4778018 5854512 6238659 8699834 9088552 5582599 3051549\n  ..$ Residence.type..Lives.in.a.communal.establishment..measures..Value: int [1:10] 52185 126837 104034 102036 96245 96415 99894 189513 118587 55945\n $ :'data.frame':   10 obs. of  21 variables:\n  ..$ date                                                                                                                                                                                       : int [1:10] 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021\n  ..$ geography                                                                                                                                                                                  : chr [1:10] \"North East\" \"North West\" \"Yorkshire and The Humber\" \"East Midlands\" ...\n  ..$ geography.code                                                                                                                                                                             : chr [1:10] \"E12000001\" \"E12000002\" \"E12000003\" \"E12000004\" ...\n  ..$ Marital.and.civil.partnership.status..Total..measures..Value                                                                                                                               : int [1:10] 2178960 6025636 4460298 3998045 4801329 5148282 7103985 7554580 4735840 2559415\n  ..$ Marital.and.civil.partnership.status..Never.married.and.never.registered.a.civil.partnership..measures..Value                                                                              : int [1:10] 829791 2372877 1679861 1442049 1781208 1791650 3282327 2628945 1641415 951656\n  ..$ Marital.and.civil.partnership.status..Married.or.in.a.registered.civil.partnership..measures..Value                                                                                        : int [1:10] 937083 2575107 1971162 1832929 2172973 2429227 2843230 3596697 2203234 1121459\n  ..$ Marital.and.civil.partnership.status..Married.or.in.a.registered.civil.partnership..Married..measures..Value                                                                               : int [1:10] 933521 2565016 1962879 1825699 2164831 2419645 2819968 3579942 2192574 1116418\n  ..$ Marital.and.civil.partnership.status..Married.or.in.a.registered.civil.partnership..Married..Opposite.sex..measures..Value                                                                 : int [1:10] 928213 2548818 1951385 1815824 2153949 2407966 2793106 3557428 2179876 1109656\n  ..$ Marital.and.civil.partnership.status..Married.or.in.a.registered.civil.partnership..Married..Same.sex..measures..Value                                                                     : int [1:10] 5308 16198 11494 9875 10882 11679 26862 22514 12698 6762\n  ..$ Marital.and.civil.partnership.status..Married.or.in.a.registered.civil.partnership..In.a.registered.civil.partnership..measures..Value                                                     : int [1:10] 3562 10091 8283 7230 8142 9582 23262 16755 10660 5041\n  ..$ Marital.and.civil.partnership.status..Married.or.in.a.registered.civil.partnership..In.a.registered.civil.partnership..Opposite.sex..measures..Value                                       : int [1:10] 1312 3408 2975 2704 3304 3470 7946 5419 3528 1730\n  ..$ Marital.and.civil.partnership.status..Married.or.in.a.registered.civil.partnership..In.a.registered.civil.partnership..Same.sex..measures..Value                                           : int [1:10] 2250 6683 5308 4526 4838 6112 15316 11336 7132 3311\n  ..$ Marital.and.civil.partnership.status..Separated..but.still.legally.married.or.still.legally.in.a.civil.partnership..measures..Value                                                        : int [1:10] 54358 136428 102350 88980 110711 113455 165884 161395 99960 52468\n  ..$ Marital.and.civil.partnership.status..Separated..but.still.legally.married.or.still.legally.in.a.civil.partnership..Separated..but.still.married..measures..Value                          : int [1:10] 54029 135494 101660 88398 110090 112791 164083 160211 99224 52074\n  ..$ Marital.and.civil.partnership.status..Separated..but.still.legally.married.or.still.legally.in.a.civil.partnership..Separated..but.still.in.a.registered.civil.partnership..measures..Value: int [1:10] 329 934 690 582 621 664 1801 1184 736 394\n  ..$ Marital.and.civil.partnership.status..Divorced.or.civil.partnership.dissolved..measures..Value                                                                                             : int [1:10] 206974 550417 420235 378618 424612 490720 516854 705127 478079 252707\n  ..$ Marital.and.civil.partnership.status..Divorced.or.civil.partnership.dissolved..Divorced..measures..Value                                                                                   : int [1:10] 206505 549121 419338 377750 423752 489726 514117 703179 476871 252159\n  ..$ Marital.and.civil.partnership.status..Divorced.or.civil.partnership.dissolved..Formerly.in.a.civil.partnership.now.legally.dissolved..measures..Value                                      : int [1:10] 469 1296 897 868 860 994 2737 1948 1208 548\n  ..$ Marital.and.civil.partnership.status..Widowed.or.surviving.civil.partnership.partner..measures..Value                                                                                      : int [1:10] 150754 390807 286690 255469 311825 323230 295690 462416 313152 181125\n  ..$ Marital.and.civil.partnership.status..Widowed.or.surviving.civil.partnership.partner..Widowed..measures..Value                                                                             : int [1:10] 150610 390312 286369 255208 311517 322831 294837 461641 312673 180925\n  ..$ Marital.and.civil.partnership.status..Widowed.or.surviving.civil.partnership.partner..Surviving.partner.from.civil.partnership..measures..Value                                            : int [1:10] 144 495 321 261 308 399 853 775 479 200\n $ :'data.frame':   10 obs. of  25 variables:\n  ..$ date                                                                                                                                 : int [1:10] 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021\n  ..$ geography                                                                                                                            : chr [1:10] \"North East\" \"North West\" \"Yorkshire and The Humber\" \"East Midlands\" ...\n  ..$ geography.code                                                                                                                       : chr [1:10] \"E12000001\" \"E12000002\" \"E12000003\" \"E12000004\" ...\n  ..$ Household.composition..Total..measures..Value                                                                                        : int [1:10] 1175683 3153406 2330657 2037334 2429493 2628778 3423890 3807967 2448881 1347114\n  ..$ Household.composition..One.person.household..measures..Value                                                                         : int [1:10] 395924 1014913 733558 597177 725807 759808 1001983 1081739 741323 429559\n  ..$ Household.composition..One.person.household..Aged.66.years.and.over..measures..Value                                                 : int [1:10] 167832 420823 309721 264630 318108 347326 313049 503974 356329 196056\n  ..$ Household.composition..One.person.household..Other..measures..Value                                                                  : int [1:10] 228092 594090 423837 332547 407699 412482 688934 577765 384994 233503\n  ..$ Household.composition..Single.family.household..measures..Value                                                                      : int [1:10] 731124 1961888 1471340 1317959 1549864 1714480 1986263 2473698 1556311 850096\n  ..$ Household.composition..Single.family.household..All.aged.66.years.and.over..measures..Value                                          : int [1:10] 112397 278671 221778 209388 231216 272511 148209 386986 284123 138010\n  ..$ Household.composition..Single.family.household..Married.or.civil.partnership.couple..measures..Value                                 : int [1:10] 331330 904487 687238 632498 741413 848252 977165 1260379 747034 386697\n  ..$ Household.composition..Single.family.household..Married.or.civil.partnership.couple..No.children..measures..Value                    : int [1:10] 129507 312295 259341 236710 248508 287375 256539 420975 288960 145009\n  ..$ Household.composition..Single.family.household..Married.or.civil.partnership.couple..Dependent.children..measures..Value             : int [1:10] 135625 412594 305595 280529 345254 406526 541099 619300 328880 160019\n  ..$ Household.composition..Single.family.household..Married.or.civil.partnership.couple..All.children.non.dependent..measures..Value     : int [1:10] 66198 179598 122302 115259 147651 154351 179527 220104 129194 81669\n  ..$ Household.composition..Single.family.household..Cohabiting.couple.family..measures..Value                                            : int [1:10] 137302 373006 291532 253787 272420 309554 349419 433453 288505 155649\n  ..$ Household.composition..Single.family.household..Cohabiting.couple.family..No.children..measures..Value                               : int [1:10] 70052 192405 153710 134608 137757 164306 229339 240827 163957 77093\n  ..$ Household.composition..Single.family.household..Cohabiting.couple.family..With.dependent.children..measures..Value                   : int [1:10] 57542 155174 119334 103354 115766 125253 101486 166572 108519 67941\n  ..$ Household.composition..Single.family.household..Cohabiting.couple.family..All.children.non.dependent..measures..Value                : int [1:10] 9708 25427 18488 15825 18897 19995 18594 26054 16029 10615\n  ..$ Household.composition..Single.family.household..Lone.parent.family..measures..Value                                                  : int [1:10] 143417 382496 256459 209278 287205 268439 453937 369841 223832 161836\n  ..$ Household.composition..Single.family.household..Lone.parent.family..With.dependent.children..measures..Value                         : int [1:10] 94314 241480 168688 132437 180039 166653 267852 227161 138453 102274\n  ..$ Household.composition..Single.family.household..Lone.parent.family..All.children.non.dependent..measures..Value                      : int [1:10] 49103 141016 87771 76841 107166 101786 186085 142680 85379 59562\n  ..$ Household.composition..Single.family.household..Other.single.family.household..measures..Value                                       : int [1:10] 6678 23228 14333 13008 17610 15724 57533 23039 12817 7904\n  ..$ Household.composition..Single.family.household..Other.single.family.household..Other.family.composition..measures..Value             : int [1:10] 6678 23228 14333 13008 17610 15724 57533 23039 12817 7904\n  ..$ Household.composition..Other.household.types..measures..Value                                                                        : int [1:10] 48635 176605 125759 122198 153822 154490 435644 252530 151247 67459\n  ..$ Household.composition..Other.household.types..With.dependent.children..measures..Value                                               : int [1:10] 18689 73084 51557 49543 72712 63676 160669 93493 46913 26078\n  ..$ Household.composition..Other.household.types..Other..including.all.full.time.students.and.all.aged.66.years.and.over..measures..Value: int [1:10] 29946 103521 74202 72655 81110 90814 274975 159037 104334 41381\n\n\nYou can select one out individually:\n\n## Select the first table\ntable1 &lt;- tables[[1]]\nhead(table1)\n\n  date                geography geography.code\n1 2021               North East      E12000001\n2 2021               North West      E12000002\n3 2021 Yorkshire and The Humber      E12000003\n4 2021            East Midlands      E12000004\n5 2021            West Midlands      E12000005\n6 2021                     East      E12000006\n  Residence.type..Total..measures..Value\n1                                2647013\n2                                7417397\n3                                5480774\n4                                4880054\n5                                5950757\n6                                6335074\n  Residence.type..Lives.in.a.household..measures..Value\n1                                               2594828\n2                                               7290560\n3                                               5376740\n4                                               4778018\n5                                               5854512\n6                                               6238659\n  Residence.type..Lives.in.a.communal.establishment..measures..Value\n1                                                              52185\n2                                                             126837\n3                                                             104034\n4                                                             102036\n5                                                              96245\n6                                                              96415\n\n\nOr because they all have the geography.code, geography and date column, you can just attach them into one big table. This relies on the use of the purrr package, which is full of useful tools for working with lists.\n\n## Bind together\ntest &lt;- tables %&gt;%\n  reduce(left_join, by = c(\"date\", \"geography\", \"geography.code\"))\n\n## Have a look\ncolnames(test)\n\n [1] \"date\"                                                                                                                                                                                       \n [2] \"geography\"                                                                                                                                                                                  \n [3] \"geography.code\"                                                                                                                                                                             \n [4] \"Residence.type..Total..measures..Value\"                                                                                                                                                     \n [5] \"Residence.type..Lives.in.a.household..measures..Value\"                                                                                                                                      \n [6] \"Residence.type..Lives.in.a.communal.establishment..measures..Value\"                                                                                                                         \n [7] \"Marital.and.civil.partnership.status..Total..measures..Value\"                                                                                                                               \n [8] \"Marital.and.civil.partnership.status..Never.married.and.never.registered.a.civil.partnership..measures..Value\"                                                                              \n [9] \"Marital.and.civil.partnership.status..Married.or.in.a.registered.civil.partnership..measures..Value\"                                                                                        \n[10] \"Marital.and.civil.partnership.status..Married.or.in.a.registered.civil.partnership..Married..measures..Value\"                                                                               \n[11] \"Marital.and.civil.partnership.status..Married.or.in.a.registered.civil.partnership..Married..Opposite.sex..measures..Value\"                                                                 \n[12] \"Marital.and.civil.partnership.status..Married.or.in.a.registered.civil.partnership..Married..Same.sex..measures..Value\"                                                                     \n[13] \"Marital.and.civil.partnership.status..Married.or.in.a.registered.civil.partnership..In.a.registered.civil.partnership..measures..Value\"                                                     \n[14] \"Marital.and.civil.partnership.status..Married.or.in.a.registered.civil.partnership..In.a.registered.civil.partnership..Opposite.sex..measures..Value\"                                       \n[15] \"Marital.and.civil.partnership.status..Married.or.in.a.registered.civil.partnership..In.a.registered.civil.partnership..Same.sex..measures..Value\"                                           \n[16] \"Marital.and.civil.partnership.status..Separated..but.still.legally.married.or.still.legally.in.a.civil.partnership..measures..Value\"                                                        \n[17] \"Marital.and.civil.partnership.status..Separated..but.still.legally.married.or.still.legally.in.a.civil.partnership..Separated..but.still.married..measures..Value\"                          \n[18] \"Marital.and.civil.partnership.status..Separated..but.still.legally.married.or.still.legally.in.a.civil.partnership..Separated..but.still.in.a.registered.civil.partnership..measures..Value\"\n[19] \"Marital.and.civil.partnership.status..Divorced.or.civil.partnership.dissolved..measures..Value\"                                                                                             \n[20] \"Marital.and.civil.partnership.status..Divorced.or.civil.partnership.dissolved..Divorced..measures..Value\"                                                                                   \n[21] \"Marital.and.civil.partnership.status..Divorced.or.civil.partnership.dissolved..Formerly.in.a.civil.partnership.now.legally.dissolved..measures..Value\"                                      \n[22] \"Marital.and.civil.partnership.status..Widowed.or.surviving.civil.partnership.partner..measures..Value\"                                                                                      \n[23] \"Marital.and.civil.partnership.status..Widowed.or.surviving.civil.partnership.partner..Widowed..measures..Value\"                                                                             \n[24] \"Marital.and.civil.partnership.status..Widowed.or.surviving.civil.partnership.partner..Surviving.partner.from.civil.partnership..measures..Value\"                                            \n[25] \"Household.composition..Total..measures..Value\"                                                                                                                                              \n[26] \"Household.composition..One.person.household..measures..Value\"                                                                                                                               \n[27] \"Household.composition..One.person.household..Aged.66.years.and.over..measures..Value\"                                                                                                       \n[28] \"Household.composition..One.person.household..Other..measures..Value\"                                                                                                                        \n[29] \"Household.composition..Single.family.household..measures..Value\"                                                                                                                            \n[30] \"Household.composition..Single.family.household..All.aged.66.years.and.over..measures..Value\"                                                                                                \n[31] \"Household.composition..Single.family.household..Married.or.civil.partnership.couple..measures..Value\"                                                                                       \n[32] \"Household.composition..Single.family.household..Married.or.civil.partnership.couple..No.children..measures..Value\"                                                                          \n[33] \"Household.composition..Single.family.household..Married.or.civil.partnership.couple..Dependent.children..measures..Value\"                                                                   \n[34] \"Household.composition..Single.family.household..Married.or.civil.partnership.couple..All.children.non.dependent..measures..Value\"                                                           \n[35] \"Household.composition..Single.family.household..Cohabiting.couple.family..measures..Value\"                                                                                                  \n[36] \"Household.composition..Single.family.household..Cohabiting.couple.family..No.children..measures..Value\"                                                                                     \n[37] \"Household.composition..Single.family.household..Cohabiting.couple.family..With.dependent.children..measures..Value\"                                                                         \n[38] \"Household.composition..Single.family.household..Cohabiting.couple.family..All.children.non.dependent..measures..Value\"                                                                      \n[39] \"Household.composition..Single.family.household..Lone.parent.family..measures..Value\"                                                                                                        \n[40] \"Household.composition..Single.family.household..Lone.parent.family..With.dependent.children..measures..Value\"                                                                               \n[41] \"Household.composition..Single.family.household..Lone.parent.family..All.children.non.dependent..measures..Value\"                                                                            \n[42] \"Household.composition..Single.family.household..Other.single.family.household..measures..Value\"                                                                                             \n[43] \"Household.composition..Single.family.household..Other.single.family.household..Other.family.composition..measures..Value\"                                                                   \n[44] \"Household.composition..Other.household.types..measures..Value\"                                                                                                                              \n[45] \"Household.composition..Other.household.types..With.dependent.children..measures..Value\"                                                                                                     \n[46] \"Household.composition..Other.household.types..Other..including.all.full.time.students.and.all.aged.66.years.and.over..measures..Value\"",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dashboards and APIs</span>"
    ]
  },
  {
    "objectID": "03_dashboards-api.html#using-the-nomis-api",
    "href": "03_dashboards-api.html#using-the-nomis-api",
    "title": "3  Dashboards and APIs",
    "section": "3.3 Using the NOMIS API",
    "text": "3.3 Using the NOMIS API\nOne of the things that you see more commonly in practice is the construction of specific R packages used to access APIs, with supporting documentation and specific functions that make it easier to use the API.\nOne such example is nomisr, which is an R package that was built to enable users to query data from NOMIS. It is free to access and contains up-to-date official statistics including data from the latest Census, Labour Force Survey and DWP benefit statistics.\nIn the section that follows, I’m going to be showing you how to use the nomisr package to download datasets.\nVast amounts of data are available through NOMIS, so you need to use some of the different functions within nomisr to identify the specific datasets you want to use. An example is presented below which searches for datasets within NOMIS that are specifically about ‘Travel’:\n\n## Search for data on Labour Force\nsearch &lt;- nomis_search(\"*Travel*\")\n\nThis returns a dataframe (which you should see in your environment) that describes all of the different NOMIS held datasets where ‘Travel’ is mentioned. The column perhaps of most interest is the short name for the different datasets, which you can inspect below:\n\n## Have a look at the first six datasets \nhead(search$name.value)\n\n[1] \"2001 census - UK travel flows (local authority)\"            \n[2] \"2001 census - Scottish travel flows (local authority)\"      \n[3] \"2001 census - UK travel flows (ward)\"                       \n[4] \"QS702EW - Distance travelled to work\"                       \n[5] \"WD702EW - Distance travelled to work (Workday population)\"  \n[6] \"WP702EW - Distance travelled to work (Workplace population)\"\n\n\nIf you open up the dataframe in your environment and scroll down you should see one row has the value - TS061 - Method used to travel to work - which is the one we’ve been using a lot in this practical.\nWe can filter to this row very easily using the filter() command that we introduced yesterday:\n\n## Filter to row of interest\nsearch_sub &lt;- search %&gt;%\n  filter(name.value == \"TS061 - Method used to travel to work\")\n\n## Have a look at the result\nsearch_sub\n\n# A tibble: 1 × 12\n  agencyid id        uri     version annotations.annotation components.attribute\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt; &lt;list&gt;                 &lt;list&gt;              \n1 NOMIS    NM_2078_1 Nm-207…       1 &lt;df [13 × 2]&gt;          &lt;df [7 × 4]&gt;        \n# ℹ 6 more variables: components.dimension &lt;list&gt;,\n#   components.primarymeasure.conceptref &lt;chr&gt;,\n#   components.timedimension.codelist &lt;chr&gt;,\n#   components.timedimension.conceptref &lt;chr&gt;, name.value &lt;chr&gt;,\n#   name.lang &lt;chr&gt;\n\n\nNotice how the table ID is NM_2078_1. We can get some metadata for this dataset very easily using the nomis_get_metadata() command. First, let’s see what measures are available:\n\n## Supply the ID of the row we're interested in, and the second parameters specifies we'd like to know more about the measures\nnomis_get_metadata(search_sub$id, \"measures\")\n\n# A tibble: 2 × 3\n  id    label.en description.en\n  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;         \n1 20100 value    value         \n2 20301 percent  percent       \n\n\nSo for TS061, we can get both raw counts (‘value’) and percent. Notice how the ID for counts is 20100 and the ID for percent is 20301. Let’s now see what geographies are available:\n\n## Supply the ID of the row we're interested in, and the second parameter specifies that we want to know more about geographies\nnomis_get_metadata(search_sub$id, \"geography\")\n\n# A tibble: 3 × 4\n  id         parentCode label.en          description.en   \n  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;             &lt;chr&gt;            \n1 2092957703 &lt;NA&gt;       England and Wales England and Wales\n2 2092957699 &lt;NA&gt;       England           England          \n3 2092957700 2092957700 Wales             Wales            \n\n\nOk, so this is telling us the different geographic levels we can download the data for. However, if we add an additional parameter to this, we can also see the specific geographic units that this data is available at:\n\n## Add in an additional parameter\nnomis_get_metadata(search_sub$id, \"geography\", \"TYPE\")\n\n# A tibble: 12 × 3\n   id      label.en                                               description.en\n   &lt;chr&gt;   &lt;chr&gt;                                                  &lt;chr&gt;         \n 1 TYPE150 2021 output areas                                      2021 output a…\n 2 TYPE151 2021 super output areas - lower layer                  2021 super ou…\n 3 TYPE152 2021 super output areas - middle layer                 2021 super ou…\n 4 TYPE153 2022 wards                                             2022 wards    \n 5 TYPE154 2022 local authorities: districts                      2022 local au…\n 6 TYPE155 2022 local authorities: counties                       2022 local au…\n 7 TYPE168 2021 national parks                                    2021 national…\n 8 TYPE423 local authorities: county / unitary (as of April 2023) local authori…\n 9 TYPE424 local authorities: district / unitary (as of April 20… local authori…\n10 TYPE459 local enterprise partnerships (as of April 2021)       local enterpr…\n11 TYPE480 regions                                                regions       \n12 TYPE499 countries                                              countries     \n\n\nSo there are a variety of different geographic levels at which we can download the dataset, including LSOA - see 2021 super output areas - lower layer. Notice how the ID for LSOAs is TYPE151.\nThose steps we have just performed basically give us everything we need to download the dataset directly from the NOMIS API using the package, instead of downloading the .zip files directly. Let’s download the file - it could take a while! If you don’t understand any of the specific inputs to this line of code, feel free to shout Patrick to talk it through.\n\n## Download the file\ndb_v2 &lt;- nomis_get_data(id = \"NM_2078_1\", time = \"latest\", geography = c(\"TYPE151\"), measures = \"20301\")\n\nRetrieving additional pages 1 of 17\n\n\nRetrieving additional pages 2 of 17\n\n\nRetrieving additional pages 3 of 17\n\n\nRetrieving additional pages 4 of 17\n\n\nRetrieving additional pages 5 of 17\n\n\nRetrieving additional pages 6 of 17\n\n\nRetrieving additional pages 7 of 17\n\n\nRetrieving additional pages 8 of 17\n\n\nRetrieving additional pages 9 of 17\n\n\nRetrieving additional pages 10 of 17\n\n\nRetrieving additional pages 11 of 17\n\n\nRetrieving additional pages 12 of 17\n\n\nRetrieving additional pages 13 of 17\n\n\nRetrieving additional pages 14 of 17\n\n\nRetrieving additional pages 15 of 17\n\n\nRetrieving additional pages 16 of 17\n\n\nRetrieving additional pages 17 of 17\n\n\nThe format the data is presented in is not the most intuitive, so those reshaping skills we acquired yesterday are going to come in handy here again!\nFirstly, let’s get the columns we need for our analysis - LSOA codes, the different modes of transport and the actual reported values.\n\n## Select columns of interest\ndb_clean &lt;- db_v2 %&gt;%\n  select(GEOGRAPHY_CODE, C2021_TTWMETH_12_NAME, OBS_VALUE) \n\n## Inspect\nhead(db_clean)\n\n# A tibble: 6 × 3\n  GEOGRAPHY_CODE C2021_TTWMETH_12_NAME                                 OBS_VALUE\n  &lt;chr&gt;          &lt;chr&gt;                                                     &lt;dbl&gt;\n1 E01011954      Total: All usual residents aged 16 years and over in…     100  \n2 E01011954      Work mainly at or from home                                11.9\n3 E01011954      Underground, metro, light rail, tram                        0  \n4 E01011954      Train                                                       0.3\n5 E01011954      Bus, minibus or coach                                       4.1\n6 E01011954      Taxi                                                        2  \n\n\nSo as you can see from the table, it’s actually in a long format, whereas we might want it to be in a wide format, where each column is the % of people using each transport mode. Let’s use the pivot_wider() command to change this:\n\n## Go from long to wide\ndb_clean &lt;- db_clean %&gt;%\n  pivot_wider(names_from = C2021_TTWMETH_12_NAME, values_from = OBS_VALUE)\n\n## Inspect\nhead(db_clean)\n\n# A tibble: 6 × 13\n  GEOGRAPHY_CODE Total: All usual residents aged 16 yea…¹ Work mainly at or fr…²\n  &lt;chr&gt;                                             &lt;dbl&gt;                  &lt;dbl&gt;\n1 E01011954                                           100                   11.9\n2 E01011969                                           100                   14.7\n3 E01011970                                           100                   19.5\n4 E01011971                                           100                   19  \n5 E01033465                                           100                   22.2\n6 E01033467                                           100                   20.6\n# ℹ abbreviated names:\n#   ¹​`Total: All usual residents aged 16 years and over in employment the week before the census`,\n#   ²​`Work mainly at or from home`\n# ℹ 10 more variables: `Underground, metro, light rail, tram` &lt;dbl&gt;,\n#   Train &lt;dbl&gt;, `Bus, minibus or coach` &lt;dbl&gt;, Taxi &lt;dbl&gt;,\n#   `Motorcycle, scooter or moped` &lt;dbl&gt;, `Driving a car or van` &lt;dbl&gt;,\n#   `Passenger in a car or van` &lt;dbl&gt;, Bicycle &lt;dbl&gt;, `On foot` &lt;dbl&gt;, …\n\n\nGreat, that’s worked! You’ll also notice the number of rows of db_clean matches that of db (which was the file we unzipped at the start of the practical).\nSome final data cleaning steps:\n\n## Tidy up the dataset\ndb_final &lt;- db_clean %&gt;%\n  setNames(c(\"LSOA21CD\", \"total\", \"work_from_home\", \"underground_metro\", \"train\", \"bus_minibus_coach\", \n             \"taxi\", \"motorcycle\", \"car_driving\", \"car_passenger\", \"bicycle\", \"foot\", \"other\")) ## set new names\n\nAnd then we can easily produce one of the visualisations from yesterday:\n\n## Reproduce the scatter plot from yesterday's class\nggplot(data = db_final, aes(x = work_from_home, y = car_driving)) +\n  geom_point(alpha = 0.3, size = 0.35) +\n  geom_smooth(method = \"lm\") +\n  xlim(0, 100) +\n  ylim(0, 100) +\n  labs(x = \"Population who work from home (%)\", y = \"Population who drive to work (%)\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nNice! You have now learned how to programmatically use the API to scrape data from NOMIS, bypassing the need to download and unzip the files directly. Now, some independent tasks to check you can reproduce the steps.\n\n3.3.1 Independent exercise - Over to you!\n\nExperiment with downloading a different dataset using the nomisr package, and clean it.\nProduce an interesting visualisation using your chosen dataset.\n(optional) See if you can attach the LAD names to your dataset, and produce a visualisation that examines LAD differences in your chosen dataset - recommend you choose a dataset at either LSOA or MSOA geography to use yesterday’s lookup table. If you are unsure of how to do this, you will need to go back to Day 2 - Data Visualisation.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dashboards and APIs</span>"
    ]
  },
  {
    "objectID": "03_dashboards-api.html#building-dashboards-in-r",
    "href": "03_dashboards-api.html#building-dashboards-in-r",
    "title": "3  Dashboards and APIs",
    "section": "3.4 Building Dashboards in R",
    "text": "3.4 Building Dashboards in R\nDashboards are often a great way to share results and analyses with others. There are a number of ways you can build dashboards in R, including:\n\nUsing markdown (flexdashboard R package)\nUsing R shiny.\n\nThe former offers you to create a dashboard with panels and pages very easily, and has significant advantages over R Shiny:\n\nMinimal coding required.\nDashboard can be distributed as the .html file, with no server required.\nOther packages can hook into the dashboard to add interactivity.\n\n\n3.4.1 Getting started\nTo build a dashboard using R markdown, we will need to use an alternate type of computational workbook - thus far we have been working with Quarto files (.qmd), but now we need to switch to the format that supports “Flex Dashboards”.\nHowever, flexdashboard runs into problems when linked to an existing R project, especially one which is hooked up to Quarto.\nImportant So for this part of the project please create a new directory where you want to build your dashboard. For example, I’ve created a new folder called ‘Dashboard’, which is where I will be building my dashboard. Also, make sure to copy some of the datasets we have been using into this new directory:\n\n\n\nNew Directory\n\n\nThe final step is to create a new file which will be used to build your dashboard. In R, Go to File &gt; New File &gt; R Markdown &gt; From Template &gt; Flex Dashboard (see below).\n\n\n\nNew File\n\n\nThe file should open up automatically, and should look the one below:\n\n\n\nBlank Dashboard Template\n\n\nNow save it inside your new folder as something you can remember - e.g., dashboard.Rmd. It is vital that this new .Rmd is saved within your new folder, which should now look like this:\n\n\n\nFull Directory\n\n\nWhen you open up the .Rmd file, you should be able to see the ‘Knit’ button as below. If you instead see the ‘Render’ button, you’ve not saved the .rmd in your new directory. Speak to Patrick if you run into problems here.\n\n\n\nKnit Button\n\n\n\n\n3.4.2 Introduction to Flex Dashboard\nFor the remainder of the practical, you need to be working in your new .Rmd file. This is where you will build and deploy your dashboard, so please make sure you are working in this file - ‘dashboard.Rmd’.\nInside the file you will notice a couple of different things:\n\nCode blocks - you will see code blocks like those you have been running in this document, which can be used to run lines of code easily.\nYAML header - at the top of the new file is a YAML header, which is where you can set up the basic metadata for the dashboard.\n\nHave a go at changing your YAML header to the following:\n\n\n\nYAML\n\n\nThese parameters are doing the following:\n\ntitle: sets a title to appear at the top of the dashboard.\norientation: determines whether charts should be aligned in rows or columns\nvertical_layout: sets the dashboard to fill available browser height.\n\nPress ‘Knit’ and see what happens…\nR should open up a new window that looks like this:\n\n\n\nFirst Dashboard\n\n\nSo you can see that the dashboard has three panes set up to host different types of visualisation. In the .Rmd file you’ll notice that each ## denotes the start of a new column, and each ### denotes a new pane for visualisation.\nLet’s change the layout slightly, to create a grid of four equally sized panes. To do this you need to:\n\nChange the data-width parameter to be equal for both columns\nAdd a second panel under column one\n\nHere is what the code looks like:\n\n\n\nCode\n\n\nNow press ‘Knit’ again, and see what has changed:\n\n\n\nResized\n\n\nCool! So the dashboard layout is set up and ready to go!\n\n\n3.4.3 Independent exercise - Over to you!\n\nSwap the orientation to be columns\nSee if you can set up the dashboard to be structured as 1 large panel on the left, and three on the right.\n(optional) Change the section headers for each panel to list some potential visualisations you might put in each, based on yesterday’s class.\n\nSOLUTION:\n\n\n\nSolution\n\n\n\n\n3.4.4 Embedding visualisations\nWhen building a dashboard, a key component will be adding in a number of visualisations to enhance the information being conveyed by the dashboard. As you have seen so far, flexdashboard creates panes to host plots and visualisations on.\nHowever, the visualisations need to be produced within the .Rmd file before they can be displayed on the dashboard itself. This is where you can use code chunks within the .Rmd file to re-run some of the analyses we did yesterday to produce visuals for the dashboard.\nThe code chunks need to be placed before the dashboard structural parameters - i.e. before the ## Column commands in the script. Have a look at the example below where we read in and clean the census data we were using on Day 2:\n\n\n\nHow to insert code\n\n\nThen, once you have the read the data in you can produce one of the visualisations we made yesterday - such as the scatter plot we made yesterday:\n\n\n\nMake a plot\n\n\nNow the final step is to think about embedding this plot so it can be displayed on the plot. To do this, all you need to do is call the plot in one of the code blocks which are set up to host visualisations, see below:\n\n\n\nEmbed a plot\n\n\nNow hit ‘Knit’ and you should see this plot on the dashboard:\n\n\n\nFirst stage\n\n\n\n\n3.4.5 Independent exercise - Over to you!! (30 - 45 mins)\nHave a go at embedding some more visualisations on the dashboard. To do this you will need to reproduce lots of the analysis you did on Day 2.\nBelow I’ve included something that I put together, which is something you could aim to try and generate. Have a look at this vignette produced by the flexdashboard package developers for some ideas of different elements and interactive functionalities you might want to build into your dashboard.\n\n\n\nTransport Dashboard",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dashboards and APIs</span>"
    ]
  },
  {
    "objectID": "03_dashboards-api.html#other-useful-reporting-techniques",
    "href": "03_dashboards-api.html#other-useful-reporting-techniques",
    "title": "3  Dashboards and APIs",
    "section": "3.5 Other Useful Reporting Techniques",
    "text": "3.5 Other Useful Reporting Techniques\nWe have shown you the power of using R and Quarto for generating computational workbooks where you can view both the figures/outputs and code used to generate them, all at once.\n\n3.5.1 Constructing Reports\nThe .html files that render alongside these .qmd files can be seen as ‘reports’ in a way. However, there is a whole host of design-related modifications you can make to the .qmd file which will enhance the appearance of the output report.\nThere is lots of useful information online about creating nice reports using R markdown - including this one from The Epidemiologist R Handbook.\n\n\n3.5.2 Routine Reporting\nThe Epidemiologist Handbook also has a really nice section on how to use R to run reports routinely, using the reportfactory R package. Have a a look at the Organising routing reports guide if you are interested in learning more about this!",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dashboards and APIs</span>"
    ]
  },
  {
    "objectID": "04_data-modeling.html",
    "href": "04_data-modeling.html",
    "title": "4  Data modeling",
    "section": "",
    "text": "4.1 Learning objectives\nBy the end of today’s session you should be able to:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data modeling</span>"
    ]
  },
  {
    "objectID": "04_data-modeling.html#learning-objectives",
    "href": "04_data-modeling.html#learning-objectives",
    "title": "4  Data modeling",
    "section": "",
    "text": "Understand how to estimate, interpret and calibrate linear regression and ARIMA models;\nBe familiar with the main assumptions and challenges of these models;\nUse these models to produce predictions.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data modeling</span>"
    ]
  },
  {
    "objectID": "04_data-modeling.html#dependencies",
    "href": "04_data-modeling.html#dependencies",
    "title": "4  Data modeling",
    "section": "4.2 Dependencies",
    "text": "4.2 Dependencies\n\n# data manipulation\nlibrary(tidyverse)\n# plot design / placement\nlibrary(patchwork)\nlibrary(ggfortify)\n# time series modelling\nlibrary(forecast)\nlibrary(tseries)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data modeling</span>"
    ]
  },
  {
    "objectID": "04_data-modeling.html#data",
    "href": "04_data-modeling.html#data",
    "title": "4  Data modeling",
    "section": "4.3 Data",
    "text": "4.3 Data\nWe first read the data. We will be working with data from NOMIS. We will use data on claimant count and job density.\nClaimant Count (Experimental Statistics)\nAs it is described in NOMIS:\n\n“The Claimant Count is the number of people claiming benefit principally for the reason of being unemployed. This is measured by combining the number of people claiming Jobseeker’s Allowance (JSA) and National Insurance credits with the number of people receiving Universal Credit principally for the reason of being unemployed. Claimants declare that they are out of work, capable of, available for and actively seeking work during the week in which the claim is made.”\n\n\n“The measure of the number of people receiving Universal Credit principally for the reason of being unemployed is still being developed by the Department for Work and Pensions. Consequently this component of the total Claimant Count does not yet correctly reflect the target population of unemployed claimants and is subject to revisions. For this reason the Claimant Count is currently designated as Experimental Statistics.”\n\n\n“The Claimant Count is mostly derived from DWP administrative systems. For various reasons, e.g. a claimant’s National Insurance number is not known, a small number of claims have to be dealt with manually. These clerical claims do not have as much detail as the computerised claims and therefore, whilst part of the claimant count by sex table, cannot be included the age breakdown.”\n\nWe read the data using read_csv:\n\ndf_claimants &lt;- read_csv(\"./data/claimants/claimants_liverpool.csv\", \n                         col_types = cols(\n                           date = col_date(format = \"%B %Y\"),\n                           count = col_number()\n                           )\n                         )\n\nhead(df_claimants)\n\n# A tibble: 6 × 2\n  date       count\n  &lt;date&gt;     &lt;dbl&gt;\n1 1992-01-01 40165\n2 1992-02-01 40145\n3 1992-03-01 39880\n4 1992-04-01 40000\n5 1992-05-01 39790\n6 1992-06-01 39425\n\n\nJobs Density\nTo explain changes over time in the claimant count, we use data on job density from NOMIS. The definition of job density is as follows:\n\n“The level of jobs per resident aged 16-64. For example, a job density of 1.0 would mean that there is one job for every resident aged 16-64.”\n\n\n“The total number of jobs is a workplace-based measure and comprises employee jobs, self-employed, government-supported trainees and HM Forces. The number of residents aged 16-64 figures used to calculate jobs densities are based on the relevant mid-year population estimates.”\n\n\ndf_job.density &lt;- read_csv(\"./data/job-density/job-density_liverpool.csv\", \n                         col_types = cols(\n                           year = col_date(format = \"%Y\"),\n                           job_density = col_number()\n                           )\n                         )\n\nhead(df_job.density)\n\n# A tibble: 6 × 2\n  year       job_density\n  &lt;date&gt;           &lt;dbl&gt;\n1 2000-01-01       0.762\n2 2001-01-01       0.816\n3 2002-01-01       0.818\n4 2003-01-01       0.819\n5 2004-01-01       0.813\n6 2005-01-01       0.814",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data modeling</span>"
    ]
  },
  {
    "objectID": "04_data-modeling.html#inspecting-the-data",
    "href": "04_data-modeling.html#inspecting-the-data",
    "title": "4  Data modeling",
    "section": "4.4 Inspecting the data",
    "text": "4.4 Inspecting the data\nVisually explore the data and describe main patterns.\n\np1 &lt;- ggplot(data = df_claimants, aes(x = date, y = count)) +\n  geom_line(colour = \"darkblue\", linewidth = 1.5) +\n  labs(title = \"Claimants\", x = \"Date\", y = \"Claimant count\") +\n  scale_x_date(date_labels = \"%Y\", date_breaks = \"5 year\") +\n  theme_minimal()\n\n\np2 &lt;- ggplot(data = df_job.density, \n             aes(x = year, y = job_density)) +\n  geom_line(colour = \"darkred\", linewidth = 1.5) +\n  labs(title = \"Job density\", x = \"Year\", y = \"Job density\") +\n  scale_x_date(date_labels = \"%Y\", date_breaks = \"3 year\") +\n  theme_minimal()\n\np1 + p2\n\n\n\n\n\n\n\n\nWe note that the data are of different temporal length. So we reduce the temporal scale of the claimant count series to match that of the series of job density.\n\np1 &lt;- ggplot(data = df_claimants %&gt;% \n               dplyr::filter(date &gt; \"2000-01-01\" & date &lt; \"2022-01-01\"),\n             aes(x = date, y = count)) +\n  geom_line(colour = \"darkblue\", linewidth = 1.5) +\n  labs(title = \"Claimants\", x = \"Date\", y = \"Claimant count\") +\n  scale_x_date(date_labels = \"%Y\", date_breaks = \"3 year\") +\n  theme_minimal()\n\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTask\nWhat can we learn from these plots?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data modeling</span>"
    ]
  },
  {
    "objectID": "04_data-modeling.html#data-wrangling",
    "href": "04_data-modeling.html#data-wrangling",
    "title": "4  Data modeling",
    "section": "4.5 Data wrangling",
    "text": "4.5 Data wrangling\nNow we will prepare the data frames that we need for the linear modelling section. The data for job density are available aggregated by year from 2000 to 2022. So we aggregate the data on claimants to match these temporal granularity averaging the monthly counts to obtain an annual average.\n\ndf_claimants$year &lt;- year(df_claimants$date)\n\ndf_claimants.year &lt;- df_claimants %&gt;% \n  group_by(year) %&gt;% \n  summarise( annual_claimants = round( mean(count) ))\n\nWe create a new year variable containing only the year (not the day and month) to join the data.\n\ndf_job.density$year2 &lt;- year(df_job.density$year)\n\nWe are now ready to join the data.\n\ndf_modelling &lt;- left_join(df_claimants.year, \n                          df_job.density,\n                          by = join_by(year == year2)\n)\n\ndf_modelling &lt;- df_modelling[complete.cases(df_modelling), ]\n\nhead(df_modelling)\n\n# A tibble: 6 × 4\n   year annual_claimants year.y     job_density\n  &lt;dbl&gt;            &lt;dbl&gt; &lt;date&gt;           &lt;dbl&gt;\n1  2000            19000 2000-01-01       0.762\n2  2001            16846 2001-01-01       0.816\n3  2002            15850 2002-01-01       0.818\n4  2003            14982 2003-01-01       0.819\n5  2004            14255 2004-01-01       0.813\n6  2005            14772 2005-01-01       0.814",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data modeling</span>"
    ]
  },
  {
    "objectID": "04_data-modeling.html#linear-regression",
    "href": "04_data-modeling.html#linear-regression",
    "title": "4  Data modeling",
    "section": "4.6 Linear regression",
    "text": "4.6 Linear regression\nWe will illustrate how we can fit a linear regression model to understand the relationship between claimant counts and job density. In a linear regression model, we can express an outcome (\\(y\\)) as a linear function of a series of explanatory variables (\\(x\\)), and we are interested in estimating the strength and direction of the linear relationship between the outcome and explanatory variables. We are interested in estimating the \\(\\beta\\)’s, and to this end, we use linear regression modelling. We assuming that there is a part that we can model and explain, represented by \\(\\beta\\) and \\(x\\); and, a part that we cannot explain or measure \\(epsilon\\) and we assume to be randomly distributed.\n\\[\ny = \\alpha + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + … + \\epsilon_i\n\\]\n\n4.6.1 Fitting a model\nWe will estimate a simple model assuming that annual claimants are a linear function of job density.\n\neq1 &lt;- annual_claimants ~ job_density\n\nlm1 &lt;- lm(eq1, \n         data = df_modelling)\n\n# estimates\nsummary(lm1)\n\n\nCall:\nlm(formula = eq1, data = df_modelling)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -5901  -2611  -1126   2872   8978 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)    12833      17522   0.732    0.472\njob_density     5062      21374   0.237    0.815\n\nResidual standard error: 4341 on 21 degrees of freedom\nMultiple R-squared:  0.002664,  Adjusted R-squared:  -0.04483 \nF-statistic: 0.0561 on 1 and 21 DF,  p-value: 0.8151\n\n\n\n\n4.6.2 Interpreting linear regression estimates\nIntercept (\\(\\alpha\\)). The intercept represents the expected value of annual claimants when job density is zero. If job density were hypothetically zero, the model predicts an average of approximately 12,833 annual claimants.\nSlope (\\(\\beta_1\\)). The coefficient represents the change in annual claimants for a one-unit increase in job density. For each additional unit of job density, the number of annual claimants is expected to increase by approximately 5,062, assuming all other factors remain constant.\n\n\n\n\n\n\nTask\nDoes the \\(\\beta_1\\) coefficient make sense? Why? Why not?\n\n\n\nIn fact, the results seem to make little sense. Let us examine the measure of model fit:\nResidual Standard Error: A measure of the average distance between the observed values and the model’s predicted values. 4341 in this case indicates the typical deviation of observed annual claimants from the model’s predictions.\nR-squared: Proportion of variance in the dependent variable explained by the model. Multiple R-squared: 0.002664 indicates that about 0.27% of the variability in annual claimants is explained by job density.\nF-statistic: Tests the overall significance of the model. An F-statistic of 0.0561 with a high p-value (0.8151) indicates that the model is not statistically significant.\n\n\n\n\n\n\nTask\nOverall, what do these measures of fit tell us?\n\n\n\nFinally, let us have a look at the data visually. In addition to the inferences that we can made based on the data reported above, these results also suggest a need to consider the temporal sequence of the data.\n\nggplot(df_modelling, aes(x = job_density, y = annual_claimants)) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"yellow\") +\n  geom_point(color = \"darkblue\", size = 3, alpha  = 0.7) +\n  labs(title = \"Association between claimants vs job density\", \n       x = \"Job density\", \n       y = \"Claimants\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data modeling</span>"
    ]
  },
  {
    "objectID": "04_data-modeling.html#time-series-data-modelling",
    "href": "04_data-modeling.html#time-series-data-modelling",
    "title": "4  Data modeling",
    "section": "4.7 Time series data modelling",
    "text": "4.7 Time series data modelling\nFor this section, we will return to our original time series of claimants for the period from January 1992 to April 2024. We will illustrate the use of ARIMA models, or Auto-Regressive Integrated Moving Average models. ARIMA is the combination of two models, an autoregressive (\\(AR\\)) and an moving average (\\(MA\\)) model. An autoregressive \\(AR(p)\\) component refers to the use of past values in the regression equation for the series \\(y\\). The autoregressive parameter \\(p\\) specifies the number of lags, or past values, to be used in the model. For example, an autoregressive model of order 2 (i.e. \\(AR(2)\\)) is represented as:\n\\[\ny_t = c + \\theta_1 y_{t-1} + \\theta_2 y_{t-2} + \\epsilon_t\n\\]\nwhere: \\(\\theta_1\\), \\(\\theta_2\\) are model parameters. The moving average nature of the model is represented by the \\(q\\) value, which is the number of lagged values of the error term. A moving average \\(MA(q)\\) component represents the error of the model as a combination of previous error terms. The order \\(q\\) determines the number of terms to include in the model. For example, an moving average model of order 2 (i.e. \\(AR(2)\\)) is represented as:\n\\[\ny_t = c + \\rho_1 e_{t-1} + \\rho_2 e_{t-2} + e_t\n\\]\nAdditionally, a time series needs to be stationary and a non-stationary time series needs to be transform through a procedure known as differencing (\\(d\\)) or integration (\\(I\\)). Together, these components (i.e. the autoregressive, integration and moving average components) define the ARIMA model. We will expand on these components later. An ARIMA model is specified by three order parameters: (\\(p\\), \\(d\\), \\(q\\)).\nThe process of modelling time series is complex task. To facilitate this process, we will use the following a modelling framework of five steps:\n\ntime series visualisation\nstationarity testing\noptimal parameter identification\nARIMA model calibration\nmodel prediction\n\n\n4.7.1 Visualising time series\nA time series has key components that we need to understand to uncover hidden patterns in the data.\n\nTrend: The long-term movement in the data, which can be upward, downward, or constant.\nSeasonality: Regular, repeating patterns or cycles in the data that occur at fixed intervals, such as daily, monthly, or annually.\nIrregular/Random Fluctuations: Noise or random variations that cannot be attributed to trends, seasonality, or cycles.\n\n\n# create a time series object\ndf_claimants_ts &lt;- ts(df_claimants$count, \n                     start = c(1992, 1),\n                     end = c(2024, 4),\n                     frequency = 12)\n\n# decompose time series\ndecompose_ts &lt;- decompose(df_claimants_ts)\n# plot time series components\nplot(decompose_ts)\n\n\n\n\n\n\n\n\nWhat do we learn from the plots? There are clear trends, seasonality and random variation, but also a spike during 2020 and 2021.\n\n\n4.7.2 Stationarity\nStationarity is a critical property in time series analysis.\nWhat is stationary? Stationary means that the mean, variance and covariance should be constant over time; that is, the mean, variance and covariance of the time series should not be a function of time.\nWhy do we care about stationarity? We care about stationarity because we cannot build a time series model if the time series is non-stationary. Non-stationary data can lead to misleading statistical inferences, so it is often necessary to transform non-stationary data into a stationary form before further analysis.\nHow do we transform a time series from non-stationary data into a stationary? There are three commonly used ways to achieve this.\n\nDetrending: Detrending involves removing the trend component from the time series. That would be removing the trend component shown in the plot above from the time series and building a model with the rest.\nDifferencing: Differencing is probably the most commonly used technique to remove non-stationarity. Differentiation is used to make a time series stationary by removing trends and seasonality. The differencing operation subtracts the previous value from the current value. Differencing is also known as for being the integration part in ARIMA models. Differencing involves in taking the difference between \\(y_t\\) and \\(y_t-1\\).\nSeasonality: Seasonality corresponds to the periodic cycles of changes in a time series and can be integrated via the autoregressive (AR) and moving average (MA) terms in ARIMA models\n\nSo we will use differencing and then test for stationarity.\nHow we know if a time series is stationary? We can use statistical tests to identify if a time series is stationary. We will the Augmented Dickey-Fuller (ADF) test which is a statistical test used to determine whether a given time series is stationary. The primary purpose of the ADF test is to check for the presence of a unit root in a time series sample; that is, if the time series is nonstationary and exhibits a stochastic trend. Essentially, a time series with a unit root shows that its values are heavily influenced by its own past values and that shocks or changes to the series have a permanent effect, rather than temporary. If the test rejects the null hypothesis, it suggests that the time series is stationary.\n\nadf.test(diff(log(df_claimants$count)), \n         alternative = \"stationary\", \n         k=0)\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  diff(log(df_claimants$count))\nDickey-Fuller = -12.742, Lag order = 0, p-value = 0.01\nalternative hypothesis: stationary\n\n\nThe Dickey-Fuller test returns a p-value of 0.01, resulting in the rejection of the null hypothesis in favour of the alternate. That is that the time series is stationary. Note that we used a log transformation. This transformation is applied to stabilise the variance and normalise the distribution of the data. Taking the logarithm of the claimants means that multiplicative relationships in the original time series become additive.\n\n\n4.7.3 Optimal parameters\nNext we need examine the Auto-Correlation Function (ACF) and the Partial Auto-Correlation Function (PACF) to identify appropriate values for \\(p\\) and \\(q\\). Thus, we examine these functions to identify which \\(AR(p)\\) , \\(MA(q)\\), \\(ARMA(p, q)\\) or \\(ARIMA(p, d, q)\\) model is more appropriate.\nACF is used to determine the level of autocorrelation between \\(y_t\\) and \\(y_{t-k}\\) for different values of \\(k\\). The ACF tells us how the present value in a time series is related with its past values. It helps identify the presence of any repeating patterns or relationships over different lags. Thus, ACF will help determining the number, or order, of moving-average (MA) coefficients for ARIMA models.\nPACF measures partial autocorrelations between \\(y_t\\) and \\(y_{t-k}\\) after removing the effects of lags 1, 2, 3, … , k - 1. This helps identify the direct relationships between observations separated by various lag periods. Thus, PACF helps us identify the number of autoregressive (AR) coefficients in our ARIMA model.\nThe figures below show ACF and PACF plots for our data to determine the order of parameters for our ARIMA model.\n\nacf(diff(log(df_claimants$count)))\n\n\n\n\n\n\n\n\n\npacf(diff(log(df_claimants$count)))\n\n\n\n\n\n\n\n\nHyndman and Athanasopoulos (2021) describe the usefulness of ACF and PACF plots. They suggest that a time series may correspond to an ARIMA( \\(p\\), \\(d\\), 0) model if the ACF and PACF plots of the differenced time series show the following patterns:\n\nthe ACF has an exponential decay or sine curve form;\nthere is a significant spike at lag \\(p\\) in the PACF, but none beyond lag \\(p\\).\n\nSimilarly, they state that a time series may follow an ARIMA(0, \\(d\\), \\(q\\)) model if the ACF and PACF plots of the differenced time series show the following patterns:\n\nthe PACF has an exponential decay or sine curve form;\nthere is a significant spike at lag \\(q\\) in the ACF, but none beyond lag \\(q\\).\n\nIn the ACF and PACF plots above, we observe a significant spike at lag 1 in the PACF plot followed by non-significant spikes suggests that an autoregressive (AR) component of order 1 is appropriate. Significant spikes at lags 1 and 2 in the ACF plot suggest that a moving average (MA) component of order 2 might be appropriate. Additionally, a significant spike at lag 12 in both ACF and PACF indicates the presence of a seasonal component with a period of 12. This suggests that the time series may have an annual seasonal pattern if the data is monthly. However, we will first concentrate on the ARIMA model (1, 0, 2) to illustrate the calibration of this type of models, and also because we generally prefer parsimonious models, and as you will see, a simpler model seems to provide the optimal AR and MA parameters with no integration at lag 12. Though, note that our model has one integration as we have differentiated our time series.\n\n\n4.7.4 ARIMA model calibration\nLet us fit the ARIMA (1, 0, 2) model using the arima function:\n\n# fit model\narima_m1 &lt;- arima(diff(log(df_claimants$count)), c(1, 0, 2))\n# estimates\nsummary(arima_m1)\n\n\nCall:\narima(x = diff(log(df_claimants$count)), order = c(1, 0, 2))\n\nCoefficients:\n         ar1      ma1      ma2  intercept\n      0.8818  -0.4644  -0.2839    -0.0019\ns.e.  0.0824   0.0995   0.0636     0.0032\n\nsigma^2 estimated as 0.0008907:  log likelihood = 809.8,  aic = -1609.6\n\nTraining set error measures:\n                        ME       RMSE        MAE  MPE MAPE      MASE       ACF1\nTraining set -1.357069e-05 0.02984486 0.01579798 -Inf  Inf 0.8246125 0.01209695\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the arima_m1 is the same that fitting the following model:\narima( log(df_claimants$count) ), c(1, 1, 2) )\nThat is not differencing the time series using diff before the log\n\n\nInterpretation\nA key point to note is that when interpreting the AR(1) and MA(1) coefficients in the context of a differenced logged time series, the focus is on the percentage changes rather than the absolute changes. Thus, the estimated coefficient of 0.8818 for ar1 term indicates that 88.18% of the percentage change in claimants from the previous period carries over to the current period. The sign is positive indicating that the concurrent count of claimants is strongly influenced by the the claimants from the previous period (i.e. lag 1). In other words, if claimants increased by 10% last month (after taking logs and differencing), this month’s claimants would increase by approximately 8.82% (88.18% of 10%), assuming other factors remain constant. This reflects strong persistence in the growth rates of claimants.\nIn terms of the MA terms, their estimated coefficients signal the temporal dependence of an unexpected change in the outcome from a previous period on the concurrent outcome. The MA(1) coefficient of -0.4644 indicates that an unexpected change (shock) in claimaints from the previous period has a negative effect on the current period’s percentage change in claimaints. If there was an unexpected increase in claimaints last month, this month’s percentage change in claimaints will be reduced by 46.44% of that shock. In other words, if there was an unexpected 5% increase in claimaints last month, this month’s sales would be expected to decrease by approximately 2.32% (-0.4644 * 5%), indicating a partial correction of the previous unexpected increase.\nModel performance\nHow do we know we have chosen the best model? The Akaike information criterion (AIC) score is a good indicator of the ARIMA model accuracy. The lower the AIC score, the better the model performs. Our model produced an AIC score of -1609. However, we can only know if we have selected the best model through iterated experimentation. We can randomly experiment with the parameters until we find parameters that yield the lowest AIC.\nAuto ARIMA\nTo this end, we can use a built-in function in the forecast package called auto.arima. The function returns the best-fitting ARIMA model according to either AIC, AICc or BIC value. The function conducts a search over possible model within the order constraints provided - see ?auto.arima for more information.\n\nautoarima_m1 &lt;- auto.arima(diff(log(df_claimants$count)), trace=TRUE)\n\n\n Fitting models using approximations to speed things up...\n\n ARIMA(2,0,2) with non-zero mean : Inf\n ARIMA(0,0,0) with non-zero mean : -1540.47\n ARIMA(1,0,0) with non-zero mean : -1608.778\n ARIMA(0,0,1) with non-zero mean : -1606.811\n ARIMA(0,0,0) with zero mean     : -1541.104\n ARIMA(2,0,0) with non-zero mean : -1607.388\n ARIMA(1,0,1) with non-zero mean : -1608.528\n ARIMA(2,0,1) with non-zero mean : -1605.537\n ARIMA(1,0,0) with zero mean     : -1610.231\n ARIMA(2,0,0) with zero mean     : -1608.789\n ARIMA(1,0,1) with zero mean     : -1609.917\n ARIMA(0,0,1) with zero mean     : -1608.005\n ARIMA(2,0,1) with zero mean     : -1606.965\n\n Now re-fitting the best model(s) without approximations...\n\n ARIMA(1,0,0) with zero mean     : -1611.047\n\n Best model: ARIMA(1,0,0) with zero mean     \n\n\nThe algorithm indicates that the best ARIMA model is achieved with parameters p=1, d=0, q=0.\n\n\n\n\n\n\n\n\nNote\n\n\n\nauto.arima generates models with non-zero mean and zero mean.\nA non-zero mean model indicates that the model has a constant term (\\(c\\)) or a drift term (\\(d\\)) if \\(d &gt; 0\\). For a non-differenced series (\\(d = 0\\)), the constant term is a true intercept, representing the mean level around which the series fluctuates. For a differenced series (\\(d &gt; 0\\)), the constant term can be interpreted as a drift, representing the average change per time period in the differenced series.\nA zero mean model indicates that the model does not has a constant term. It assumes that the time series fluctuates around a mean of zero if \\(d = 0\\). For a differenced series (\\(d &gt; 0\\)), this implies no deterministic trend (drift) in the data. This model is appropriate for stationary time series data that fluctuates around a mean of zero without a trend.\n\n\nLet us fit the ARIMA (1, 0, 0) model with zero mean:\n\n# fit model\narima_m2 &lt;- arima(diff(log(df_claimants$count)), c(1, 0, 0), include.mean = FALSE)\n# estimates\nsummary(arima_m2)\n\n\nCall:\narima(x = diff(log(df_claimants$count)), order = c(1, 0, 0), include.mean = FALSE)\n\nCoefficients:\n         ar1\n      0.4114\ns.e.  0.0462\n\nsigma^2 estimated as 0.0009013:  log likelihood = 807.54,  aic = -1611.08\n\nTraining set error measures:\n                       ME       RMSE        MAE  MPE MAPE      MASE       ACF1\nTraining set -0.001159562 0.03002149 0.01625172 -Inf  Inf 0.8482966 0.02558901\n\n\n\n\n\n\n\n\nTask\nHow do we judge if this model is any better? Write down the interpretation of the ar1 coefficient.\n\n\n\n\n\n4.7.5 Prediction\nNow that we have identified our best fitting ARIMA model, we can use the model to make predictions of claimant counts into the future. But, before we do this let us see how our model fitted our data.\n\nplot(as.ts(diff(log(df_claimants$count))), main = \"Logged claimaints (first difference)\", ylab = \"Rates\", xlab = \"Time\", type = \"l\", lty = 1, lwd = 2)\nlines(fitted(arima_m2), col= \"blue\", lwd = 2)\n\n\n\n\n\n\n\n\nThe model seems to have fitted our data relatively well, even the spike in claimants during 2020 and 2021. Let us now make a prediction of future claimants with the forecast.Arima function. We predict the claimants on the next 12 months:\n\narima_m2 %&gt;% \n  forecast(h = 12, \n           level = c(99)) %&gt;%  #confidence level 99% \n  autoplot() +\n  theme_bw() +\n  labs( y = \"Rates\", x = \"Time\")\n\n\n\n\n\n\n\n\nThe prediction suggests that the number of claimants are likely to vary within the range of -0.07 and 0.07 over the next 12 months of the time series.\n\n\n\n\nHyndman, Rob, and G. Athanasopoulos. 2021. Forecasting: Principles and Practice. 3rd ed. Australia: OTexts.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data modeling</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Appelhans, Tim, Florian Detsch, Christoph Reudenbach, and Stefan\nWoellauer. 2022. Mapview: Interactive Viewing of Spatial Data in\nr. https://github.com/r-spatial/mapview.\n\n\nBaddeley, Adrian, Ege Rubak, and Rolf Turner. 2015. Spatial Point\nPatterns: Methodology and Applications with r. CRC press.\n\n\nBaddeley, Adrian, Rolf Turner, and Ege Rubak. 2022. Spatstat:\nSpatial Point Pattern Analysis, Model-Fitting, Simulation, Tests.\nhttp://spatstat.org/.\n\n\nBivand, Roger. 2022. Spdep: Spatial Dependence: Weighting Schemes,\nStatistics.\n\n\nBivand, Roger, and Gianfranco Piras. 2022. Spatialreg: Spatial\nRegression Analysis. https://CRAN.R-project.org/package=spatialreg.\n\n\nDunnington, Dewey, Edzer Pebesma, and Ege Rubak. 2023. S2: Spherical\nGeometry Operators Using the S2 Geometry Library. https://CRAN.R-project.org/package=s2.\n\n\nHyndman, Rob, and G. Athanasopoulos. 2021. Forecasting: Principles\nand Practice. 3rd ed. Australia: OTexts.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2024.\nGeocomputation with r. Online. https://doi.org/10.1201/9780203730058.\n\n\nPebesma, Edzer. 2018. “Simple Features for R:\nStandardized Support for Spatial Vector Data.”\nThe R Journal 10 (1): 439–46. https://doi.org/10.32614/RJ-2018-009.\n\n\n———. 2022a. Sf: Simple Features for r. https://CRAN.R-project.org/package=sf.\n\n\n———. 2022b. Stars: Spatiotemporal Arrays, Raster and Vector Data\nCubes. https://CRAN.R-project.org/package=stars.\n\n\n———. 2023. Lwgeom: Bindings to Selected Liblwgeom Functions for\nSimple Features. https://github.com/r-spatial/lwgeom/.\n\n\nPebesma, Edzer J. 2004. “Multivariable Geostatistics in S: The\nGstat Package.” Computers & Geosciences 30 (7):\n683–91. https://doi.org/10.1016/j.cageo.2004.03.012.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With\nApplications in r. CRC Press.\n\n\nPebesma, Edzer, and Benedikt Graeler. 2022. Gstat: Spatial and\nSpatio-Temporal Geostatistical Modelling, Prediction and\nSimulation. https://github.com/r-spatial/gstat/.\n\n\nTennekes, Martijn. 2018. “tmap:\nThematic Maps in R.” Journal of Statistical\nSoftware 84 (6): 1–39. https://doi.org/10.18637/jss.v084.i06.\n\n\n———. 2022. Tmap: Thematic Maps. https://github.com/r-tmap/tmap.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nD’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019.\n“Welcome to the tidyverse.”\nJournal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023.\nR for Data Science. \" O’Reilly Media, Inc.\".\n\n\nXie, Yihui, J. J. Allaire, and Garrett Grolemund. 2018. R\nMarkdown. Chapman; Hall/CRC. https://doi.org/10.1201/9781138359444.",
    "crumbs": [
      "References"
    ]
  }
]