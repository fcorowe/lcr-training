[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R training: Liverpool City Region",
    "section": "",
    "text": "Contact\n\nProf. Francisco Rowe, Professor in Population Data Science\nf.rowe-gonzalez [at] liverpool.ac.uk\nDepartment of Geography and Planning, University of Liverpool, Liverpool, United Kingdom\n\n\nDr. Patrick Ballantyne, Postdoctoral Researcher in Geographic Data Science\np.ballantyne [at] liverpool.ac.uk\nDepartment of Geography and Planning, University of Liverpool, Liverpool, United Kingdom"
  },
  {
    "objectID": "00_overview.html",
    "href": "00_overview.html",
    "title": "Overview",
    "section": "",
    "text": "This workshop aims to provide R training to analysts in Liverpool City Region Combined Authority. Over four days we will cover a number of topics, which align with the current needs of the analyst team, demonstrating how R can be used for a diverse range of day-to-day analyst tasks."
  },
  {
    "objectID": "00_overview.html#structure",
    "href": "00_overview.html#structure",
    "title": "Overview",
    "section": "Structure",
    "text": "Structure\n\n\n\nDay\nActivity\n\n\n\n\n1\nR Fundamentals\n\n\n2\nData visualisation\n\n\n3\nDashboards & APIs\n\n\n4\nData modeling"
  },
  {
    "objectID": "00_overview.html#before-the-workshop",
    "href": "00_overview.html#before-the-workshop",
    "title": "Overview",
    "section": "Before the workshop",
    "text": "Before the workshop\n\n\n\n\n\n\nImportant\n\n\n\nPlease make sure you download and install the most recent version of R, RStudio and Quarto on the computer that you will be using during the workshop, and install the indicated R packages – see detailed instructions below.\n\n\n\n\n\n\n\n\nNote\n\n\n\nAll three software packages are open and free to use.\n\n\nR\nYou can download R here. Make sure you select the appropriate version for your Operating System: Windows, MacOS (Apple silicon M1/M2 or older intel Macs). For example, if you use a macOS laptop with an M1 processor, click on ‘Download R for macOS’ and then, click the link to download the installer file (.pkg extension for macOS) under the header ‘For Apple silicon (M1/M2) Macs’. You can then open the installer and follow the instructions that you will be prompted with. For Windows users, click on ‘install R for the first time’ and follow the prompts.\nRStudio\nYou will also need to download RStudio Desktop (or simply RStudio), which is an integrated development environment to help you write code in R more easily. To download RStudio, follow this link and scroll down to the section titled ‘All Installers and Tarballs’. Download the appropriate installer file according to your Operating System. Then, open the installer and follow the installation instructions that you will be prompted with.\nQuarto\nDownload Quarto from this website. Quarto is a publishing system that will allow you to open and work on the computational notebooks for the workshop. On ‘Step 1’ on the website, download the version of Quarto that matches your Operating System. Open the installer file, run it and follow the prompts.\nR packages\nOnce you have installed R, you will need to install some R extensions, known as packages, that will be useful for the applications explored in this workshop. The packages you need to install are:\n\ntidyverse\nggthemes\nzoo\nmice\npatchwork\nviridis\ntmap\nsf\nsp\nstringr\nRColorBrewer\nshowtext\nscales\nleaflet\ntmap\nmapdeck\nplotly\nhtmlwidgets\nnomisr\nflexdashboard\n\nTo install the packages, open RStudio. On the console window (normally at the bottom left), write the following command: install.packages(\"name of package\"). Make sure you replace “name of package” by the actual name of the package that you want to install e.g. install.packages(\"tidyverse\"). Then, press enter and repeat this process until you have installed all the packages in the list.\nYou can install all the packages by copying and running the code below:\n\nlist.of.packages.cran <- c(\n   \"tidyverse\",\n   \"ggthemes\",\n   \"zoo\",\n   \"mice\",\n   \"patchwork\",\n   \"viridis\",\n   \"tmap\",\n   \"sf\",\n   \"sp\",\n   \"stringr\",\n   \"RColorBrewer\",\n   \"showtext\",\n   \"scales\",\n   \"leaflet\",\n   \"tmap\",\n   \"mapdeck\",\n   \"plotly\",\n   \"htmlwidgets\",\n   \"nomisr\",\n   \"flexdashboard\"\n)\n\nnew.packages.cran <- list.of.packages.cran[!(list.of.packages.cran %in% installed.packages()[,\"Package\"])]\nif(length(new.packages.cran)) install.packages(new.packages.cran)\n\nfor(i in 1:length(list.of.packages.cran)) {\n  library(list.of.packages.cran[i], character.only = T)\n}\n\nYou can load all the packages by copying and running the code below:\n\ndeps <- list(\n   \"tidyverse\",\n   \"ggthemes\",\n   \"zoo\",\n   \"mice\",\n   \"patchwork\",\n   \"viridis\",\n   \"tmap\",\n   \"sf\",\n   \"sp\",\n   \"stringr\",\n   \"RColorBrewer\",\n   \"showtext\",\n   \"scales\",\n   \"leaflet\",\n   \"tmap\",\n   \"mapdeck\",\n   \"plotly\",\n   \"htmlwidgets\",\n   \"nomisr\",\n   \"flexdashboard\"\n)\n\nfor(lib in deps){library(lib, character.only = TRUE)}\n\n\n\n\n\n\n\nNote\n\n\n\nWe might ask you to install more packages on the day that this workshop is taking place.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nInstructions by email will be sent before the workshop to download the Github repository and data which will be used during the workshop. Please ensure you have downloaded the repository and data before the workshop."
  },
  {
    "objectID": "00_overview.html#during-the-workshop",
    "href": "00_overview.html#during-the-workshop",
    "title": "Overview",
    "section": "During the workshop",
    "text": "During the workshop\nAll the workshop material will be made available on this website which is currently under construction. Further instructions on how to download the material will be given during the workshop."
  },
  {
    "objectID": "01_data-description.html",
    "href": "01_data-description.html",
    "title": "1  Data",
    "section": "",
    "text": "1.1 Data 1",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "01_data-description.html#data-2",
    "href": "01_data-description.html#data-2",
    "title": "1  Data",
    "section": "1.2 Data 2",
    "text": "1.2 Data 2",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "01_data-description.html#data-3",
    "href": "01_data-description.html#data-3",
    "title": "1  Data",
    "section": "1.3 Data 3",
    "text": "1.3 Data 3",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "02_fundamentals.html",
    "href": "02_fundamentals.html",
    "title": "2  R Fundamentals",
    "section": "",
    "text": "This session will introduce the fundamental concepts, principles and tools that we will use during the course. Understanding these components provides the foundation for the rest of the course."
  },
  {
    "objectID": "02_fundamentals.html#plan-for-the-day",
    "href": "02_fundamentals.html#plan-for-the-day",
    "title": "2  R Fundamentals",
    "section": "2.1 Plan for the day",
    "text": "2.1 Plan for the day\n\n\n\nTime\nContent\n\n\n\n\n9.00 - 9.15\nIntroduction\n\n\n9.15 - 9.45\nSetting up & interacting with materials\n\n\n9.45 - 10.30\nR Basics\n\n\n10.30 - 10.50\nBreak\n\n\n10.50 - 11.50\nData types\n\n\n11.50 - 12.30\nNon-geographic data frames\n\n\n12.30 - 13.30\nLunch\n\n\n12.30 - 13.30"
  },
  {
    "objectID": "02_fundamentals.html#dependencies",
    "href": "02_fundamentals.html#dependencies",
    "title": "2  R Fundamentals",
    "section": "2.2 Dependencies",
    "text": "2.2 Dependencies\n\n# data manipulation\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.5.0     ✔ purrr   1.0.1\n✔ tibble  3.1.7     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.2     ✔ forcats 1.0.0\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n# spatial data manipulation\nlibrary(sf)\n\nLinking to GEOS 3.9.1, GDAL 3.3.2, PROJ 7.2.1; sf_use_s2() is TRUE"
  },
  {
    "objectID": "02_fundamentals.html#introducing-r",
    "href": "02_fundamentals.html#introducing-r",
    "title": "2  R Fundamentals",
    "section": "2.3 Introducing R",
    "text": "2.3 Introducing R\nR is a freely available language and environment for statistical computing and graphics which provides a wide variety of statistical and graphical techniques. It has gained widespread use in academia and industry. R offers a wider array of functionality than a traditional statistics package, is composed of core (base) functionality, and is expandable through libraries hosted on (The Comprehensive R Archive Network (CRAN))[]. CRAN is a network of ftp and web servers around the world that store identical, up-to-date, versions of code and documentation for R.\nCommands are sent to R using either the terminal / command line or the R Console which is installed with R on either Windows or OS X. On Linux, there is no equivalent of the console, however, third party solutions exist. On your own machine, R can be installed from here.\nNormally RStudio is used to implement R coding. RStudio is an integrated development environment (IDE) for R and provides a more user-friendly front-end to R than the front-end provided with R.\nTo run R or RStudio, just double click on the R or RStudio icon. Throughout this course, we will be using RStudio:\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you would like to know more about the various features of RStudio, watch this video."
  },
  {
    "objectID": "02_fundamentals.html#working-directory",
    "href": "02_fundamentals.html#working-directory",
    "title": "2  R Fundamentals",
    "section": "2.4 Working directory",
    "text": "2.4 Working directory\nBefore we start any analysis, ensure to set the path to the directory where we are working. We have two options to do this.\nOption 1\nOnce you have opened R, you can use the command setwd( ) to set the working directory. For example, replace in the following line the path to the folder where you have placed this file and where the data folder lives.\n\nsetwd(\"\")\n\nYou can check your current working directory by typing:\n\ngetwd()\n\nOption 2\nBefore opening any files in the folder, open the file with the extension *.Rproj. This is a R project and automatically indexes all the files in the folder and subfolders so there is no need to explicitly set the working directory. You can call any files in the R project folder by replacing the working directory with .. For instance, let us open a dataset from our subfolder data:\n\nread_csv(\"./data\")"
  },
  {
    "objectID": "02_fundamentals.html#r-scripts-and-quarto-documents",
    "href": "02_fundamentals.html#r-scripts-and-quarto-documents",
    "title": "2  R Fundamentals",
    "section": "2.5 R scripts and Quarto documents",
    "text": "2.5 R scripts and Quarto documents\n\n2.5.1 R script\nAn R script is a series of commands that you can execute at one time and help you save time. R scripts are useful to ensure reproducibility; that is if you want to repeat the same series of steps with the same or different datasets. An R script is a plain text file with R commands.\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo get familiar with good practices in writing your code in R, we recommend the Chapter Workflow: basics and Workflow: scripts and projects from the R in Data Science book by Wickham, Çetinkaya-Rundel, and Grolemund (2023)\n\n\nTo create an R script in RStudio, you need to: * Open a new script file: File > New File > R Script * Write some code on your new script window by typing eg. mtcars * Run the script. Click anywhere on the line of code, then hit Ctrl + Enter (Windows) or Cmd + Enter (Mac) to run the command or select the code chunk and click run on the right-top corner of your script window. If do that, you should get:\n\nmtcars\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nMazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nFiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\nHonda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\nToyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\nFiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\nPorsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\nLotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\nFord Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\nFerrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\nMaserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\nVolvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n\n\n\n\n2.5.2 Quarto Document\nA Quarto Document is based on Markdown technology. It allows to integrate descriptive text and code chunks. Code chunks can be executed independently and interactively, with output visible immediately beneath a code chunk - see Xie, Allaire, and Grolemund (2019). A Quarto Document is an improved version of the original R Notebook. Quarto Document requires a package called Quarto. Quarto does not have a dependency or requirement for R. Quarto is multilingual, beginning with R, Python, Javascript, and Julia. The concept is that Quarto will work even for languages that do not yet exist.\nTo create a Quarto Document, you need to:\n\nOpen a new script file: File > New File > Quarto Document.\nQuarto Documents work in the same way as R Notebooks with small variations. You can find a comprehensive guide on how to use Quarto Documents on the Quarto website.\n\n\n\n2.5.3 Using quarto documents\nQuarto documents are very flexible. They can be rendered into different formats, including pdf, html and doc files. They can be used to product reports, articles, briefs, websites, books and more. We can explore how this can be done using some of the templates we have produced and are hosted on our personal Github repository."
  },
  {
    "objectID": "02_fundamentals.html#help",
    "href": "02_fundamentals.html#help",
    "title": "2  R Fundamentals",
    "section": "2.6 Help",
    "text": "2.6 Help"
  },
  {
    "objectID": "02_fundamentals.html#r-data-types",
    "href": "02_fundamentals.html#r-data-types",
    "title": "2  R Fundamentals",
    "section": "2.7 R data types",
    "text": "2.7 R data types\n\n2.7.1 Factors"
  },
  {
    "objectID": "02_fundamentals.html#data-frames",
    "href": "02_fundamentals.html#data-frames",
    "title": "2  R Fundamentals",
    "section": "2.8 Data frames",
    "text": "2.8 Data frames\n\n2.8.1 Non-geographic data frames\nReading data frames\nCreating data frames\nReferencing data frames\nManipulating data frames\ntidyverse\n\n\n2.8.2 Geographic data frames\nReading geographic data frames\nManipulating geographic data frames"
  },
  {
    "objectID": "05_data-modeling.html",
    "href": "05_data-modeling.html",
    "title": "5  Data modeling",
    "section": "",
    "text": "estimation\ninterpretation / CIs, p-values, etc.\ndummy variables\nmulticollinearity"
  },
  {
    "objectID": "05_data-modeling.html#linear-regression",
    "href": "05_data-modeling.html#linear-regression",
    "title": "5  Data modeling",
    "section": "",
    "text": "estimation\ninterpretation / CIs, p-values, etc.\ndummy variables\nmulticollinearity",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data modeling</span>"
    ]
  },
  {
    "objectID": "05_data-modeling.html#time-series-data-modelling",
    "href": "05_data-modeling.html#time-series-data-modelling",
    "title": "5  Data modeling",
    "section": "5.2 Time series data modelling",
    "text": "5.2 Time series data modelling\n\nautoregressive (AR)\nseasonality / integration / diffencing (I)\nmoving average (MA)\nARIMA\nARIMAX (adding Xs)\nVAR???"
  },
  {
    "objectID": "03_data-visualisation.html",
    "href": "03_data-visualisation.html",
    "title": "3  Day 2 - Data Visualisation",
    "section": "",
    "text": "By the end of today’s session you should be able to:\n\nProduce static visualisations and maps using ggplot\nProduce more advanced static visualisations and maps, using advanced data wrangling techniques\nProduce interactive visualisations\nExplore reporting strategies for visualisation outputs"
  },
  {
    "objectID": "03_data-visualisation.html#introducing-todays-datasets",
    "href": "03_data-visualisation.html#introducing-todays-datasets",
    "title": "3  Day 2 - Data Visualisation",
    "section": "3.2 Introducing Today’s Dataset(s)",
    "text": "3.2 Introducing Today’s Dataset(s)\nFor today’s practical, we will be using a couple of different datasets.\nFirstly, we will be using data from the latest UK census - available from NOMIS. In particular, we will be looking at one specific census table; ‘Method of Travel to Work’, which describes the main method of transport people use to travel to work - e.g. by car, by bus, on foot etc.\nFor today’s, we will be using the table of data that is available for Lower Super Output Areas (LSOAs). Let’s go ahead and read the table of data in:\n\n## Read in the ts061 (LSOAs)\nts061 <- read.csv(\"data/census2021-ts061-lsoa.csv\")\n\nLet’s have a look at some of the attributes in the data:\n\n## Examine attributes\nhead(ts061)\n\n  date                 geography geography.code\n1 2021       City of London 001A      E01000001\n2 2021       City of London 001B      E01000002\n3 2021       City of London 001C      E01000003\n4 2021       City of London 001E      E01000005\n5 2021 Barking and Dagenham 016A      E01000006\n6 2021 Barking and Dagenham 015A      E01000007\n  Method.of.travel.to.workplace..Total..All.usual.residents.aged.16.years.and.over.in.employment.the.week.before.the.census\n1                                                                                                                       866\n2                                                                                                                       881\n3                                                                                                                      1000\n4                                                                                                                       496\n5                                                                                                                       888\n6                                                                                                                      1385\n  Method.of.travel.to.workplace..Work.mainly.at.or.from.home\n1                                                        639\n2                                                        676\n3                                                        618\n4                                                        203\n5                                                        192\n6                                                        370\n  Method.of.travel.to.workplace..Underground..metro..light.rail..tram\n1                                                                  35\n2                                                                  31\n3                                                                  74\n4                                                                  69\n5                                                                 205\n6                                                                 358\n  Method.of.travel.to.workplace..Train\n1                                   17\n2                                   10\n3                                   21\n4                                   25\n5                                  104\n6                                  177\n  Method.of.travel.to.workplace..Bus..minibus.or.coach\n1                                                   13\n2                                                   15\n3                                                   26\n4                                                   44\n5                                                   60\n6                                                  117\n  Method.of.travel.to.workplace..Taxi\n1                                   4\n2                                   2\n3                                   4\n4                                   2\n5                                   1\n6                                   8\n  Method.of.travel.to.workplace..Motorcycle..scooter.or.moped\n1                                                           3\n2                                                           1\n3                                                           4\n4                                                           3\n5                                                           5\n6                                                           3\n  Method.of.travel.to.workplace..Driving.a.car.or.van\n1                                                  18\n2                                                  19\n3                                                  24\n4                                                  33\n5                                                 227\n6                                                 220\n  Method.of.travel.to.workplace..Passenger.in.a.car.or.van\n1                                                        0\n2                                                        3\n3                                                        7\n4                                                        1\n5                                                       10\n6                                                       21\n  Method.of.travel.to.workplace..Bicycle Method.of.travel.to.workplace..On.foot\n1                                     24                                    109\n2                                     25                                     92\n3                                     62                                    143\n4                                     18                                     90\n5                                      6                                     61\n6                                     21                                     71\n  Method.of.travel.to.workplace..Other.method.of.travel.to.work\n1                                                             4\n2                                                             7\n3                                                            17\n4                                                             8\n5                                                            17\n6                                                            19\n\n\nBefore we start working with this data, we are going to tidy it up slightly. As you can probably see, the column names are long and messy, and the values in each column are raw counts, instead of percentages.\nMy preferred approach to tidying up data or ‘data wrangling’ is to use the ‘tidyverse’ suite of packages. One of the real benefits of tidyverse are tools called ‘pipes’ (%>%), which are used to emphasise a sequence of actions, linking a series of different data cleaning steps into one nice block of code.\nIn the example below I show how you can use pipes to select some desired columns (by name), rename them, and then convert one a percentage.\n\n## An example of data wrangling with pipes\nexample <- ts061 %>%\n  select(geography.code,\n         Method.of.travel.to.workplace..Total..All.usual.residents.aged.16.years.and.over.in.employment.the.week.before.the.census,\n         Method.of.travel.to.workplace..Work.mainly.at.or.from.home) %>% ## SELECT is used to select specific columns\n  rename(LSOA21CD = geography.code,\n         total = Method.of.travel.to.workplace..Total..All.usual.residents.aged.16.years.and.over.in.employment.the.week.before.the.census,\n         work_from_home = Method.of.travel.to.workplace..Work.mainly.at.or.from.home) %>% ## RENAME is used to rename columns individually\n  mutate(pctWFH = (work_from_home / total) * 100) ## MUTATE is used to create new columns, or modify existing ones \n\n## Inspect\nhead(example)\n\n   LSOA21CD total work_from_home   pctWFH\n1 E01000001   866            639 73.78753\n2 E01000002   881            676 76.73099\n3 E01000003  1000            618 61.80000\n4 E01000005   496            203 40.92742\n5 E01000006   888            192 21.62162\n6 E01000007  1385            370 26.71480\n\n\nOk, so that’s just one example of some steps you might take to tidy up a raw dataset from NOMIS into something a little bit more user friendly. There are lots of additional ‘data wrangling’ steps you might take as an analyst, some of which we will come onto later on, but for now we just need to apply these techniques to ts061 to get it ready for today’s practical, as below.\nIn the code block below, I am going to select columns by index rather than name, which works much better when you have a lot more columns. I am also going to apply the setNames() function to set all column names at once:\n\n## Tidy up ts061\nts061_clean <- ts061 %>%\n  select(3:15) %>% ## selects all columns between index 3 and 15\n  setNames(c(\"LSOA21CD\", \"total\", \"work_from_home\", \"underground_metro\", \"train\", \"bus_minibus_coach\", \n             \"taxi\", \"motorcycle\", \"car_driving\", \"car_passenger\", \"bicycle\", \"foot\", \"other\")) %>% ## applies new column names to those columns\n  mutate(work_from_home = (work_from_home / total) * 100, underground_metro = (underground_metro / total) * 100,\n         train = (train / total) * 100, bus_minibus_coach = (bus_minibus_coach / total) * 100,\n         taxi = (taxi / total) * 100, motorcycle = (motorcycle / total) * 100, \n         car_driving = (car_driving / total) * 100, car_passenger = (car_passenger / total) * 100,\n         bicycle = (bicycle / total) * 100, foot = (foot / total) * 100, other = (other / total) * 100)\n\n## Inspect\nhead(ts061_clean)\n\n   LSOA21CD total work_from_home underground_metro     train bus_minibus_coach\n1 E01000001   866       73.78753          4.041570  1.963048          1.501155\n2 E01000002   881       76.73099          3.518729  1.135074          1.702611\n3 E01000003  1000       61.80000          7.400000  2.100000          2.600000\n4 E01000005   496       40.92742         13.911290  5.040323          8.870968\n5 E01000006   888       21.62162         23.085586 11.711712          6.756757\n6 E01000007  1385       26.71480         25.848375 12.779783          8.447653\n       taxi motorcycle car_driving car_passenger   bicycle      foot     other\n1 0.4618938  0.3464203    2.078522     0.0000000 2.7713626 12.586605 0.4618938\n2 0.2270148  0.1135074    2.156640     0.3405221 2.8376844 10.442679 0.7945516\n3 0.4000000  0.4000000    2.400000     0.7000000 6.2000000 14.300000 1.7000000\n4 0.4032258  0.6048387    6.653226     0.2016129 3.6290323 18.145161 1.6129032\n5 0.1126126  0.5630631   25.563063     1.1261261 0.6756757  6.869369 1.9144144\n6 0.5776173  0.2166065   15.884477     1.5162455 1.5162455  5.126354 1.3718412\n\n\nSo now we have a nice tidy table, where each variable is now a percentage. The final step is to add some additional geographies to the table - in this case we will append on the corresponding Local Authority District for each LSOA.\nThe Open Geography Portal is a great place to find lookup tables for any administrative datasets in the UK. The specific table we have given you provides a lookup between Output Areas (OAs), Lower Super Output Areas (LSOAs), Middle Super Output Areas (MSOAs), Local Enterprise Partnerships (LEPs) and Local Authority Districts (LADs). Let’s read in the lookup table:\n\n## Read in the lookup table\nlookup <- read.csv(\"data/OAs_to_LSOAs_to_MSOAs_to_LEP_to_LAD_(May_2022)_Lookup_in_England.csv\")\n\n## Have a look at the data\nhead(lookup)\n\n     OA21CD  LSOA21CD        LSOA21NM  MSOA21CD       MSOA21NM  LEP21CD1\n1 E00060358 E01011968 Hartlepool 014D E02006909 Hartlepool 014 E37000034\n2 E00060359 E01011968 Hartlepool 014D E02006909 Hartlepool 014 E37000034\n3 E00060360 E01011968 Hartlepool 014D E02006909 Hartlepool 014 E37000034\n4 E00060361 E01011968 Hartlepool 014D E02006909 Hartlepool 014 E37000034\n5 E00060362 E01011970 Hartlepool 001C E02002483 Hartlepool 001 E37000034\n6 E00060363 E01011970 Hartlepool 001C E02002483 Hartlepool 001 E37000034\n     LEP21NM1 LEP21CD2 LEP21NM2   LAD22CD    LAD22NM ObjectId\n1 Tees Valley                   E06000001 Hartlepool        1\n2 Tees Valley                   E06000001 Hartlepool        2\n3 Tees Valley                   E06000001 Hartlepool        3\n4 Tees Valley                   E06000001 Hartlepool        4\n5 Tees Valley                   E06000001 Hartlepool        5\n6 Tees Valley                   E06000001 Hartlepool        6\n\n\nLookup tables often contain more information than you actually need. For example, the one above is structured so that every row is an Output Area (e.g., E00060361), and then the various columns link to other geographies - LSOA, LEP, LAD etc. What we are interested in doing is joining the LSOA-level census data from earlier, with the LAD-specific columns in the lookup table. So, we need to do a couple of things to the lookup table:\n\n## Tidy up the lookup\nlookup_clean <- lookup %>%\n  select(LSOA21CD, LAD22CD, LAD22NM) %>% ## select the LSOA and LAD columns\n  distinct() ## keeps only unique values, i.e., dropping all the additional rows for Output Areas\n\n## Look at the dataset\nhead(lookup_clean)\n\n   LSOA21CD   LAD22CD    LAD22NM\n1 E01011968 E06000001 Hartlepool\n2 E01011970 E06000001 Hartlepool\n3 E01011969 E06000001 Hartlepool\n4 E01011971 E06000001 Hartlepool\n5 E01033465 E06000001 Hartlepool\n6 E01033467 E06000001 Hartlepool\n\n\nThe final step is to attach the Local Authority variables (LAD22CD, LAD22NM) to our main dataset. This can be done in a number of ways, but I have a personal preference for integrating these kind of joins within pipes (as we have done so far).\n\n## Attach the LAD variables to the main dataset\ndb <- ts061_clean %>%\n  inner_join(lookup_clean, by = \"LSOA21CD\")\n\n## Look at the new attributes\ncolnames(db)\n\n [1] \"LSOA21CD\"          \"total\"             \"work_from_home\"   \n [4] \"underground_metro\" \"train\"             \"bus_minibus_coach\"\n [7] \"taxi\"              \"motorcycle\"        \"car_driving\"      \n[10] \"car_passenger\"     \"bicycle\"           \"foot\"             \n[13] \"other\"             \"LAD22CD\"           \"LAD22NM\"          \n\n\nOk, so we have a nice data set that is cleaned and ready for use in today’s practical."
  },
  {
    "objectID": "03_data-visualisation.html#static-data-visualisation-easy",
    "href": "03_data-visualisation.html#static-data-visualisation-easy",
    "title": "3  Day 2 - Data Visualisation",
    "section": "3.3 Static Data Visualisation (Easy)",
    "text": "3.3 Static Data Visualisation (Easy)\nFor most of today’s practical, we are going to be using the ggplot2 package to learn how to create nice visualisations in R. It is a really awesome package, has really excellent documentation and the quality of graphics it can produce is (arguably) second-to-none.\nHOWEVER…. Lot’s of people say that ggplot is a tricky syntax to get used to, as it requires a more ‘programmatic’ style of coding (e.g. piping), instead of line-by-line.\n\n3.3.1 The ‘grammar of graphics’\nBefore getting stuck into ggplot, there are a couple of key fundamentals that you need to learn, which comprise something called the ‘grammar of graphics’ The first relates to specifying the specific dataset that you are using to create a plot - it is very easy to do this:\n\n## Specify db as our source of data\nggplot(data = db)\n\n\n\n\nAs you can see, ggplot has opened a blank canvas which is going to rely on data from the ‘db’ object to create some form of visualisation.\nThe next fundamental relates to how the information from that source of data is going to be represented, which relies on use of ggplot’s mapping argument - aes(). With this argument, you are able to identify how different variables from your dataset can be visually represented.\nSo for example, let’s say we are interested in looking at the association between two variables in our dataset, plotting one on each axis:\n\n## Set some ggplot aesthetics\nggplot(data = db, aes(x = work_from_home, y = car_driving)) \n\n\n\n\nGgplot has now established that those are the two variables you wish to create your visualisation around, and has added axis’ that reflect the underlying distribution of these variables. The final fundamental stage is to introduce ‘geoms’ to our existing plot. Geoms are different types of objects that are used to represent data, including points, bars, lines etc. etc. We will explore lots of these today, but for now, let’s just consider plotting a scatter between the two variables in the plot above.\n\n## Add your first geom\nggplot(data = db, aes(x = work_from_home, y = car_driving)) +\n  geom_point()\n\n\n\n\nExcellent! Your first ggplot visualisation is now ready. It doesn’t look the best (right now), but hopefully you have a good understanding of those three fundamental concepts when using ggplot for plotting. So to recap, for every ggplot visualisation you need to be clear on:\n\nWhich dataset is being used to generate the visualisation\nHow you are going to map your variables to generate plot aesthetics (aes)\nThe specific type of geom that you want to use\n\nBefore we move on to exploring other types of data visualisation, let’s think about how we can make this plot better, by changing some of the default options.\n\n## Change some point parameters - size and transparency \nggplot(data = db, aes(x = work_from_home, y = car_driving)) +\n  geom_point(alpha = 0.3, size = 0.35) ## alpha is used to change the transparency of points\n\n\n\n\n\n## Add a trend line\nggplot(data = db, aes(x = work_from_home, y = car_driving)) +\n  geom_point(alpha = 0.3, size = 0.35) +\n  geom_smooth(method = \"lm\") ## geom_smooth is used to add an overall trend line to a plot\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n## Change axis titles\nggplot(data = db, aes(x = work_from_home, y = car_driving)) +\n  geom_point(alpha = 0.3, size = 0.35) +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Population who work from home (%)\", y = \"Population who drive to work (%)\") ## change the x and y axis labels\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nFor official reporting and academic publications, it is also important cite the data source used to generate the output, which can be done nicely with a caption in the labs() command:\n\n## Cite the data source\nggplot(data = db, aes(x = work_from_home, y = car_driving)) +\n  geom_point(alpha = 0.3, size = 0.35) +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Population who work from home (%)\", y = \"Population who drive to work (%)\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") ## set a caption for the plot\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe final tweak you might make to a plot like this is to change the plot theme. Ggplot has a number of themes that can be selected to change the general appearance of a plot. Here is one example:\n\n## Change the plot theme\nggplot(data = db, aes(x = work_from_home, y = car_driving)) +\n  geom_point(alpha = 0.3, size = 0.35) +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Population who work from home (%)\", y = \"Population who drive to work (%)\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_bw() ## sets a theme to the plot\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n3.3.2 Independent exercise - Over to you!\nHave a go at making some other modifications to the plot above:\n\nChange the variables that are being plotted on the x and y axis, to look at associations between different modes of travel.\nExplore different themes, and see which one you like most.\n(optional) See if you can figure out how to scale the x and y axis to be between 0 and 100, using the xlim() and ylim() commands.\n\n\n## Patrick's attempt\nggplot(data = db, aes(x = work_from_home, y = car_driving)) +\n  geom_point(alpha = 0.3, size = 0.35) +\n  geom_smooth(method = \"lm\") +\n  xlim(0, 100) +\n  ylim(0, 100) +\n  labs(x = \"Population who work from home (%)\", y = \"Population who drive to work (%)\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n3.3.3 Other static visualisations\nNow that you have a good understanding of how to construct a basic scatter plot using ggplot, and how to change some of the parameters to make your plot more visually appealing, we are going to do a quick overview of some simple visualisation techniques and how to build these in ggplot.\nFirstly, let’s have a look at building a histogram. NOTE: histograms are uni-dimensional, so you only need to set one variable in the aes() command:\n\n## Compute a histogram for one variable.\nggplot(data = db, aes(x = work_from_home)) +\n  geom_histogram(fill = \"orange\") +\n  labs(x = \"Population who work from home (%)\", y = \"Number of LSOAs\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nAlternatively, if you don’t like bar-style histograms, you can swap geom_histogram() for geom_density() to achieve a similar output:\n\n## Different style of histogram\nggplot(data = db, aes(x = work_from_home)) +\n  geom_density(fill = \"orange\") +\n  labs(x = \"Population who work from home (%)\", y = \"Number of LSOAs\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal()\n\n\n\n\nWe can also very easily plot a bar chart using ggplot. Let’s look at the distribution of LSOAs across LADs.\nBut first, let’s filter our dataset to only look at LSOAs within Liverpool City Region Combined Authority (LCRCA):\n\n## Filter to the six LADs that make up Liverpool City Region Combined Authority\ndb_lcr <- db %>%\n  filter(LAD22NM == \"Liverpool\" | LAD22NM == \"Wirral\" | LAD22NM == \"St. Helens\" | LAD22NM == \"Sefton\" | LAD22NM == \"Knowsley\" | LAD22NM == \"Halton\") ## filter allows you to filter specific values\n\n\n## Plot a bar chart\nggplot(data = db_lcr, aes(x = LAD22NM)) +\n  geom_bar(fill = \"orange\") +\n  labs(x = \"Local Authority District\", y = \"Number of LSOAs\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal()\n\n\n\n\nBy default, when you have one variable on the x axis and call geom_bar(), ggplot will return a count of the number of rows in each x axis value.\nSometimes, it’s more useful to flip the axis on a plot, especially when you have a lot of categories:\n\n## Flip the axis\nggplot(data = db_lcr, aes(x = LAD22NM)) +\n  geom_bar(fill = \"orange\") +\n  labs(x = \"Local Authority District\", y = \"Number of LSOAs\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() +\n  coord_flip() ## this command swaps the x and y axis\n\n\n\n\nFinally, you might be interested in changing how the bars are ordered, going from lowest to highest values.\n\n## Reorder bar plot\nggplot(data = db_lcr, aes(x = fct_infreq(LAD22NM))) + ## Use the fct_infreq to reorder the x axis values\n  geom_bar(fill = \"orange\") +\n  labs(x = \"Local Authority District\", y = \"Number of LSOAs\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() +\n  coord_flip()\n\n\n\n\nOr from highest to lowest:\n\n## Reorder bar plot\nggplot(data = db_lcr, aes(x = fct_rev(fct_infreq(LAD22NM)))) + ## Use the fct_rev() and fct_infreq() commands to reorder the x axis values\n  geom_bar(fill = \"orange\") +\n  labs(x = \"Local Authority District\", y = \"Number of LSOAs\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() +\n  coord_flip()\n\n\n\n\nWhat if we wanted to look at the underlying distribution of different commuting methods across the LADs? I really like dotplots as a visualisation technique, and published a paper using one recently.\nLet’s use a dotplot to look at the distribution of walking commuters across the six LADs:\n\n## Examine differences in people who walk to work\nggplot(data = db_lcr, aes(x = LAD22NM, y = foot)) +\n  geom_dotplot(binaxis = \"y\", stackdir = \"center\", stackratio = 0.5, dotsize = .3) +\n  labs(x = \"Local Authority District\", y = \"Population who walk to work(%)\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal()\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\nHowever, as you’re probably thinking, something more advanced might be needed to look at these differences. For example, if you calculated the average percentage of people who walk to work across the six LADs, what interesting story might that tell?\nWe will explore some of these ideas in the next part of the course, where I will show you how to reshape dataframes, and the importance of doing so for producing really powerful visualisations."
  },
  {
    "objectID": "03_data-visualisation.html#static-data-visualisation-harder",
    "href": "03_data-visualisation.html#static-data-visualisation-harder",
    "title": "3  Day 2 - Data Visualisation",
    "section": "3.4 Static Data Visualisation (Harder)",
    "text": "3.4 Static Data Visualisation (Harder)\nOk, so by now you should understand the basics of producing static visualisations with ggplot. Now, we are going to work towards building some better visualisations, which are not possible to achieve without learning more about reshaping data. If you are familar with pivot tables, its a similar concept!\nSo take our dataset for Liverpool City Region:\n\nhead(db_lcr)\n\n   LSOA21CD total work_from_home underground_metro     train bus_minibus_coach\n1 E01006412   570       11.22807         0.0000000 0.7017544         16.666667\n2 E01006413   524       12.59542         0.0000000 0.9541985         19.656489\n3 E01006414   481        9.97921         0.0000000 0.8316008         20.166320\n4 E01006415   956       18.93305         0.2092050 1.8828452          5.125523\n5 E01006416   588       15.47619         0.1700680 1.1904762          9.353741\n6 E01006417   529       16.82420         0.1890359 2.4574669          5.293006\n      taxi motorcycle car_driving car_passenger  bicycle      foot     other\n1 3.333333  0.3508772    47.71930     10.526316 2.982456  5.964912 0.5263158\n2 3.816794  0.5725191    45.61069      8.206107 1.145038  6.297710 1.1450382\n3 3.534304  0.4158004    47.19335      7.484407 1.663202  8.316008 0.4158004\n4 2.301255  0.3138075    53.97490      6.694561 1.987448  7.322176 1.2552301\n5 2.891156  0.0000000    43.87755      8.843537 4.081633 13.605442 0.5102041\n6 4.914934  0.0000000    47.63705      7.183365 3.024575 11.342155 1.1342155\n    LAD22CD  LAD22NM\n1 E08000011 Knowsley\n2 E08000011 Knowsley\n3 E08000011 Knowsley\n4 E08000011 Knowsley\n5 E08000011 Knowsley\n6 E08000011 Knowsley\n\n\nWe are interested in looking at average commuter behaviours between the six Local Authority Districts that make-up Liverpool City Region Combined Authority. To do so, I’m going to introduce two new commands - group_by() and summarise(). As an example, I’ll show you how to calculate the average percentage of people who walk to work in each LAD:\n\n## Calculate average walking to work in LADs\nwalk <- db_lcr %>%\n  select(LAD22NM, foot) %>%\n  group_by(LAD22NM) %>% ## tells R to calculate a different value for each LAD\n  summarise(foot = mean(foot)) ## tells R to calculate the average % of people who walk to work, per LAD\n\n## Look at the output\nwalk\n\n# A tibble: 6 × 2\n  LAD22NM     foot\n  <chr>      <dbl>\n1 Halton      7.74\n2 Knowsley    7.55\n3 Liverpool   9.82\n4 Sefton      7.21\n5 St. Helens  6.06\n6 Wirral      6.71\n\n\nThen we can produce an interesting visualisation that conveys this story:\n\n## Plot a bar chart\nggplot(data = walk, aes(x = fct_reorder(LAD22NM, -foot), y = foot)) + ## notice how I've set up the new column we calculated as the y axis value\n  geom_bar(stat = \"identity\", fill = \"orange\") + ## this is a slight bug - you need to tell R that each x axis value has it's own y axis value\n  labs(x = \"Local Authority District\", y = \"Population who walk to work (%)\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() \n\n\n\n\nNow let’s think about how we can look at differences in commuting patterns between all modes of transport. To do so, we need to calculate the average percentage of people using each mode of transport, in each LAD. Below I show how this can be done using the summarise_all() function, which can be applied when all columns are of the same data type:\n\n## Calculate average use of modes of transport between LADs\nlcr_avg <- db_lcr %>%\n  select(-c(LSOA21CD, total, LAD22CD)) %>% ## first you'll need to drop columns that you don't need anymore\n  group_by(LAD22NM) %>% ## calculates a value for every LAD\n  summarise_all(mean) ## calculates the mean value of every column, for every LAD\n\n## Look at the result\nhead(lcr_avg)\n\n# A tibble: 6 × 12\n  LAD22NM    work_…¹ under…² train bus_m…³  taxi motor…⁴ car_d…⁵ car_p…⁶ bicycle\n  <chr>        <dbl>   <dbl> <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 Halton        23.5  0.0407 0.778    3.68 0.891   0.410    54.1    5.77    2.15\n2 Knowsley      20.5  0.0734 2.52     7.29 2.08    0.259    50.3    6.41    1.77\n3 Liverpool     25.4  0.256  2.40    11.4  1.82    0.290    39.9    5.07    2.38\n4 Sefton        27.7  0.149  3.09     4.16 1.40    0.337    47.7    5.00    2.15\n5 St. Helens    22.5  0.0369 1.12     3.75 1.16    0.361    56.9    5.93    1.20\n6 Wirral        26.6  0.239  2.65     4.52 0.958   0.439    51.0    4.38    1.38\n# … with 2 more variables: foot <dbl>, other <dbl>, and abbreviated variable\n#   names ¹​work_from_home, ²​underground_metro, ³​bus_minibus_coach, ⁴​motorcycle,\n#   ⁵​car_driving, ⁶​car_passenger\n\n\nNow we need to think about reshaping this dataset. Why?\nWell if you look at the code used to produce the bar plot seen above, you’ll notice you can only put one command for x and y in the aes() parameter. Thus, we need to reshape our data from wide to long, so that all the %s are within one neat column that can be specified as the y axis variable.\nDon’t worry if this doesn’t make too much sense. The more you practice ggplot, the more you will begin to understand why reshaping is an important part of the grammar of graphics:\n\n## Reshape the dataset from wide to long\nlcr_avg <- lcr_avg %>%\n  pivot_longer(!LAD22NM, names_to = \"variable\", values_to = \"avg_pct\") \n\n## Have a look at the output\nhead(lcr_avg)\n\n# A tibble: 6 × 3\n  LAD22NM variable          avg_pct\n  <chr>   <chr>               <dbl>\n1 Halton  work_from_home    23.5   \n2 Halton  underground_metro  0.0407\n3 Halton  train              0.778 \n4 Halton  bus_minibus_coach  3.68  \n5 Halton  taxi               0.891 \n6 Halton  motorcycle         0.410 \n\n\nOk, so now we have all the modes of transport in one column, and a corresponding column which details the % of people who use that mode of transport. Let’s explore some visualisation options here - firstly, a stacked bar chart. Notice the additional parameter set in the aes() command, which tells R to colour the bars by the different modes of transport.\n\n## Stacked bar chart\nggplot(data = lcr_avg, aes(x = LAD22NM, y = avg_pct, fill = variable)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Local Authority District\", y = \"(Average) Population (%)\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() \n\n\n\n\nThere are a few things you can do to change the legend title used to represent the different colours, firstly you can set a new legend title using the labs() command:\n\n## Change label\nggplot(data = lcr_avg, aes(x = LAD22NM, y = avg_pct, fill = variable)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Local Authority District\", y = \"(Average) Population (%)\", fill = \"Mode of Transport\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() \n\n\n\n\nSecond, you can remove it completely:\n\n## Remove label\nggplot(data = lcr_avg, aes(x = LAD22NM, y = avg_pct, fill = variable)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Local Authority District\", y = \"(Average) Population (%)\", fill = NULL,\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() \n\n\n\n\nOr reposition the labels to be at the bottom of the plot:\n\n## Change label\nggplot(data = lcr_avg, aes(x = LAD22NM, y = avg_pct, fill = variable)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Local Authority District\", y = \"(Average) Population (%)\", fill = NULL,\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\nHowever, I think for something like average populations, it’s better to use an unstacked bar chart, which tells a much clearer story. Furthermore, I would probably swap what is being plotted on the axis, to make the plot even clearer, and flip the axis so you can see the different x axis labels.\n\n## Unstacked bar chart\nggplot(data = lcr_avg, aes(x = variable, y = avg_pct, fill = LAD22NM)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(x = \"Mode of Transport\", y = \"(Average) Population (%)\", fill = NULL,\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  coord_flip() +\n  theme_minimal() \n\n\n\n\n\n3.4.1 Independent exercise - Over to you!\nHave a go at the following:\n\nSee what changes if you ask the summarise_all() command above to calculate median instead of mean.\nHave a go at changing the colour palette used on the plot above, using the scale_fill_brewer() command. Have a look at the documentation for some help with this.\n\nSee if you can figure out how to generate a facet plot, where six individual plots are created, one per LAD, instead of applying different colours for each LAD. Have a look at this tutorial for some support with this.\n\nSOLUTION - EXERCISE 2\n\n## My solution\nggplot(data = lcr_avg, aes(x = variable, y = avg_pct, fill = LAD22NM)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  labs(x = \"Mode of Transport\", y = \"(Average) Population (%)\", fill = NULL,\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  coord_flip() +\n  theme_minimal() \n\n\n\n\nSOLUTION - EXERCISE 3\n\n## My solution\nggplot(data = lcr_avg, aes(x = variable, y = avg_pct)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  labs(x = \"Mode of Transport\", y = \"(Average) Population (%)\", fill = NULL,\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  coord_flip() +\n  facet_wrap(~ LAD22NM) +\n  theme_minimal() \n\n\n\n\n\n\n3.4.2 For the spatial peeps!\nFinally, before we move on to talk about interactive visualisations, I want to do a quick overview of how you can use R to make maps. There is a whole host of GIS functionality within the R ecosystem (see links below), but one of the nice things about R is that it also works really well as as a cartographic tool.\nLet’s return to our original dataset - LSOA level breakdown of different commuting patterns:\n\n## Inspect\nhead(db)\n\n   LSOA21CD total work_from_home underground_metro     train bus_minibus_coach\n1 E01000001   866       73.78753          4.041570  1.963048          1.501155\n2 E01000002   881       76.73099          3.518729  1.135074          1.702611\n3 E01000003  1000       61.80000          7.400000  2.100000          2.600000\n4 E01000005   496       40.92742         13.911290  5.040323          8.870968\n5 E01000006   888       21.62162         23.085586 11.711712          6.756757\n6 E01000007  1385       26.71480         25.848375 12.779783          8.447653\n       taxi motorcycle car_driving car_passenger   bicycle      foot     other\n1 0.4618938  0.3464203    2.078522     0.0000000 2.7713626 12.586605 0.4618938\n2 0.2270148  0.1135074    2.156640     0.3405221 2.8376844 10.442679 0.7945516\n3 0.4000000  0.4000000    2.400000     0.7000000 6.2000000 14.300000 1.7000000\n4 0.4032258  0.6048387    6.653226     0.2016129 3.6290323 18.145161 1.6129032\n5 0.1126126  0.5630631   25.563063     1.1261261 0.6756757  6.869369 1.9144144\n6 0.5776173  0.2166065   15.884477     1.5162455 1.5162455  5.126354 1.3718412\n    LAD22CD              LAD22NM\n1 E09000001       City of London\n2 E09000001       City of London\n3 E09000001       City of London\n4 E09000001       City of London\n5 E09000002 Barking and Dagenham\n6 E09000002 Barking and Dagenham\n\n\nWe are going to be producing an LSOA-level map for Liverpool City Region Combined Authority, so let’s filter the dataset to the six LADs in LCRCA:\n\n## Filter to LCRCA\nlsoa_lcr <- db %>%\n  filter(LAD22NM == \"Liverpool\" | LAD22NM == \"Wirral\" | LAD22NM == \"St. Helens\" | LAD22NM == \"Sefton\" | LAD22NM == \"Knowsley\" | LAD22NM == \"Halton\")\n\nNow we need a set of LSOA polygons to plot the map with. You covered spatial data formats briefly yesterday with Francisco, so this should be relatively familiar. We have provided a set of LSOAs for Liverpool, which you can read in as below:\n\n## Read in the LSOAs\nlsoa <- st_read(\"data/LCR-LSOA.gpkg\")\n\nReading layer `LCR-LSOA' from data source \n  `C:\\Users\\pball24\\My Drive\\Patrick Academic\\PDRA\\Projects\\lcr-training\\data\\LCR-LSOA.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1043 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 318351.7 ymin: 377513.8 xmax: 361791.1 ymax: 422866.5\nProjected CRS: OSGB 1936 / British National Grid\n\n## Inspect\nhead(lsoa)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 356526.1 ymin: 397294.1 xmax: 359746.3 ymax: 399734.2\nProjected CRS: OSGB 1936 / British National Grid\n   LSOA21CD   LSOA21NM                               GlobalID Rank. Decile\n1 E01006220 Wigan 035A {6A968831-6B5B-42A7-AFDE-9A2FD2E01FE2}     5      5\n2 E01006225 Wigan 036B {0727B328-8FBD-4074-A887-A40CB89502E2}     9      9\n3 E01006226 Wigan 035E {8A587355-7518-47EF-A60A-6CB117F54F05}     8      8\n4 E01006227 Wigan 038A {CC387BCB-5B3B-4E57-ABA3-4ADB3175D624}     8      8\n5 E01006264 Wigan 036D {89C9660D-5EC9-4498-BEBF-BED018377F41}    10     10\n6 E01006346 Wigan 038E {37DD7E6B-F345-400F-BD76-D8700BFCE534}     7      7\n       Top  Bottom.                           geom\n1 17.47911 42.96657 MULTIPOLYGON (((359223.5 39...\n2 39.40579 27.52150 MULTIPOLYGON (((356696.7 39...\n3 29.37013 36.02265 MULTIPOLYGON (((358079.4 39...\n4 27.95950 37.14953 MULTIPOLYGON (((359464.4 39...\n5 38.51224 26.55367 MULTIPOLYGON (((356526.2 39...\n6 28.96305 36.88915 MULTIPOLYGON (((359465.7 39...\n\n\nThe ‘geom’ column is the most important here - this is what stores the spatial information needed to produce maps. Let’s just extract the LSOA code and the ‘geom’ column.\n\n## Tidy up\nlsoa <- lsoa %>%\n  select(LSOA21CD, geom)\n\nOk, final ‘boring’ step before getting to mapmaking is the joining of our census data with the polygons. As you can probably see from your environment, there is a mismatch between the number of rows in the ‘lsoa’ object and our ‘lsoa_lcr’ object which contains the census data. Thus, when we merge these two datasets together, we want it to return only those rows which match:\n\n## Merge census data with polygons\nlsoa <- merge(lsoa, lsoa_lcr, by = \"LSOA21CD\", all.y = TRUE)\n\nNow we’re ready to make a map! Let’s return to some ggplot fundamentals - remember that you need to set the data, but this time ignore the aesthetics:\n\n## Set the data\nggplot(data = lsoa)\n\n\n\n\nNow, to plot a map using ggplot, you need to use a specific geom type that was built for mapping with - geom_sf(). Remember that the data type of our spatial data is called a ‘simple feature’ or ‘sf’:\n\nstr(lsoa)\n\nClasses 'sf' and 'data.frame':  1003 obs. of  16 variables:\n $ LSOA21CD         : chr  \"E01006412\" \"E01006413\" \"E01006414\" \"E01006415\" ...\n $ total            : int  570 524 481 956 588 529 547 755 1337 623 ...\n $ work_from_home   : num  11.23 12.6 9.98 18.93 15.48 ...\n $ underground_metro: num  0 0 0 0.209 0.17 ...\n $ train            : num  0.702 0.954 0.832 1.883 1.19 ...\n $ bus_minibus_coach: num  16.67 19.66 20.17 5.13 9.35 ...\n $ taxi             : num  3.33 3.82 3.53 2.3 2.89 ...\n $ motorcycle       : num  0.351 0.573 0.416 0.314 0 ...\n $ car_driving      : num  47.7 45.6 47.2 54 43.9 ...\n $ car_passenger    : num  10.53 8.21 7.48 6.69 8.84 ...\n $ bicycle          : num  2.98 1.15 1.66 1.99 4.08 ...\n $ foot             : num  5.96 6.3 8.32 7.32 13.61 ...\n $ other            : num  0.526 1.145 0.416 1.255 0.51 ...\n $ LAD22CD          : chr  \"E08000011\" \"E08000011\" \"E08000011\" \"E08000011\" ...\n $ LAD22NM          : chr  \"Knowsley\" \"Knowsley\" \"Knowsley\" \"Knowsley\" ...\n $ geometry         :sfc_MULTIPOLYGON of length 1003; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:407, 1:2] 342811 342810 342809 342808 342779 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:15] \"LSOA21CD\" \"total\" \"work_from_home\" \"underground_metro\" ...\n\n\nGeom_sf works really well with these types of data, so let’s add it to the code above and see what happens:\n\n## Add a polygon geom\nggplot(data = lsoa) +\n  geom_sf()\n\n\n\n\nNice! Almost there… now just to tweak the geom_sf command to enable colouring of the polygons based on values. In this example let’s focus on train usage. Notice how aes() is used directly in the geom_sf() command this time instead of in the ggplot() command.\n\n## Plot a choropleth map\nggplot(data = lsoa) +\n  geom_sf(aes(fill = train)) \n\n\n\n\nAwesome! Now let’s tweak some of the plotting parameters to make this much more effective:\n\n## Improve the map\nggplot(data = lsoa) +\n  geom_sf(aes(fill = train), color = NA) + ## color = NA removes the borders\n  scale_fill_viridis_c() + ## sets a different colour palette\n  labs(fill = \"Rail Commuters (%)\", caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") + ## some labels\n  theme_minimal()\n\n\n\n\nAwesome! You’ve made a really nice map using R with literally only a couple of lines of code. Take a look at Geocomputation with R if you are interested in learning more about how to use R to make maps, or as a GIS. The syntax for different spatial operations (spatial join, intersection etc.) is really intuitive!"
  },
  {
    "objectID": "03_data-visualisation.html#interactive-data-visualisation",
    "href": "03_data-visualisation.html#interactive-data-visualisation",
    "title": "3  Day 2 - Data Visualisation",
    "section": "3.5 Interactive Data Visualisation",
    "text": "3.5 Interactive Data Visualisation\nOk, so for the final part of today’s practical we are going to explore some options for producing interactive visualisations using R. By interactive we mean producing a visual representation of data that can be explored and analysed directly within the visualisation itself.\nWe will be focusing on two types of interactive visualisation:\n\nInteractive non-spatial - e.g. graphs, charts\nInteractive spatial - e.g. maps\n\n\n3.5.1 Interactive non-spatial visualisations\nThroughout today’s practical, we’ve constructed a large volume of static plots, like bar charts, histograms etc. If you want to turn any of these into something interactive, this is really easy! All you need to do is use ggplotly() function from the ‘plotly’ package, which converts an existing ggplot visualisation into something interactive.\nLet’s test it on one of our earlier plots - the unstacked bar chart.\n\n## Produce the static plot - note it needs to be saved as an object\np <- ggplot(data = lcr_avg, aes(x = variable, y = avg_pct, fill = LAD22NM)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_fill_brewer(palette = \"Dark2\") +\n  labs(x = \"Mode of Transport\", y = \"(Average) Population (%)\", fill = NULL,\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  coord_flip() +\n  theme_minimal() \n\n## Produce the interactive version\nggplotly(p)\n\n\n\n\n\nHow easy was that!\nI think this works really well when you have quite a lot of information, and it’s difficult to unpack exactly the individual trends. A good example of this was the stacked bar chart we produced earlier:\n\n## Produce the stacked bar chart again\np2 <- ggplot(data = lcr_avg, aes(x = LAD22NM, y = avg_pct, fill = variable)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Local Authority District\", y = \"(Average) Population (%)\", fill = NULL,\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal() \n\n## Produce the interactive version\nggplotly(p2)\n\n\n\n\n\nThere are lots of ways you can use an interactive plot like this. One is to utilise the Quarto formats we have introduced in this course to produce reports, where you embed the interactive visualisation within the report.\nAlternatively, you can export the interactive chart to both .html and .png formats. To save as a .html file, you need the htmlwidgets package to be installed.\nLet’s export the stacked bar chart as a .html file:\n\n## First assign the interactive plot to a new object\ni <- ggplotly(p2)\n\n## Save the file\nsaveWidget(i, file = \"figs/Stack.html\")\n\n\n\n3.5.2 Independent exercise - Over to you!\n\nSee if you can produce interactive versions of some of the other visualisations we have made today.\nCheck you know how to save these to .html files\n(optional) Start tweaking what appears in the pop-ups on the interactive visualisations - you need to think about what data is being displayed from the original data frame, and how you might modify the original data frame to make the pop ups better.\n\n\n\n3.5.3 Interactive spatial visualisations\nIf you want to turn the ggplot map we made earlier into something interactive, the easiest option is to actually use a different package - tmap. Tmap has a really nice hookup to leaflet, which makes it really easy to plot maps interactively.\nTo reproduce the map above in tmap, here’s the code:\n\n## Choropleth map in tmap\ntm_shape(lsoa) +\n  tm_fill(col = \"train\", title = \"Rail Commuters (%)\", palette = \"viridis\") +\n  tm_layout(frame = FALSE)\n\n\n\n\nTo make this interactive, you need to change the default plotting mode in tmap:\nReplot the map and see what happens:\n\n## Choropleth map in tmap (interactive)\ntm_shape(lsoa) +\n  tm_fill(col = \"train\", title = \"Rail Commuters (%)\", palette = \"viridis\", alpha = 0.7) + ## Lower the transparency, so you can see the basemap\n  tm_layout(frame = FALSE)\n\n\n\n\n\n\nTo save this interactive map to a .html file, you just need to save the interactive map as an object, and then run the tmap_save() command to export to a .html.\n\n## Save the map to an object\np3 <- tm_shape(lsoa) +\n  tm_fill(col = \"train\", title = \"Rail Commuters (%)\", palette = \"viridis\", alpha = 0.7) + ## Lower the transparency, so you can see the basemap\n  tm_layout(frame = FALSE)\n\n## Save as a .html\ntmap_save(p3, \"figs/Map.html\")\n\nInteractive map saved to C:\\Users\\pball24\\My Drive\\Patrick Academic\\PDRA\\Projects\\lcr-training\\figs\\figs\\Map.html\n\n\n\n\n3.5.4 Independent exercise - Over to you!\n\nHave a go at mapping different variables, by playing with the col() command in tmap.\nThink about what additional spatial information you might add to a map like this to tell a good story - chat to Patrick. Clue: how might data on transport infrastructure help to explain differences in public transport usage.\n(optional) Download another spatial dataset, and have a go at trying to produce a map with it."
  },
  {
    "objectID": "03_data-visualisation.html#additional-resources",
    "href": "03_data-visualisation.html#additional-resources",
    "title": "3  Day 2 - Data Visualisation",
    "section": "3.6 Additional Resources",
    "text": "3.6 Additional Resources\nAs I said at the beginning of the practical, ggplot really benefits from a great community which contributes lots of documentation and examples about how to use ggplot for different applications.\nA really cool resource is this - Top 50 ggplot2 visualisations. It has lots of examples of different visualisation techniques that ggplot can be used for.\nThis book is really awesome too - R for Data Science. It was written by Hadley Wickham, who introduced ggplot and the tidyverse to the R world.\nIf interested in using R as a GIS, this free online book is excellent - Geocomputation with R."
  },
  {
    "objectID": "04_dashboards-api.html",
    "href": "04_dashboards-api.html",
    "title": "4  Dashboards and APIs",
    "section": "",
    "text": "By the end of today’s session you should be able to:\n\nUnderstand the basic principles of APIs\nDownload and visualise data from NOMIS using the NOMIS API\nUnderstand the basic principles of flexdashboard\nBuild a basic dashboard using flexdashboard"
  },
  {
    "objectID": "04_dashboards-api.html#introduction-to-apis",
    "href": "04_dashboards-api.html#introduction-to-apis",
    "title": "4  Dashboards and APIs",
    "section": "4.2 Introduction to APIs",
    "text": "4.2 Introduction to APIs\nWeb services make their data easily accessible to computer programs like R through use of an Application Programming Interface (API). Today’s practical will teach you how to access data from APIs, and load them into your R environment for analysis.\nTo download data from an API you need to send a HTTP request to a server, which tells the server to return the specific parcel of data that matches the criteria in the HTTP request.\nFor example, on NOMIS there is a page called ‘Census 2021 Bulk Data Download’, which contains .zip files for different tables of data available from the latest census.\nNow you should go to the ‘Census 2021 Bulk Data Download’ page, and see what it contains.\n\n\n\nNOMIS\n\n\nThere are lots of files on the web page - e.g. census2021-ts001.zip, census2021-ts007a.zip.\nYou can click on these files individually, download them to your PC, unzip them and read them into R. Alternatively, we can programmatically download the data directly from the webpage.\nIf you ‘right click’ on one of the .zip files and press ‘copy link’, you will have a URL which can access that specific .zip file, as below:\n\nurl <- \"https://www.nomisweb.co.uk/output/census/2021/census2021-ts061.zip\"\nurl\n\n[1] \"https://www.nomisweb.co.uk/output/census/2021/census2021-ts061.zip\"\n\n\nThe specific URL above relates to table TS061 - “Method of Travel to Work”, which is the same dataset we were using in the Data Visualisation workshop.\nNow I’m going to show you how to download the .zip file, and read in the file of data we used yesterday. This is a really basic example of using an API, which shows how you can download data from NOMIS into your environment, without having to physically go and download it, save it to a folder, unzip it and read it into memory.\nFirst, let’s download the .zip file - this line of code downloads the .zip file to your local machine. It creates a new file in your working directory called ‘temp.zip’ - go and take a look!\n\n## Download the .zip file, using the url set above\ndownload.file(url, \"temp.zip\")\n\nNext we need to unzip the folder, to get to the datasets stored within:\n\n## First set where you want the unzipped files to be stored\noutDir <- \"data/unzip\"\n## Unzip the folder to the data/unzip folder\nunzip(\"temp.zip\", exdir = outDir)\n\nOk so now that you’ve downloaded the files to your local machine, we can look and see what files are available to us:\n\n## Use list.files() to see what we unzipped\nlist.files(\"data/unzip\")\n\n[1] \"census2021-ts061-ctry.csv\" \"census2021-ts061-lsoa.csv\"\n[3] \"census2021-ts061-ltla.csv\" \"census2021-ts061-msoa.csv\"\n[5] \"census2021-ts061-oa.csv\"   \"census2021-ts061-rgn.csv\" \n[7] \"census2021-ts061-utla.csv\" \"metadata\"                 \n\n\nThankfully, NOMIS use a really standard naming protocol for their files, which makes it really easy to tell what each of the files contains. If you cast your mind back to yesterday, we used a file called “census2021-ts061-lsoa.csv”, which we provided to you as part of the course materials. However, as you can see from the code above, you have now programmatically downloaded the same file, which we can read in:\n\n## Read in the LSOA census data\ndb <- read.csv(\"data/unzip/census2021-ts061-lsoa.csv\")\n\n\n4.2.1 Independent exercise - Over to you! (15 - 20 mins)\n\nAs a recap, see if you can reproduce one of the visualisations we produced yesterday using the data we have just scraped from the API.\nTest downloading two more datasets from NOMIS, by swapping in new URLs, and reading in one of the files from the folder you download.\n(optional) Produce an interesting visualisation from that new dataset.\n\nSolution 2\n\n## Set the new URL\nurl2 <- \"https://www.nomisweb.co.uk/output/census/2021/census2021-ts066.zip\"\n\n## Download the files\ndownload.file(url2, \"temp2.zip\")\n\n## Unzip the files\noutDir2 <- \"data/unzip2\"\n## Unzip the folder to the data/unzip folder\nunzip(\"temp2.zip\", exdir = outDir2)\n\n## Read in the LSOA census data\ndb2 <- read.csv(\"data/unzip2/census2021-ts066-lsoa.csv\")\n\n## Select some columns to work with, and calculate % student\ndb2_clean <- db2 %>%\n  select(geography.code, Economic.activity.status..Total..All.usual.residents.aged.16.years.and.over, Economic.activity.status..Economically.inactive..Student) %>%\n  setNames(c(\"LSOA21CD\", \"total\", \"student\")) %>%\n  mutate(student = (student / total) * 100)\n\nSolution 3\n\n## Produce a histogram\nggplot(data = db2_clean, aes(x = student)) +\n  geom_density(fill = \"orange\") +\n  labs(x = \"Population who are students (%)\", y = \"Number of LSOAs\",\n       caption = \"Data: UK Census (2021) - 'Economic Activity Status' (ts066)\") +\n  theme_minimal()\n\n\n\n\nSo what have we achieved?\n\nYou can now programmatically download datasets from the NOMIS bulk census page, without needing to download the files.\nYou can produce visualisations using these different datasets.\nYou are in a position to automate download and visualisation of census data from NOMIS.\n\nHowever, there is one easier way of getting the data from NOMIS, and this involves use of the NOMIS API."
  },
  {
    "objectID": "04_dashboards-api.html#using-the-nomis-api",
    "href": "04_dashboards-api.html#using-the-nomis-api",
    "title": "4  Dashboards and APIs",
    "section": "4.3 Using the NOMIS API",
    "text": "4.3 Using the NOMIS API\nOne of the things that you see more commonly in practice is the construction of specific R packages used to access APIs, with supporting documentation and specific functions that make it easier to use the API.\nOne such example is nomisr, which is an R package that was built to enable users to query data from NOMIS. It is free to access and contains up-to-date official statistics including data from the latest Census, Labour Force Survey and DWP benefit statistics.\nIn the section that follows, I’m going to be showing you how to use the nomisr package to download datasets.\nVast amounts of data are available through NOMIS, so you need to use some of the different functions within nomisr to identify the specific datasets you want to use. An example is presented below which searches for datasets within NOMIS that are specifically about ‘Travel’:\n\n## Search for data on Labour Force\nsearch <- nomis_search(\"*Travel*\")\n\nThis returns a dataframe (which you should see in your environment) that describes all of the different NOMIS held datasets where ‘Travel’ is mentioned. The column perhaps of most interest is the short name for the different datasets, which you can inspect below:\n\n## Have a look at the first six datasets \nhead(search$name.value)\n\n[1] \"2001 census - UK travel flows (local authority)\"            \n[2] \"2001 census - Scottish travel flows (local authority)\"      \n[3] \"2001 census - UK travel flows (ward)\"                       \n[4] \"QS702EW - Distance travelled to work\"                       \n[5] \"WD702EW - Distance travelled to work (Workday population)\"  \n[6] \"WP702EW - Distance travelled to work (Workplace population)\"\n\n\nIf you open up the dataframe in your environment and scroll down you should see one row has the value - TS061 - Method used to travel to work - which is the one we’ve been using a lot in this practical.\nWe can filter to this row very easily using the filter() command that we introduced yesterday:\n\n## Filter to row of interest\nsearch_sub <- search %>%\n  filter(name.value == \"TS061 - Method used to travel to work\")\n\n## Have a look at the result\nsearch_sub\n\n# A tibble: 1 × 12\n  agencyid id      uri   version annot…¹ compo…² compo…³ compo…⁴ compo…⁵ compo…⁶\n  <chr>    <chr>   <chr>   <dbl> <list>  <list>  <list>  <chr>   <chr>   <chr>  \n1 NOMIS    NM_207… Nm-2…       1 <df>    <df>    <df>    OBS_VA… CL_207… TIME   \n# … with 2 more variables: name.value <chr>, name.lang <chr>, and abbreviated\n#   variable names ¹​annotations.annotation, ²​components.attribute,\n#   ³​components.dimension, ⁴​components.primarymeasure.conceptref,\n#   ⁵​components.timedimension.codelist, ⁶​components.timedimension.conceptref\n\n\nNotice how the table ID is NM_2078_1.\nWe can get some metadata for this dataset very easily using the nomis_get_metadata() command. First, let’s see what measures are available:\n\n## Supply the ID of the row we're interested in, and the second parameters specifies we'd like to know more about the measures\nnomis_get_metadata(search_sub$id, \"measures\")\n\n# A tibble: 2 × 3\n  id    label.en description.en\n  <chr> <chr>    <chr>         \n1 20100 value    value         \n2 20301 percent  percent       \n\n\nSo for TS061, we can get both raw counts (‘value’) and percent. Notice how the ID for counts is 20100 and the ID for percent is 20301. Let’s now see what geographies are available:\n\n## Supply the ID of the row we're interested in, and the second parameter specifies that we want to know more about geographies\nnomis_get_metadata(search_sub$id, \"geography\")\n\n# A tibble: 3 × 4\n  id         parentCode label.en          description.en   \n  <chr>      <chr>      <chr>             <chr>            \n1 2092957703 <NA>       England and Wales England and Wales\n2 2092957699 <NA>       England           England          \n3 2092957700 2092957700 Wales             Wales            \n\n\nOk, so this is telling us the different geographic levels we can download the data for. However, if we add an additional parameter to this, we can also see the specific geographic units that this data is available at:\n\n## Add in an additional parameter\nnomis_get_metadata(search_sub$id, \"geography\", \"TYPE\")\n\n# A tibble: 12 × 3\n   id      label.en                                                 descriptio…¹\n   <chr>   <chr>                                                    <chr>       \n 1 TYPE150 2021 output areas                                        2021 output…\n 2 TYPE151 2021 super output areas - lower layer                    2021 super …\n 3 TYPE152 2021 super output areas - middle layer                   2021 super …\n 4 TYPE153 2022 wards                                               2022 wards  \n 5 TYPE154 2022 local authorities: districts                        2022 local …\n 6 TYPE155 2022 local authorities: counties                         2022 local …\n 7 TYPE168 2021 national parks                                      2021 nation…\n 8 TYPE423 local authorities: county / unitary (as of April 2023)   local autho…\n 9 TYPE424 local authorities: district / unitary (as of April 2023) local autho…\n10 TYPE459 local enterprise partnerships (as of April 2021)         local enter…\n11 TYPE480 regions                                                  regions     \n12 TYPE499 countries                                                countries   \n# … with abbreviated variable name ¹​description.en\n\n\nSo there are a variety of different geographic levels at which we can download the dataset, including LSOA - see 2021 super output areas - lower layer. Notice how the ID for LSOAs is TYPE151.\nThose steps we have just performed basically give us everything we need to download the dataset directly from the NOMIS API using the package, instead of downloading the .zip files directly. Let’s download the file - it could take a while! If you don’t understand any of the specific inputs to this line of code, feel free to shout Patrick to talk it through.\n\n## Download the file\ndb_v2 <- nomis_get_data(id = \"NM_2078_1\", time = \"latest\", geography = c(\"TYPE151\"), measures = \"20301\")\n\nRetrieving additional pages 1 of 17\n\n\nRetrieving additional pages 2 of 17\n\n\nRetrieving additional pages 3 of 17\n\n\nRetrieving additional pages 4 of 17\n\n\nRetrieving additional pages 5 of 17\n\n\nRetrieving additional pages 6 of 17\n\n\nRetrieving additional pages 7 of 17\n\n\nRetrieving additional pages 8 of 17\n\n\nRetrieving additional pages 9 of 17\n\n\nRetrieving additional pages 10 of 17\n\n\nRetrieving additional pages 11 of 17\n\n\nRetrieving additional pages 12 of 17\n\n\nRetrieving additional pages 13 of 17\n\n\nRetrieving additional pages 14 of 17\n\n\nRetrieving additional pages 15 of 17\n\n\nRetrieving additional pages 16 of 17\n\n\nRetrieving additional pages 17 of 17\n\n\nThe format the data is presented in is not the most intuitive, so those reshaping skills we acquired yesterday are going to come in handy here again!\nFirstly, let’s get the columns we need for our analysis - LSOA codes, the different modes of transport and the actual reported values.\n\n## Select columns of interest\ndb_clean <- db_v2 %>%\n  select(GEOGRAPHY_CODE, C2021_TTWMETH_12_NAME, OBS_VALUE) \n\n## Inspect\nhead(db_clean)\n\n# A tibble: 6 × 3\n  GEOGRAPHY_CODE C2021_TTWMETH_12_NAME                                   OBS_V…¹\n  <chr>          <chr>                                                     <dbl>\n1 E01011954      Total: All usual residents aged 16 years and over in e…   100  \n2 E01011954      Work mainly at or from home                                11.9\n3 E01011954      Underground, metro, light rail, tram                        0  \n4 E01011954      Train                                                       0.3\n5 E01011954      Bus, minibus or coach                                       4.1\n6 E01011954      Taxi                                                        2  \n# … with abbreviated variable name ¹​OBS_VALUE\n\n\nSo as you can see from the table, it’s actually in a long format, whereas we might want it to be in a wide format, where each column is the % of people using each transport mode. Let’s use the pivot_wider() command to change this:\n\n## Go from long to wide\ndb_clean <- db_clean %>%\n  pivot_wider(names_from = C2021_TTWMETH_12_NAME, values_from = OBS_VALUE)\n\n## Inspect\nhead(db_clean)\n\n# A tibble: 6 × 13\n  GEOGRAPH…¹ Total…² Work …³ Under…⁴ Train Bus, …⁵  Taxi Motor…⁶ Drivi…⁷ Passe…⁸\n  <chr>        <dbl>   <dbl>   <dbl> <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>\n1 E01011954      100    11.9     0     0.3     4.1   2       0.3    63.6     7.5\n2 E01011969      100    14.7     0     0.9     2.9   0.7     0.2    67.6     6.7\n3 E01011970      100    19.5     0     1.5     2.7   0.6     0.8    65.5     5.4\n4 E01011971      100    19       0     0.7     1.6   0.5     0      68.1     5.6\n5 E01033465      100    22.2     0.2   1       1.5   1.1     0.1    65.5     3.6\n6 E01033467      100    20.6     0.3   0.5     2.3   1.2     0      67.1     4  \n# … with 3 more variables: Bicycle <dbl>, `On foot` <dbl>,\n#   `Other method of travel to work` <dbl>, and abbreviated variable names\n#   ¹​GEOGRAPHY_CODE,\n#   ²​`Total: All usual residents aged 16 years and over in employment the week before the census`,\n#   ³​`Work mainly at or from home`, ⁴​`Underground, metro, light rail, tram`,\n#   ⁵​`Bus, minibus or coach`, ⁶​`Motorcycle, scooter or moped`,\n#   ⁷​`Driving a car or van`, ⁸​`Passenger in a car or van`\n\n\nGreat, that’s worked! You’ll also notice the number of rows of db_clean matches that of db (which was the file we unzipped at the start of the practical).\nSome final data cleaning steps:\n\n## Tidy up the dataset\ndb_final <- db_clean %>%\n  setNames(c(\"LSOA21CD\", \"total\", \"work_from_home\", \"underground_metro\", \"train\", \"bus_minibus_coach\", \n             \"taxi\", \"motorcycle\", \"car_driving\", \"car_passenger\", \"bicycle\", \"foot\", \"other\")) ## set new names\n\nAnd then we can easily produce one of the visualisations from yesterday:\n\n## Reproduce the scatter plot from yesterday's class\nggplot(data = db_final, aes(x = work_from_home, y = car_driving)) +\n  geom_point(alpha = 0.3, size = 0.35) +\n  geom_smooth(method = \"lm\") +\n  xlim(0, 100) +\n  ylim(0, 100) +\n  labs(x = \"Population who work from home (%)\", y = \"Population who drive to work (%)\",\n       caption = \"Data: UK Census (2021) - 'Method of travel to work' (ts061)\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nNice! You have now learned how to programmatically use the API to scrape data from NOMIS, bypassing the need to download and unzip the files directly. Now, some independent tasks to check you can reproduce the steps.\n\n4.3.1 Independent exercise - Over to you!\n\nExperiment with downloading a different dataset using the nomisr package, and clean it.\nProduce an interesting visualisation using your chosen dataset.\n(optional) See if you can attach the LAD names to your dataset, and produce a visualisation that examines LAD differences in your chosen dataset - recommend you choose a dataset at either LSOA or MSOA geography to use yesterday’s lookup table. If you are unsure of how to do this, you will need to go back to Day 2 - Data Visualisation."
  },
  {
    "objectID": "04_dashboards-api.html#building-dashboards-in-r",
    "href": "04_dashboards-api.html#building-dashboards-in-r",
    "title": "4  Dashboards and APIs",
    "section": "4.4 Building Dashboards in R",
    "text": "4.4 Building Dashboards in R\nDashboards are often a great way to share results and analyses with others. There are a number of ways you can build dashboards in R, including:\n\nUsing markdown (flexdashboard R package)\nUsing R shiny.\n\nThe former offers you to create a dashboard with panels and pages very easily, and has significant advantages over R Shiny:\n\nMinimal coding required.\nDashboard can be distributed as the .html file, with no server required.\nOther packages can hook into the dashboard to add interactivity.\n\n\n4.4.1 Getting started\nTo build a dashboard using R markdown, we will need to use an alternate type of computational workbook - thus far we have been working with Quarto files (.qmd), but now we need to switch to the format that supports “Flex Dashboards”.\nHowever, flexdashboard runs into problems when linked to an existing R project, especially one which is hooked up to Quarto.\nImportant So for this part of the project please create a new directory where you want to build your dashboard. For example, I’ve created a new folder called ‘Dashboard’, which is where I will be building my dashboard. Also, make sure to copy some of the datasets we have been using into this new directory:\n\n\n\nNew Directory\n\n\nThe final step is to create a new file which will be used to build your dashboard. In R, Go to File > New File > R Markdown > From Template > Flex Dashboard (see below).\n\n\n\nNew File\n\n\nThe file should open up automatically, and should look the one below:\n\n\n\nBlank Dashboard Template\n\n\nNow save it inside your new folder as something you can remember - e.g., dashboard.Rmd. It is vital that this new .Rmd is saved within your new folder, which should now look like this:\n\n\n\nFull Directory\n\n\nWhen you open up the .Rmd file, you should be able to see the ‘Knit’ button as below. If you instead see the ‘Render’ button, you’ve not saved the .rmd in your new directory. Speak to Patrick if you run into problems here.\n\n\n\nKnit Button\n\n\n\n\n4.4.2 Introduction to Flex Dashboard\nFor the remainder of the practical, you need to be working in your new .Rmd file. This is where you will build and deploy your dashboard, so please make sure you are working in this file - ‘dashboard.Rmd’.\nInside the file you will notice a couple of different things:\n\nCode blocks - you will see code blocks like those you have been running in this document, which can be used to run lines of code easily.\nYAML header - at the top of the new file is a YAML header, which is where you can set up the basic metadata for the dashboard.\n\nHave a go at changing your YAML header to the following:\n\n\n\nYAML\n\n\nThese parameters are doing the following:\n\ntitle: sets a title to appear at the top of the dashboard.\norientation: determines whether charts should be aligned in rows or columns\nvertical_layout: sets the dashboard to fill available browser height.\n\nPress ‘Knit’ and see what happens…\nR should open up a new window that looks like this:\n\n\n\nFirst Dashboard\n\n\nSo you can see that the dashboard has three panes set up to host different types of visualisation. In the .Rmd file you’ll notice that each ## denotes the start of a new column, and each ### denotes a new pane for visualisation.\nLet’s change the layout slightly, to create a grid of four equally sized panes. To do this you need to:\n\nChange the data-width parameter to be equal for both columns\nAdd a second pane under column one\n\nHere is what the code looks like:\n\n\n\nCode\n\n\nNow press ‘Knit’ again, and see what has changed:\n\n\n\nResized\n\n\nCool! So the dashboard layout is set up and ready to go!\n\n\n4.4.3 Independent exercise - Over to you!\n\nSwap the orientation to be columns\nSee if you can set up the dashboard to be structured as 1 large panel on the left, and three on the right.\n(optional) Change the section headers for each pane to list some potential visualisations you might put in each, based on yesterday’s class.\n\nSOLUTION:\n\n\n\nSolution\n\n\n\n\n4.4.4 Embedding visualisations\nWhen building a dashboard, a key component will be adding in a number of visualisations to enhance the information being conveyed by the dashboard. As you have seen so far, flexdashboard creates panes to host plots and visualisations on.\nHowever, the visualisations need to be produced within the .Rmd file before they can be displayed on the dashboard itself. This is where you can use code chunks within the .Rmd file to re-run some of the analyses we did yesterday to produce visuals for the dashboard.\nThe code chunks need to be placed before the dashboard structural parameters - i.e. before the ## Column commands in the script. Have a look at the example below where we read in and clean the census data we were using on Day 2:\n\n\n\nHow to insert code\n\n\nThen, once you have the read the data in you can produce one of the visualisations we made yesterday - such as the scatter plot we made yesterday:\n\n\n\nMake a plot\n\n\nNow the final step is to think about embedding this plot so it can be displayed on the plot. To do this, all you need to do is call the plot in one of the code blocks which are set up to host visualisations, see below:\n\n\n\nEmbed a plot\n\n\nNow hit ‘Knit’ and you should see this plot on the dashboard:\n\n\n\nFirst stage\n\n\n\n\n4.4.5 Independent exericse - Over to you!! (30 - 45 mins)\nHave a go at embedding some more visualisations on the dashboard. To do this you will need to reproduce lots of the analysis you did on Day 2.\nBelow I’ve included something that I put together, which is something you could aim to try and generate…\n\n\n\nTransport Dashboard"
  },
  {
    "objectID": "04_dashboards-api.html#other-useful-reporting-techniques",
    "href": "04_dashboards-api.html#other-useful-reporting-techniques",
    "title": "4  Dashboards and APIs",
    "section": "4.5 Other Useful Reporting Techniques",
    "text": "4.5 Other Useful Reporting Techniques\nWe have shown you the power of using R and Quarto for generating computational workbooks where you can view both the figures/outputs and code used to generate them, all at once.\n\n4.5.1 Constructing Reports\nThe .html files that render alongside these .qmd files can be seen as ‘reports’ in a way. However, there is a whole host of design-related modifications you can make to the .qmd file which will enhance the appearance of the output report.\nThere is lots of useful information online about creating nice reports using R markdown - including this one from The Epidemiologist R Handbook.\n\n\n4.5.2 Routine Reporting\nThe Epidemiologist Handbook also has a really nice section on how to use R to run reports routinely, using the reportfactory R package. Have a a look ath the Organising routing reports guide if you are interested in learning more about this!"
  },
  {
    "objectID": "04_dashboards-api.html#additional-resources",
    "href": "04_dashboards-api.html#additional-resources",
    "title": "Transport Dashboard - Liverpool",
    "section": "4.6 Additional Resources",
    "text": "4.6 Additional Resources"
  },
  {
    "objectID": "00_overview.html#delivery-structure",
    "href": "00_overview.html#delivery-structure",
    "title": "Overview",
    "section": "Delivery & Structure",
    "text": "Delivery & Structure\nThe course will be taught across four days. Each day will run from 10AM to 3PM. Days 1 & 2 will be hosted at the University of Liverpool, and Days 3 & 4 will be hosted at LCRCA.\n\n\n\nDay\nActivity\nInstructor\n\n\n\n\n1\nR Fundamentals\nFrancisco Rowe\n\n\n2\nData visualisation\nPatrick Ballantyne\n\n\n3\nAPIs & Dashboards\nPatrick Ballantyne\n\n\n4\nData modeling\nFrancisco Rowe"
  }
]